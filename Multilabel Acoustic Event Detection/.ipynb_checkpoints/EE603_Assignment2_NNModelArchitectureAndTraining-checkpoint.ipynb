{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d17f2a5b",
   "metadata": {},
   "source": [
    "## RNN Model for Audio Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66cec55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40225a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all path variables\n",
    "dir_path = os.getcwd()\n",
    "x_data = os.path.join(dir_path, \"X\")\n",
    "y_data = os.path.join(dir_path, \"Y\")\n",
    "mfcc_data = os.path.join(dir_path, \"MFCC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffb26a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(dirpath):\n",
    "    X_train = numpy.load(os.path.join(dir_path, 'X_train.npy'))\n",
    "    X_test = numpy.load(os.path.join(dir_path, 'X_test.npy'))\n",
    "    y_train = numpy.load(os.path.join(dir_path, 'y_train.npy'))\n",
    "    y_test = numpy.load(os.path.join(dir_path, 'y_test.npy'))\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a67e588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.recurrent import LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def getModel(X_train):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(units=128, recurrent_dropout=0.35, return_sequences=True, input_shape = [99,13]))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(LSTM(units=64, recurrent_dropout=0.35, return_sequences=False))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation = 'relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(units= y_train.shape[1], activation=\"softmax\"))\n",
    "\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faa597cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = getData(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20edddae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 20, 1000, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdf83424",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = getModel(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11fcf7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 20, 1000, 32)      320       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 20, 1000, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 20, 1000, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 10, 500, 32)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 10, 500, 128)      36992     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 10, 500, 128)     512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 10, 500, 128)      0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 250, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 5, 250, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 5, 250, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 5, 250, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 2, 125, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 2, 125, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 2, 125, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 2, 125, 256)       0         \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 256)              0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 516,426\n",
      "Trainable params: 515,338\n",
      "Non-trainable params: 1,088\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8896f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(1e-2), loss = 'binary_crossentropy', metrics = ['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00c82f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To keep track of the best metrices obtained while training the model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath = dir_path + 'my_best_model_cnn.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='accuracy', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe276200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.1640 - accuracy: 0.2663\n",
      "Epoch 1: accuracy improved from -inf to 0.26629, saving model to C:\\Users\\Hp\\OneDrive\\Desktop\\IITK\\SEM5\\EE603\\Audio_Classification-MLSP_Assignment-2my_best_model_cnn.hdf5\n",
      "219/219 [==============================] - 312s 1s/step - loss: 0.1640 - accuracy: 0.2663 - val_loss: 0.2083 - val_accuracy: 0.1840\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.1454 - accuracy: 0.2986\n",
      "Epoch 2: accuracy improved from 0.26629 to 0.29857, saving model to C:\\Users\\Hp\\OneDrive\\Desktop\\IITK\\SEM5\\EE603\\Audio_Classification-MLSP_Assignment-2my_best_model_cnn.hdf5\n",
      "219/219 [==============================] - 300s 1s/step - loss: 0.1454 - accuracy: 0.2986 - val_loss: 0.1904 - val_accuracy: 0.3413\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.1384 - accuracy: 0.3069\n",
      "Epoch 3: accuracy improved from 0.29857 to 0.30686, saving model to C:\\Users\\Hp\\OneDrive\\Desktop\\IITK\\SEM5\\EE603\\Audio_Classification-MLSP_Assignment-2my_best_model_cnn.hdf5\n",
      "219/219 [==============================] - 324s 1s/step - loss: 0.1384 - accuracy: 0.3069 - val_loss: 0.2596 - val_accuracy: 0.2853\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.1211 - accuracy: 0.3241\n",
      "Epoch 4: accuracy improved from 0.30686 to 0.32414, saving model to C:\\Users\\Hp\\OneDrive\\Desktop\\IITK\\SEM5\\EE603\\Audio_Classification-MLSP_Assignment-2my_best_model_cnn.hdf5\n",
      "219/219 [==============================] - 360s 2s/step - loss: 0.1211 - accuracy: 0.3241 - val_loss: 0.2751 - val_accuracy: 0.2190\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.1152 - accuracy: 0.3334\n",
      "Epoch 5: accuracy improved from 0.32414 to 0.33343, saving model to C:\\Users\\Hp\\OneDrive\\Desktop\\IITK\\SEM5\\EE603\\Audio_Classification-MLSP_Assignment-2my_best_model_cnn.hdf5\n",
      "219/219 [==============================] - 315s 1s/step - loss: 0.1152 - accuracy: 0.3334 - val_loss: 0.2458 - val_accuracy: 0.2607\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.1033 - accuracy: 0.3454\n",
      "Epoch 6: accuracy improved from 0.33343 to 0.34543, saving model to C:\\Users\\Hp\\OneDrive\\Desktop\\IITK\\SEM5\\EE603\\Audio_Classification-MLSP_Assignment-2my_best_model_cnn.hdf5\n",
      "219/219 [==============================] - 317s 1s/step - loss: 0.1033 - accuracy: 0.3454 - val_loss: 0.2247 - val_accuracy: 0.2780\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.1048 - accuracy: 0.3424\n",
      "Epoch 7: accuracy did not improve from 0.34543\n",
      "219/219 [==============================] - 308s 1s/step - loss: 0.1048 - accuracy: 0.3424 - val_loss: 0.1999 - val_accuracy: 0.2390\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.0907 - accuracy: 0.3514\n",
      "Epoch 8: accuracy improved from 0.34543 to 0.35143, saving model to C:\\Users\\Hp\\OneDrive\\Desktop\\IITK\\SEM5\\EE603\\Audio_Classification-MLSP_Assignment-2my_best_model_cnn.hdf5\n",
      "219/219 [==============================] - 301s 1s/step - loss: 0.0907 - accuracy: 0.3514 - val_loss: 0.2106 - val_accuracy: 0.2740\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.0858 - accuracy: 0.3451\n",
      "Epoch 9: accuracy did not improve from 0.35143\n",
      "219/219 [==============================] - 300s 1s/step - loss: 0.0858 - accuracy: 0.3451 - val_loss: 0.2496 - val_accuracy: 0.3300\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 0.3511\n",
      "Epoch 10: accuracy did not improve from 0.35143\n",
      "219/219 [==============================] - 1014s 5s/step - loss: 0.0808 - accuracy: 0.3511 - val_loss: 0.2666 - val_accuracy: 0.2877\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.3551\n",
      "Epoch 11: accuracy improved from 0.35143 to 0.35514, saving model to C:\\Users\\Hp\\OneDrive\\Desktop\\IITK\\SEM5\\EE603\\Audio_Classification-MLSP_Assignment-2my_best_model_cnn.hdf5\n",
      "219/219 [==============================] - 382s 2s/step - loss: 0.0772 - accuracy: 0.3551 - val_loss: 0.1997 - val_accuracy: 0.3170\n",
      "Epoch 12/20\n",
      " 42/219 [====>.........................] - ETA: 4:57 - loss: 0.0577 - accuracy: 0.3549"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=32, epochs=20, verbose = 1, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a491600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "model.metrics_names\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
