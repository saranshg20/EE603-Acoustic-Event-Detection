{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78229dd2",
   "metadata": {
    "id": "78229dd2"
   },
   "source": [
    "### CNN Model for Audio Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95c553ea",
   "metadata": {
    "id": "95c553ea"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "# import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# import seaborn as sns\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7dbd808",
   "metadata": {
    "id": "f7dbd808"
   },
   "outputs": [],
   "source": [
    "# Initialize all path variables\n",
    "dir_path = os.getcwd()\n",
    "x_data = os.path.join(dir_path, \"X\")\n",
    "y_data = os.path.join(dir_path, \"Y\")\n",
    "mfcc_data = os.path.join(dir_path, \"MFCC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92815d66",
   "metadata": {
    "id": "92815d66"
   },
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TObP_MluSiE0",
   "metadata": {
    "id": "TObP_MluSiE0"
   },
   "outputs": [],
   "source": [
    "# PARAMETER FOR STFT\n",
    "# SAMPLING_RATE=16000\n",
    "# DURATION=10\n",
    "# N_FFT = 1024\n",
    "# WIN_LENGTH = 1024\n",
    "# HOP_LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voL_UCT0Lj3Z",
   "metadata": {
    "id": "voL_UCT0Lj3Z"
   },
   "outputs": [],
   "source": [
    "for file in os.listdir(x_data):\n",
    "    mel_spectrogram = numpy.load(x_data+'/'+file)\n",
    "    print(file)\n",
    "    mfcc = librosa.feature.mfcc(S=mel_spectrogram, sr=16000,n_mfcc=20)\n",
    "    mean = numpy.average(mfcc)\n",
    "    std = numpy.std(mfcc)\n",
    "    if(std == 0):\n",
    "      std = std + 1e-25\n",
    "    mfcc = (mfcc - mean)/std\n",
    "    path = os.path.join(mfcc_data, file)\n",
    "    numpy.save(path, mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rvpLI8Tmd7Dw",
   "metadata": {
    "id": "rvpLI8Tmd7Dw"
   },
   "outputs": [],
   "source": [
    "x = os.listdir(x_data)\n",
    "x = sorted(set(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iO7zWkrrUGf_",
   "metadata": {
    "id": "iO7zWkrrUGf_"
   },
   "outputs": [],
   "source": [
    "#List containing all spectrograms\n",
    "mfccs=[] \n",
    "for file in x:\n",
    "    arr = numpy.load(os.path.join(mfcc_data, file))\n",
    "    m,n,o = arr.shape\n",
    "    arr = arr.reshape(n,o)\n",
    "    mat = arr.reshape((arr.shape[0], arr.shape[1], 1))\n",
    "    mfccs.append(tf.convert_to_tensor(mat))\n",
    "mfccs = numpy.array(mfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38da62bf",
   "metadata": {
    "id": "38da62bf"
   },
   "outputs": [],
   "source": [
    "def eventroll_to_multihot_vector(eventroll):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    eventroll : np.array\n",
    "        Eventroll matrix of shape=(11, 1000).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        A multihot vector of shape=(10,)\n",
    "    \"\"\"\n",
    "    \n",
    "    # findout active events:\n",
    "    active_events = (eventroll.sum(axis=1) >= 0.5).astype('float')\n",
    "    \n",
    "    # remove silence class:\n",
    "    return numpy.delete(active_events, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sq0aFGU9gqUS",
   "metadata": {
    "id": "sq0aFGU9gqUS"
   },
   "outputs": [],
   "source": [
    "y_list = os.listdir(y_data)\n",
    "y_list = sorted(set(y_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af27be3",
   "metadata": {
    "id": "2af27be3"
   },
   "outputs": [],
   "source": [
    "#List containing all spectrograms\n",
    "y = [] \n",
    "for file in y_list:\n",
    "    arr = numpy.load(os.path.join(y_data, file))\n",
    "    y.append(eventroll_to_multihot_vector(arr))\n",
    "y = numpy.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f38586d",
   "metadata": {
    "id": "5f38586d"
   },
   "source": [
    "#### Load the required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oYrVPXPEKJca",
   "metadata": {
    "id": "oYrVPXPEKJca"
   },
   "outputs": [],
   "source": [
    "X=mfccs[0:10000]\n",
    "y=y[0:10000]\n",
    "# used 'random_state' of 40 while splitting to get the balanced split of data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40, shuffle=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96f2924",
   "metadata": {
    "id": "e96f2924"
   },
   "outputs": [],
   "source": [
    "# get the count of classes present in y_test\n",
    "# print(type(y_test))\n",
    "# val_label=pd.Series(list(y_test))\n",
    "# val_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86c1076",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d86c1076",
    "outputId": "a0c8e080-7b04-494b-df09-3d66c5a84763"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 64, 1000, 1)\n"
     ]
    }
   ],
   "source": [
    "pool_size = (2, 2)\n",
    "kernel_size = (3, 3)\n",
    "input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])\n",
    "num_classes = 10\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85983480",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "85983480",
    "outputId": "005232a1-299b-4362-b5f4-7543991d1bd2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'10%'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''10%'''\n",
    "# model = tf.keras.models.Sequential([\n",
    "#     #first_convolution\n",
    "#     tf.keras.layers.Conv2D(32, kernel_size,\n",
    "#                 padding=\"same\", input_shape=input_shape),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Activation('relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(2, 2),\n",
    "#     # tf.keras.layers.Dropout(0.25),\n",
    "#     #second_convolution\n",
    "#     tf.keras.layers.Conv2D(64, kernel_size,\n",
    "#                                   padding=\"same\"),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Activation('relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(2,2),\n",
    "# #     tf.keras.layers.Dropout(0.25),\n",
    "#     #third_convolution\n",
    "#     tf.keras.layers.Conv2D(128, kernel_size,\n",
    "#                                   padding=\"same\"),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Activation('relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(2,2),\n",
    "#     tf.keras.layers.Dropout(0.25),\n",
    "#     #fourth_convolution\n",
    "#     tf.keras.layers.Conv2D(128, kernel_size,\n",
    "#                                   padding=\"same\"),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Activation('relu'),\n",
    "#     tf.keras.layers.GlobalMaxPooling2D(),\n",
    "#     tf.keras.layers.Dropout(0.25),\n",
    "#     #Fully connected 1st layer\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "#     tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "#     tf.keras.layers.Dense(10, activation=\"sigmoid\") \n",
    "# ]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1964c53",
   "metadata": {
    "id": "f1964c53"
   },
   "source": [
    "https://publications.lib.chalmers.se/records/fulltext/255604/255604.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yIAEW3m06UHQ",
   "metadata": {
    "id": "yIAEW3m06UHQ"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    #first_convolution\n",
    "    tf.keras.layers.Conv2D(32, kernel_size,\n",
    "                padding=\"same\", input_shape=input_shape),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # tf.keras.layers.Dropout(0.25),\n",
    "    #second_convolution\n",
    "    tf.keras.layers.Conv2D(128, kernel_size,\n",
    "                                  padding=\"same\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "#     tf.keras.layers.Dropout(0.25),\n",
    "    #third_convolution\n",
    "    tf.keras.layers.Conv2D(128, kernel_size,\n",
    "                                  padding=\"same\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # tf.keras.layers.Dropout(0.25),\n",
    "    #fifth_convolution\n",
    "    tf.keras.layers.Conv2D(256, kernel_size,\n",
    "                                  padding=\"same\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.GlobalMaxPooling2D(),\n",
    "    # tf.keras.layers.Dropout(0.25),\n",
    "    #Fully connected 1st layer\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1024, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"sigmoid\") \n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6137f68a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6137f68a",
    "outputId": "7b016f33-c52b-4f5f-8480-0533b3ded4ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_14 (Conv2D)          (None, 64, 1000, 32)      320       \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 64, 1000, 32)     128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 64, 1000, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 32, 500, 32)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 32, 500, 128)      36992     \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 32, 500, 128)     512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 32, 500, 128)      0         \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 16, 250, 128)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 16, 250, 128)      147584    \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 16, 250, 128)     512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_16 (Activation)  (None, 16, 250, 128)      0         \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 8, 125, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 8, 125, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 8, 125, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_17 (Activation)  (None, 8, 125, 256)       0         \n",
      "                                                                 \n",
      " global_max_pooling2d_5 (Glo  (None, 256)              0         \n",
      " balMaxPooling2D)                                                \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1024)              263168    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,337,162\n",
      "Trainable params: 1,336,074\n",
      "Non-trainable params: 1,088\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XsLcJSr2_uZz",
   "metadata": {
    "id": "XsLcJSr2_uZz"
   },
   "source": [
    "https://www.kaggle.com/code/kmkarakaya/multi-label-model-evaluation/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9851d373",
   "metadata": {
    "id": "9851d373"
   },
   "outputs": [],
   "source": [
    "# # compile the model using Adam optimizer\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "#           loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "#           metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8w-6D6srKtya",
   "metadata": {
    "id": "8w-6D6srKtya"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f66166e",
   "metadata": {
    "id": "2f66166e"
   },
   "outputs": [],
   "source": [
    "# To keep track of the best metrices obtained while training the model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "filepath = '/content/drive/MyDrive/Audio_Classification-MLSP_Assignment-2/my_best_model_cnn.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='accuracy', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bd0a55",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92bd0a55",
    "outputId": "78bc6c32-41d1-4271-b4cc-1e37bd36cbf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3931 - accuracy: 0.1135\n",
      "Epoch 1: accuracy improved from -inf to 0.11350, saving model to /content/drive/MyDrive/Audio_Classification-MLSP_Assignment-2/my_best_model_cnn.hdf5\n",
      "250/250 [==============================] - 48s 150ms/step - loss: 0.3931 - accuracy: 0.1135 - val_loss: 0.3810 - val_accuracy: 0.1070\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3792 - accuracy: 0.1142\n",
      "Epoch 2: accuracy improved from 0.11350 to 0.11425, saving model to /content/drive/MyDrive/Audio_Classification-MLSP_Assignment-2/my_best_model_cnn.hdf5\n",
      "250/250 [==============================] - 38s 154ms/step - loss: 0.3792 - accuracy: 0.1142 - val_loss: 0.3776 - val_accuracy: 0.1070\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3770 - accuracy: 0.1142\n",
      "Epoch 3: accuracy did not improve from 0.11425\n",
      "250/250 [==============================] - 35s 138ms/step - loss: 0.3770 - accuracy: 0.1142 - val_loss: 0.3759 - val_accuracy: 0.1070\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3762 - accuracy: 0.1142\n",
      "Epoch 4: accuracy did not improve from 0.11425\n",
      "250/250 [==============================] - 35s 139ms/step - loss: 0.3762 - accuracy: 0.1142 - val_loss: 0.3731 - val_accuracy: 0.1070\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3759 - accuracy: 0.1142\n",
      "Epoch 5: accuracy did not improve from 0.11425\n",
      "250/250 [==============================] - 35s 139ms/step - loss: 0.3759 - accuracy: 0.1142 - val_loss: 0.3771 - val_accuracy: 0.1070\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3744 - accuracy: 0.1142\n",
      "Epoch 6: accuracy did not improve from 0.11425\n",
      "250/250 [==============================] - 35s 139ms/step - loss: 0.3744 - accuracy: 0.1142 - val_loss: 0.3768 - val_accuracy: 0.1070\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3733 - accuracy: 0.1142\n",
      "Epoch 7: accuracy did not improve from 0.11425\n",
      "250/250 [==============================] - 35s 139ms/step - loss: 0.3733 - accuracy: 0.1142 - val_loss: 0.3742 - val_accuracy: 0.1070\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3722 - accuracy: 0.1142\n",
      "Epoch 8: accuracy did not improve from 0.11425\n",
      "250/250 [==============================] - 35s 139ms/step - loss: 0.3722 - accuracy: 0.1142 - val_loss: 0.3716 - val_accuracy: 0.1070\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3725 - accuracy: 0.1142\n",
      "Epoch 9: accuracy did not improve from 0.11425\n",
      "250/250 [==============================] - 35s 139ms/step - loss: 0.3725 - accuracy: 0.1142 - val_loss: 0.3796 - val_accuracy: 0.1070\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3705 - accuracy: 0.1142\n",
      "Epoch 10: accuracy did not improve from 0.11425\n",
      "250/250 [==============================] - 37s 149ms/step - loss: 0.3705 - accuracy: 0.1142 - val_loss: 0.3737 - val_accuracy: 0.1070\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=32, epochs=10, verbose = 1, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57988576",
   "metadata": {
    "id": "57988576"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "model.metrics_names\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a13e78",
   "metadata": {
    "id": "41a13e78"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "accuracy = model.evaluate(X_test, y_test)\n",
    "print('n', 'Test_Accuracy:-', accuracy[1])\n",
    "pred=model.predict(X_test)\n",
    "y_pred = pred\n",
    "y_true = y_test\n",
    "\n",
    "print('confusion matrix')\n",
    "print(multilabel_confusion_matrix(numpy.array(y_true), numpy.array(y_pred)))\n",
    "\n",
    "# f, ax = plt.subplots(figsize=(8,5))\n",
    "# sns.heatmap(confusion_matrix(y_true, y_pred), annot=True, fmt=\".0f\", ax=ax)\n",
    "# plt.xlabel(\"y_pred\")\n",
    "# plt.ylabel(\"y_true\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25084bb",
   "metadata": {
    "id": "f25084bb"
   },
   "outputs": [],
   "source": [
    "print(y_pred[0])\n",
    "print(y_true[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35dd396",
   "metadata": {
    "id": "e35dd396"
   },
   "outputs": [],
   "source": [
    "model = load_model(filepath, custom_objects={'f1_m':f1_m, 'precision_m':precision_m, 'recall_m':recall_m})"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
