{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **CNN Model for Single Audio Event Detection**\n"
      ],
      "metadata": {
        "id": "4gL3WOPkWd9f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5pk-azK4uFJ"
      },
      "outputs": [],
      "source": [
        "import numpy \n",
        "import os\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCUeEWjt43cb",
        "outputId": "f2ced1dd-cbf0-484e-fcaa-4d5068a02be9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize all path variables\n",
        "dir_path = '/content/drive/MyDrive/Audio_Classification-MLSP'\n",
        "train_data_path=os.path.join(dir_path, \"train\")"
      ],
      "metadata": {
        "id": "EBE7YuBl48Jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data from 'annotations.csv' \n",
        "data=pd.read_csv(os.path.join(dir_path, \"annotations.csv\"))"
      ],
      "metadata": {
        "id": "vMznpHFkX1yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Preprocessing data**"
      ],
      "metadata": {
        "id": "fUOb2KyyYrGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#List containing all spectrograms\n",
        "mel_spectrograms=[] \n",
        "\n",
        "for file in data['fname']:\n",
        "  arr=numpy.load(os.path.join(train_data_path, file))\n",
        "  m,n,o=arr.shape\n",
        "  print(m, n, o)\n",
        "  arr.resize(n,o)\n",
        "  print(arr.shape)\n",
        "  # Convert a power spectrogram (amplitude squared) to decibel (dB) units\n",
        "  mel_spectrogram = librosa.power_to_db(arr, ref=numpy.max)\n",
        "  # mfcc = librosa.features.mfcc(mel_spect)\n",
        "  mel_spectrograms.append(mel_spectrogram)"
      ],
      "metadata": {
        "id": "pTnyufS95GD-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b82313a6-f340-4588-d97c-63806b079c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 128 314\n",
            "(128, 314)\n",
            "1 128 2504\n",
            "(128, 2504)\n",
            "1 128 236\n",
            "(128, 236)\n",
            "1 128 1070\n",
            "(128, 1070)\n",
            "1 128 272\n",
            "(128, 272)\n",
            "1 128 70\n",
            "(128, 70)\n",
            "1 128 664\n",
            "(128, 664)\n",
            "1 128 1421\n",
            "(128, 1421)\n",
            "1 128 432\n",
            "(128, 432)\n",
            "1 128 200\n",
            "(128, 200)\n",
            "1 128 1211\n",
            "(128, 1211)\n",
            "1 128 2512\n",
            "(128, 2512)\n",
            "1 128 52\n",
            "(128, 52)\n",
            "1 128 868\n",
            "(128, 868)\n",
            "1 128 106\n",
            "(128, 106)\n",
            "1 128 34\n",
            "(128, 34)\n",
            "1 128 2512\n",
            "(128, 2512)\n",
            "1 128 2584\n",
            "(128, 2584)\n",
            "1 128 72\n",
            "(128, 72)\n",
            "1 128 32\n",
            "(128, 32)\n",
            "1 128 44\n",
            "(128, 44)\n",
            "1 128 194\n",
            "(128, 194)\n",
            "1 128 100\n",
            "(128, 100)\n",
            "1 128 224\n",
            "(128, 224)\n",
            "1 128 1506\n",
            "(128, 1506)\n",
            "1 128 269\n",
            "(128, 269)\n",
            "1 128 518\n",
            "(128, 518)\n",
            "1 128 586\n",
            "(128, 586)\n",
            "1 128 100\n",
            "(128, 100)\n",
            "1 128 194\n",
            "(128, 194)\n",
            "1 128 41\n",
            "(128, 41)\n",
            "1 128 359\n",
            "(128, 359)\n",
            "1 128 282\n",
            "(128, 282)\n",
            "1 128 94\n",
            "(128, 94)\n",
            "1 128 314\n",
            "(128, 314)\n",
            "1 128 1701\n",
            "(128, 1701)\n",
            "1 128 240\n",
            "(128, 240)\n",
            "1 128 55\n",
            "(128, 55)\n",
            "1 128 2512\n",
            "(128, 2512)\n",
            "1 128 1114\n",
            "(128, 1114)\n",
            "1 128 230\n",
            "(128, 230)\n",
            "1 128 47\n",
            "(128, 47)\n",
            "1 128 272\n",
            "(128, 272)\n",
            "1 128 309\n",
            "(128, 309)\n",
            "1 128 259\n",
            "(128, 259)\n",
            "1 128 1512\n",
            "(128, 1512)\n",
            "1 128 2357\n",
            "(128, 2357)\n",
            "1 128 645\n",
            "(128, 645)\n",
            "1 128 52\n",
            "(128, 52)\n",
            "1 128 57\n",
            "(128, 57)\n",
            "1 128 340\n",
            "(128, 340)\n",
            "1 128 369\n",
            "(128, 369)\n",
            "1 128 475\n",
            "(128, 475)\n",
            "1 128 209\n",
            "(128, 209)\n",
            "1 128 1534\n",
            "(128, 1534)\n",
            "1 128 244\n",
            "(128, 244)\n",
            "1 128 1701\n",
            "(128, 1701)\n",
            "1 128 340\n",
            "(128, 340)\n",
            "1 128 908\n",
            "(128, 908)\n",
            "1 128 307\n",
            "(128, 307)\n",
            "1 128 42\n",
            "(128, 42)\n",
            "1 128 50\n",
            "(128, 50)\n",
            "1 128 52\n",
            "(128, 52)\n",
            "1 128 268\n",
            "(128, 268)\n",
            "1 128 47\n",
            "(128, 47)\n",
            "1 128 216\n",
            "(128, 216)\n",
            "1 128 197\n",
            "(128, 197)\n",
            "1 128 716\n",
            "(128, 716)\n",
            "1 128 64\n",
            "(128, 64)\n",
            "1 128 494\n",
            "(128, 494)\n",
            "1 128 34\n",
            "(128, 34)\n",
            "1 128 162\n",
            "(128, 162)\n",
            "1 128 29\n",
            "(128, 29)\n",
            "1 128 436\n",
            "(128, 436)\n",
            "1 128 445\n",
            "(128, 445)\n",
            "1 128 170\n",
            "(128, 170)\n",
            "1 128 40\n",
            "(128, 40)\n",
            "1 128 307\n",
            "(128, 307)\n",
            "1 128 434\n",
            "(128, 434)\n",
            "1 128 1628\n",
            "(128, 1628)\n",
            "1 128 280\n",
            "(128, 280)\n",
            "1 128 48\n",
            "(128, 48)\n",
            "1 128 50\n",
            "(128, 50)\n",
            "1 128 56\n",
            "(128, 56)\n",
            "1 128 257\n",
            "(128, 257)\n",
            "1 128 381\n",
            "(128, 381)\n",
            "1 128 254\n",
            "(128, 254)\n",
            "1 128 1628\n",
            "(128, 1628)\n",
            "1 128 100\n",
            "(128, 100)\n",
            "1 128 451\n",
            "(128, 451)\n",
            "1 128 760\n",
            "(128, 760)\n",
            "1 128 1471\n",
            "(128, 1471)\n",
            "1 128 100\n",
            "(128, 100)\n",
            "1 128 1904\n",
            "(128, 1904)\n",
            "1 128 325\n",
            "(128, 325)\n",
            "1 128 475\n",
            "(128, 475)\n",
            "1 128 381\n",
            "(128, 381)\n",
            "1 128 51\n",
            "(128, 51)\n",
            "1 128 204\n",
            "(128, 204)\n",
            "1 128 50\n",
            "(128, 50)\n",
            "1 128 75\n",
            "(128, 75)\n",
            "1 128 130\n",
            "(128, 130)\n",
            "1 128 1004\n",
            "(128, 1004)\n",
            "1 128 50\n",
            "(128, 50)\n",
            "1 128 88\n",
            "(128, 88)\n",
            "1 128 124\n",
            "(128, 124)\n",
            "1 128 776\n",
            "(128, 776)\n",
            "1 128 76\n",
            "(128, 76)\n",
            "1 128 130\n",
            "(128, 130)\n",
            "1 128 119\n",
            "(128, 119)\n",
            "1 128 62\n",
            "(128, 62)\n",
            "1 128 85\n",
            "(128, 85)\n",
            "1 128 690\n",
            "(128, 690)\n",
            "1 128 1014\n",
            "(128, 1014)\n",
            "1 128 431\n",
            "(128, 431)\n",
            "1 128 125\n",
            "(128, 125)\n",
            "1 128 74\n",
            "(128, 74)\n",
            "1 128 1900\n",
            "(128, 1900)\n",
            "1 128 974\n",
            "(128, 974)\n",
            "1 128 549\n",
            "(128, 549)\n",
            "1 128 2397\n",
            "(128, 2397)\n",
            "1 128 68\n",
            "(128, 68)\n",
            "1 128 1416\n",
            "(128, 1416)\n",
            "1 128 1938\n",
            "(128, 1938)\n",
            "1 128 496\n",
            "(128, 496)\n",
            "1 128 239\n",
            "(128, 239)\n",
            "1 128 74\n",
            "(128, 74)\n",
            "1 128 899\n",
            "(128, 899)\n",
            "1 128 551\n",
            "(128, 551)\n",
            "1 128 68\n",
            "(128, 68)\n",
            "1 128 63\n",
            "(128, 63)\n",
            "1 128 832\n",
            "(128, 832)\n",
            "1 128 555\n",
            "(128, 555)\n",
            "1 128 100\n",
            "(128, 100)\n",
            "1 128 189\n",
            "(128, 189)\n",
            "1 128 431\n",
            "(128, 431)\n",
            "1 128 360\n",
            "(128, 360)\n",
            "1 128 134\n",
            "(128, 134)\n",
            "1 128 897\n",
            "(128, 897)\n",
            "1 128 130\n",
            "(128, 130)\n",
            "1 128 897\n",
            "(128, 897)\n",
            "1 128 137\n",
            "(128, 137)\n",
            "1 128 136\n",
            "(128, 136)\n",
            "1 128 1642\n",
            "(128, 1642)\n",
            "1 128 555\n",
            "(128, 555)\n",
            "1 128 288\n",
            "(128, 288)\n",
            "1 128 1004\n",
            "(128, 1004)\n",
            "1 128 1678\n",
            "(128, 1678)\n",
            "1 128 137\n",
            "(128, 137)\n",
            "1 128 1995\n",
            "(128, 1995)\n",
            "1 128 51\n",
            "(128, 51)\n",
            "1 128 281\n",
            "(128, 281)\n",
            "1 128 137\n",
            "(128, 137)\n",
            "1 128 66\n",
            "(128, 66)\n",
            "1 128 583\n",
            "(128, 583)\n",
            "1 128 119\n",
            "(128, 119)\n",
            "1 128 832\n",
            "(128, 832)\n",
            "1 128 155\n",
            "(128, 155)\n",
            "1 128 75\n",
            "(128, 75)\n",
            "1 128 130\n",
            "(128, 130)\n",
            "1 128 952\n",
            "(128, 952)\n",
            "1 128 281\n",
            "(128, 281)\n",
            "1 128 136\n",
            "(128, 136)\n",
            "1 128 130\n",
            "(128, 130)\n",
            "1 128 124\n",
            "(128, 124)\n",
            "1 128 137\n",
            "(128, 137)\n",
            "1 128 101\n",
            "(128, 101)\n",
            "1 128 744\n",
            "(128, 744)\n",
            "1 128 776\n",
            "(128, 776)\n",
            "1 128 51\n",
            "(128, 51)\n",
            "1 128 76\n",
            "(128, 76)\n",
            "1 128 1004\n",
            "(128, 1004)\n",
            "1 128 50\n",
            "(128, 50)\n",
            "1 128 137\n",
            "(128, 137)\n",
            "1 128 701\n",
            "(128, 701)\n",
            "1 128 431\n",
            "(128, 431)\n",
            "1 128 897\n",
            "(128, 897)\n",
            "1 128 168\n",
            "(128, 168)\n",
            "1 128 70\n",
            "(128, 70)\n",
            "1 128 50\n",
            "(128, 50)\n",
            "1 128 262\n",
            "(128, 262)\n",
            "1 128 68\n",
            "(128, 68)\n",
            "1 128 952\n",
            "(128, 952)\n",
            "1 128 29\n",
            "(128, 29)\n",
            "1 128 125\n",
            "(128, 125)\n",
            "1 128 579\n",
            "(128, 579)\n",
            "1 128 1628\n",
            "(128, 1628)\n",
            "1 128 754\n",
            "(128, 754)\n",
            "1 128 1826\n",
            "(128, 1826)\n",
            "1 128 591\n",
            "(128, 591)\n",
            "1 128 1014\n",
            "(128, 1014)\n",
            "1 128 63\n",
            "(128, 63)\n",
            "1 128 68\n",
            "(128, 68)\n",
            "1 128 84\n",
            "(128, 84)\n",
            "1 128 947\n",
            "(128, 947)\n",
            "1 128 873\n",
            "(128, 873)\n",
            "1 128 360\n",
            "(128, 360)\n",
            "1 128 281\n",
            "(128, 281)\n",
            "1 128 130\n",
            "(128, 130)\n",
            "1 128 431\n",
            "(128, 431)\n",
            "1 128 1841\n",
            "(128, 1841)\n",
            "1 128 389\n",
            "(128, 389)\n",
            "1 128 352\n",
            "(128, 352)\n",
            "1 128 1073\n",
            "(128, 1073)\n",
            "1 128 1103\n",
            "(128, 1103)\n",
            "1 128 1446\n",
            "(128, 1446)\n",
            "1 128 1723\n",
            "(128, 1723)\n",
            "1 128 150\n",
            "(128, 150)\n",
            "1 128 1927\n",
            "(128, 1927)\n",
            "1 128 1927\n",
            "(128, 1927)\n",
            "1 128 1073\n",
            "(128, 1073)\n",
            "1 128 385\n",
            "(128, 385)\n",
            "1 128 1062\n",
            "(128, 1062)\n",
            "1 128 1270\n",
            "(128, 1270)\n",
            "1 128 1103\n",
            "(128, 1103)\n",
            "1 128 352\n",
            "(128, 352)\n",
            "1 128 1383\n",
            "(128, 1383)\n",
            "1 128 87\n",
            "(128, 87)\n",
            "1 128 389\n",
            "(128, 389)\n",
            "1 128 1062\n",
            "(128, 1062)\n",
            "1 128 1723\n",
            "(128, 1723)\n",
            "1 128 300\n",
            "(128, 300)\n",
            "1 128 1523\n",
            "(128, 1523)\n",
            "1 128 1841\n",
            "(128, 1841)\n",
            "1 128 1062\n",
            "(128, 1062)\n",
            "1 128 2424\n",
            "(128, 2424)\n",
            "1 128 1062\n",
            "(128, 1062)\n",
            "1 128 1270\n",
            "(128, 1270)\n",
            "1 128 2424\n",
            "(128, 2424)\n",
            "1 128 300\n",
            "(128, 300)\n",
            "1 128 87\n",
            "(128, 87)\n",
            "1 128 1062\n",
            "(128, 1062)\n",
            "1 128 1383\n",
            "(128, 1383)\n",
            "1 128 1723\n",
            "(128, 1723)\n",
            "1 128 87\n",
            "(128, 87)\n",
            "1 128 1446\n",
            "(128, 1446)\n",
            "1 128 345\n",
            "(128, 345)\n",
            "1 128 478\n",
            "(128, 478)\n",
            "1 128 780\n",
            "(128, 780)\n",
            "1 128 300\n",
            "(128, 300)\n",
            "1 128 895\n",
            "(128, 895)\n",
            "1 128 478\n",
            "(128, 478)\n",
            "1 128 150\n",
            "(128, 150)\n",
            "1 128 1446\n",
            "(128, 1446)\n",
            "1 128 345\n",
            "(128, 345)\n",
            "1 128 1446\n",
            "(128, 1446)\n",
            "1 128 817\n",
            "(128, 817)\n",
            "1 128 1723\n",
            "(128, 1723)\n",
            "1 128 895\n",
            "(128, 895)\n",
            "1 128 1383\n",
            "(128, 1383)\n",
            "1 128 150\n",
            "(128, 150)\n",
            "1 128 87\n",
            "(128, 87)\n",
            "1 128 385\n",
            "(128, 385)\n",
            "1 128 895\n",
            "(128, 895)\n",
            "1 128 87\n",
            "(128, 87)\n",
            "1 128 1062\n",
            "(128, 1062)\n",
            "1 128 1723\n",
            "(128, 1723)\n",
            "1 128 385\n",
            "(128, 385)\n",
            "1 128 1062\n",
            "(128, 1062)\n",
            "1 128 352\n",
            "(128, 352)\n",
            "1 128 2424\n",
            "(128, 2424)\n",
            "1 128 383\n",
            "(128, 383)\n",
            "1 128 1446\n",
            "(128, 1446)\n",
            "1 128 352\n",
            "(128, 352)\n",
            "1 128 1446\n",
            "(128, 1446)\n",
            "1 128 2424\n",
            "(128, 2424)\n",
            "1 128 895\n",
            "(128, 895)\n",
            "1 128 150\n",
            "(128, 150)\n",
            "1 128 1103\n",
            "(128, 1103)\n",
            "1 128 87\n",
            "(128, 87)\n",
            "1 128 1723\n",
            "(128, 1723)\n",
            "1 128 1270\n",
            "(128, 1270)\n",
            "1 128 352\n",
            "(128, 352)\n",
            "1 128 895\n",
            "(128, 895)\n",
            "1 128 1073\n",
            "(128, 1073)\n",
            "1 128 87\n",
            "(128, 87)\n",
            "1 128 345\n",
            "(128, 345)\n",
            "1 128 1270\n",
            "(128, 1270)\n",
            "1 128 1103\n",
            "(128, 1103)\n",
            "1 128 1270\n",
            "(128, 1270)\n",
            "1 128 389\n",
            "(128, 389)\n",
            "1 128 1270\n",
            "(128, 1270)\n",
            "1 128 694\n",
            "(128, 694)\n",
            "1 128 389\n",
            "(128, 389)\n",
            "1 128 1073\n",
            "(128, 1073)\n",
            "1 128 150\n",
            "(128, 150)\n",
            "1 128 2424\n",
            "(128, 2424)\n",
            "1 128 87\n",
            "(128, 87)\n",
            "1 128 1062\n",
            "(128, 1062)\n",
            "1 128 895\n",
            "(128, 895)\n",
            "1 128 478\n",
            "(128, 478)\n",
            "1 128 1927\n",
            "(128, 1927)\n",
            "1 128 385\n",
            "(128, 385)\n",
            "1 128 1446\n",
            "(128, 1446)\n",
            "1 128 1062\n",
            "(128, 1062)\n",
            "1 128 2117\n",
            "(128, 2117)\n",
            "1 128 1446\n",
            "(128, 1446)\n",
            "1 128 694\n",
            "(128, 694)\n",
            "1 128 2424\n",
            "(128, 2424)\n",
            "1 128 345\n",
            "(128, 345)\n",
            "1 128 294\n",
            "(128, 294)\n",
            "1 128 517\n",
            "(128, 517)\n",
            "1 128 30\n",
            "(128, 30)\n",
            "1 128 138\n",
            "(128, 138)\n",
            "1 128 201\n",
            "(128, 201)\n",
            "1 128 275\n",
            "(128, 275)\n",
            "1 128 45\n",
            "(128, 45)\n",
            "1 128 313\n",
            "(128, 313)\n",
            "1 128 58\n",
            "(128, 58)\n",
            "1 128 1653\n",
            "(128, 1653)\n",
            "1 128 66\n",
            "(128, 66)\n",
            "1 128 83\n",
            "(128, 83)\n",
            "1 128 36\n",
            "(128, 36)\n",
            "1 128 133\n",
            "(128, 133)\n",
            "1 128 122\n",
            "(128, 122)\n",
            "1 128 72\n",
            "(128, 72)\n",
            "1 128 110\n",
            "(128, 110)\n",
            "1 128 517\n",
            "(128, 517)\n",
            "1 128 96\n",
            "(128, 96)\n",
            "1 128 716\n",
            "(128, 716)\n",
            "1 128 121\n",
            "(128, 121)\n",
            "1 128 226\n",
            "(128, 226)\n",
            "1 128 517\n",
            "(128, 517)\n",
            "1 128 31\n",
            "(128, 31)\n",
            "1 128 181\n",
            "(128, 181)\n",
            "1 128 99\n",
            "(128, 99)\n",
            "1 128 369\n",
            "(128, 369)\n",
            "1 128 128\n",
            "(128, 128)\n",
            "1 128 71\n",
            "(128, 71)\n",
            "1 128 275\n",
            "(128, 275)\n",
            "1 128 853\n",
            "(128, 853)\n",
            "1 128 66\n",
            "(128, 66)\n",
            "1 128 921\n",
            "(128, 921)\n",
            "1 128 71\n",
            "(128, 71)\n",
            "1 128 1834\n",
            "(128, 1834)\n",
            "1 128 237\n",
            "(128, 237)\n",
            "1 128 83\n",
            "(128, 83)\n",
            "1 128 1491\n",
            "(128, 1491)\n",
            "1 128 186\n",
            "(128, 186)\n",
            "1 128 478\n",
            "(128, 478)\n",
            "1 128 127\n",
            "(128, 127)\n",
            "1 128 259\n",
            "(128, 259)\n",
            "1 128 96\n",
            "(128, 96)\n",
            "1 128 177\n",
            "(128, 177)\n",
            "1 128 226\n",
            "(128, 226)\n",
            "1 128 166\n",
            "(128, 166)\n",
            "1 128 517\n",
            "(128, 517)\n",
            "1 128 99\n",
            "(128, 99)\n",
            "1 128 1627\n",
            "(128, 1627)\n",
            "1 128 235\n",
            "(128, 235)\n",
            "1 128 181\n",
            "(128, 181)\n",
            "1 128 135\n",
            "(128, 135)\n",
            "1 128 166\n",
            "(128, 166)\n",
            "1 128 241\n",
            "(128, 241)\n",
            "1 128 491\n",
            "(128, 491)\n",
            "1 128 608\n",
            "(128, 608)\n",
            "1 128 93\n",
            "(128, 93)\n",
            "1 128 241\n",
            "(128, 241)\n",
            "1 128 472\n",
            "(128, 472)\n",
            "1 128 428\n",
            "(128, 428)\n",
            "1 128 301\n",
            "(128, 301)\n",
            "1 128 491\n",
            "(128, 491)\n",
            "1 128 79\n",
            "(128, 79)\n",
            "1 128 1254\n",
            "(128, 1254)\n",
            "1 128 316\n",
            "(128, 316)\n",
            "1 128 471\n",
            "(128, 471)\n",
            "1 128 101\n",
            "(128, 101)\n",
            "1 128 66\n",
            "(128, 66)\n",
            "1 128 235\n",
            "(128, 235)\n",
            "1 128 96\n",
            "(128, 96)\n",
            "1 128 130\n",
            "(128, 130)\n",
            "1 128 242\n",
            "(128, 242)\n",
            "1 128 355\n",
            "(128, 355)\n",
            "1 128 73\n",
            "(128, 73)\n",
            "1 128 442\n",
            "(128, 442)\n",
            "1 128 125\n",
            "(128, 125)\n",
            "1 128 294\n",
            "(128, 294)\n",
            "1 128 96\n",
            "(128, 96)\n",
            "1 128 69\n",
            "(128, 69)\n",
            "1 128 517\n",
            "(128, 517)\n",
            "1 128 70\n",
            "(128, 70)\n",
            "1 128 1653\n",
            "(128, 1653)\n",
            "1 128 39\n",
            "(128, 39)\n",
            "1 128 87\n",
            "(128, 87)\n",
            "1 128 441\n",
            "(128, 441)\n",
            "1 128 259\n",
            "(128, 259)\n",
            "1 128 398\n",
            "(128, 398)\n",
            "1 128 122\n",
            "(128, 122)\n",
            "1 128 128\n",
            "(128, 128)\n",
            "1 128 41\n",
            "(128, 41)\n",
            "1 128 139\n",
            "(128, 139)\n",
            "1 128 368\n",
            "(128, 368)\n",
            "1 128 87\n",
            "(128, 87)\n",
            "1 128 37\n",
            "(128, 37)\n",
            "1 128 259\n",
            "(128, 259)\n",
            "1 128 368\n",
            "(128, 368)\n",
            "1 128 259\n",
            "(128, 259)\n",
            "1 128 630\n",
            "(128, 630)\n",
            "1 128 118\n",
            "(128, 118)\n",
            "1 128 396\n",
            "(128, 396)\n",
            "1 128 1320\n",
            "(128, 1320)\n",
            "1 128 319\n",
            "(128, 319)\n",
            "1 128 148\n",
            "(128, 148)\n",
            "1 128 158\n",
            "(128, 158)\n",
            "1 128 100\n",
            "(128, 100)\n",
            "1 128 91\n",
            "(128, 91)\n",
            "1 128 121\n",
            "(128, 121)\n",
            "1 128 216\n",
            "(128, 216)\n",
            "1 128 140\n",
            "(128, 140)\n",
            "1 128 201\n",
            "(128, 201)\n",
            "1 128 565\n",
            "(128, 565)\n",
            "1 128 198\n",
            "(128, 198)\n",
            "1 128 205\n",
            "(128, 205)\n",
            "1 128 203\n",
            "(128, 203)\n",
            "1 128 340\n",
            "(128, 340)\n",
            "1 128 145\n",
            "(128, 145)\n",
            "1 128 152\n",
            "(128, 152)\n",
            "1 128 236\n",
            "(128, 236)\n",
            "1 128 95\n",
            "(128, 95)\n",
            "1 128 280\n",
            "(128, 280)\n",
            "1 128 301\n",
            "(128, 301)\n",
            "1 128 417\n",
            "(128, 417)\n",
            "1 128 197\n",
            "(128, 197)\n",
            "1 128 345\n",
            "(128, 345)\n",
            "1 128 1081\n",
            "(128, 1081)\n",
            "1 128 262\n",
            "(128, 262)\n",
            "1 128 60\n",
            "(128, 60)\n",
            "1 128 114\n",
            "(128, 114)\n",
            "1 128 368\n",
            "(128, 368)\n",
            "1 128 1320\n",
            "(128, 1320)\n",
            "1 128 210\n",
            "(128, 210)\n",
            "1 128 224\n",
            "(128, 224)\n",
            "1 128 268\n",
            "(128, 268)\n",
            "1 128 165\n",
            "(128, 165)\n",
            "1 128 1796\n",
            "(128, 1796)\n",
            "1 128 253\n",
            "(128, 253)\n",
            "1 128 1796\n",
            "(128, 1796)\n",
            "1 128 114\n",
            "(128, 114)\n",
            "1 128 280\n",
            "(128, 280)\n",
            "1 128 65\n",
            "(128, 65)\n",
            "1 128 265\n",
            "(128, 265)\n",
            "1 128 141\n",
            "(128, 141)\n",
            "1 128 219\n",
            "(128, 219)\n",
            "1 128 325\n",
            "(128, 325)\n",
            "1 128 67\n",
            "(128, 67)\n",
            "1 128 216\n",
            "(128, 216)\n",
            "1 128 262\n",
            "(128, 262)\n",
            "1 128 77\n",
            "(128, 77)\n",
            "1 128 130\n",
            "(128, 130)\n",
            "1 128 38\n",
            "(128, 38)\n",
            "1 128 797\n",
            "(128, 797)\n",
            "1 128 280\n",
            "(128, 280)\n",
            "1 128 95\n",
            "(128, 95)\n",
            "1 128 270\n",
            "(128, 270)\n",
            "1 128 776\n",
            "(128, 776)\n",
            "1 128 205\n",
            "(128, 205)\n",
            "1 128 114\n",
            "(128, 114)\n",
            "1 128 2403\n",
            "(128, 2403)\n",
            "1 128 145\n",
            "(128, 145)\n",
            "1 128 436\n",
            "(128, 436)\n",
            "1 128 95\n",
            "(128, 95)\n",
            "1 128 177\n",
            "(128, 177)\n",
            "1 128 270\n",
            "(128, 270)\n",
            "1 128 112\n",
            "(128, 112)\n",
            "1 128 62\n",
            "(128, 62)\n",
            "1 128 261\n",
            "(128, 261)\n",
            "1 128 125\n",
            "(128, 125)\n",
            "1 128 389\n",
            "(128, 389)\n",
            "1 128 252\n",
            "(128, 252)\n",
            "1 128 112\n",
            "(128, 112)\n",
            "1 128 95\n",
            "(128, 95)\n",
            "1 128 216\n",
            "(128, 216)\n",
            "1 128 148\n",
            "(128, 148)\n",
            "1 128 164\n",
            "(128, 164)\n",
            "1 128 484\n",
            "(128, 484)\n",
            "1 128 95\n",
            "(128, 95)\n",
            "1 128 270\n",
            "(128, 270)\n",
            "1 128 263\n",
            "(128, 263)\n",
            "1 128 216\n",
            "(128, 216)\n",
            "1 128 129\n",
            "(128, 129)\n",
            "1 128 417\n",
            "(128, 417)\n",
            "1 128 110\n",
            "(128, 110)\n",
            "1 128 1305\n",
            "(128, 1305)\n",
            "1 128 389\n",
            "(128, 389)\n",
            "1 128 271\n",
            "(128, 271)\n",
            "1 128 201\n",
            "(128, 201)\n",
            "1 128 270\n",
            "(128, 270)\n",
            "1 128 177\n",
            "(128, 177)\n",
            "1 128 110\n",
            "(128, 110)\n",
            "1 128 423\n",
            "(128, 423)\n",
            "1 128 389\n",
            "(128, 389)\n",
            "1 128 1305\n",
            "(128, 1305)\n",
            "1 128 175\n",
            "(128, 175)\n",
            "1 128 112\n",
            "(128, 112)\n",
            "1 128 228\n",
            "(128, 228)\n",
            "1 128 224\n",
            "(128, 224)\n",
            "1 128 1279\n",
            "(128, 1279)\n",
            "1 128 152\n",
            "(128, 152)\n",
            "1 128 203\n",
            "(128, 203)\n",
            "1 128 1111\n",
            "(128, 1111)\n",
            "1 128 666\n",
            "(128, 666)\n",
            "1 128 1203\n",
            "(128, 1203)\n",
            "1 128 646\n",
            "(128, 646)\n",
            "1 128 266\n",
            "(128, 266)\n",
            "1 128 778\n",
            "(128, 778)\n",
            "1 128 1103\n",
            "(128, 1103)\n",
            "1 128 1940\n",
            "(128, 1940)\n",
            "1 128 652\n",
            "(128, 652)\n",
            "1 128 769\n",
            "(128, 769)\n",
            "1 128 591\n",
            "(128, 591)\n",
            "1 128 766\n",
            "(128, 766)\n",
            "1 128 769\n",
            "(128, 769)\n",
            "1 128 102\n",
            "(128, 102)\n",
            "1 128 269\n",
            "(128, 269)\n",
            "1 128 1622\n",
            "(128, 1622)\n",
            "1 128 2057\n",
            "(128, 2057)\n",
            "1 128 237\n",
            "(128, 237)\n",
            "1 128 1387\n",
            "(128, 1387)\n",
            "1 128 710\n",
            "(128, 710)\n",
            "1 128 1940\n",
            "(128, 1940)\n",
            "1 128 1103\n",
            "(128, 1103)\n",
            "1 128 591\n",
            "(128, 591)\n",
            "1 128 1320\n",
            "(128, 1320)\n",
            "1 128 1387\n",
            "(128, 1387)\n",
            "1 128 1940\n",
            "(128, 1940)\n",
            "1 128 591\n",
            "(128, 591)\n",
            "1 128 1622\n",
            "(128, 1622)\n",
            "1 128 1333\n",
            "(128, 1333)\n",
            "1 128 666\n",
            "(128, 666)\n",
            "1 128 1555\n",
            "(128, 1555)\n",
            "1 128 179\n",
            "(128, 179)\n",
            "1 128 1103\n",
            "(128, 1103)\n",
            "1 128 237\n",
            "(128, 237)\n",
            "1 128 1387\n",
            "(128, 1387)\n",
            "1 128 259\n",
            "(128, 259)\n",
            "1 128 1940\n",
            "(128, 1940)\n",
            "1 128 591\n",
            "(128, 591)\n",
            "1 128 311\n",
            "(128, 311)\n",
            "1 128 1311\n",
            "(128, 1311)\n",
            "1 128 332\n",
            "(128, 332)\n",
            "1 128 769\n",
            "(128, 769)\n",
            "1 128 1103\n",
            "(128, 1103)\n",
            "1 128 1387\n",
            "(128, 1387)\n",
            "1 128 769\n",
            "(128, 769)\n",
            "1 128 669\n",
            "(128, 669)\n",
            "1 128 248\n",
            "(128, 248)\n",
            "1 128 1311\n",
            "(128, 1311)\n",
            "1 128 1940\n",
            "(128, 1940)\n",
            "1 128 259\n",
            "(128, 259)\n",
            "1 128 198\n",
            "(128, 198)\n",
            "1 128 769\n",
            "(128, 769)\n",
            "1 128 362\n",
            "(128, 362)\n",
            "1 128 783\n",
            "(128, 783)\n",
            "1 128 669\n",
            "(128, 669)\n",
            "1 128 102\n",
            "(128, 102)\n",
            "1 128 248\n",
            "(128, 248)\n",
            "1 128 591\n",
            "(128, 591)\n",
            "1 128 177\n",
            "(128, 177)\n",
            "1 128 2430\n",
            "(128, 2430)\n",
            "1 128 332\n",
            "(128, 332)\n",
            "1 128 1387\n",
            "(128, 1387)\n",
            "1 128 652\n",
            "(128, 652)\n",
            "1 128 669\n",
            "(128, 669)\n",
            "1 128 1555\n",
            "(128, 1555)\n",
            "1 128 179\n",
            "(128, 179)\n",
            "1 128 198\n",
            "(128, 198)\n",
            "1 128 372\n",
            "(128, 372)\n",
            "1 128 177\n",
            "(128, 177)\n",
            "1 128 179\n",
            "(128, 179)\n",
            "1 128 332\n",
            "(128, 332)\n",
            "1 128 1387\n",
            "(128, 1387)\n",
            "1 128 1103\n",
            "(128, 1103)\n",
            "1 128 332\n",
            "(128, 332)\n",
            "1 128 269\n",
            "(128, 269)\n",
            "1 128 198\n",
            "(128, 198)\n",
            "1 128 1387\n",
            "(128, 1387)\n",
            "1 128 1387\n",
            "(128, 1387)\n",
            "1 128 332\n",
            "(128, 332)\n",
            "1 128 1387\n",
            "(128, 1387)\n",
            "1 128 177\n",
            "(128, 177)\n",
            "1 128 1387\n",
            "(128, 1387)\n",
            "1 128 591\n",
            "(128, 591)\n",
            "1 128 1667\n",
            "(128, 1667)\n",
            "1 128 1791\n",
            "(128, 1791)\n",
            "1 128 1311\n",
            "(128, 1311)\n",
            "1 128 715\n",
            "(128, 715)\n",
            "1 128 259\n",
            "(128, 259)\n",
            "1 128 332\n",
            "(128, 332)\n",
            "1 128 171\n",
            "(128, 171)\n",
            "1 128 1791\n",
            "(128, 1791)\n",
            "1 128 198\n",
            "(128, 198)\n",
            "1 128 1103\n",
            "(128, 1103)\n",
            "1 128 372\n",
            "(128, 372)\n",
            "1 128 769\n",
            "(128, 769)\n",
            "1 128 1311\n",
            "(128, 1311)\n",
            "1 128 647\n",
            "(128, 647)\n",
            "1 128 766\n",
            "(128, 766)\n",
            "1 128 778\n",
            "(128, 778)\n",
            "1 128 591\n",
            "(128, 591)\n",
            "1 128 1311\n",
            "(128, 1311)\n",
            "1 128 1404\n",
            "(128, 1404)\n",
            "1 128 70\n",
            "(128, 70)\n",
            "1 128 59\n",
            "(128, 59)\n",
            "1 128 53\n",
            "(128, 53)\n",
            "1 128 96\n",
            "(128, 96)\n",
            "1 128 59\n",
            "(128, 59)\n",
            "1 128 1376\n",
            "(128, 1376)\n",
            "1 128 739\n",
            "(128, 739)\n",
            "1 128 57\n",
            "(128, 57)\n",
            "1 128 418\n",
            "(128, 418)\n",
            "1 128 2432\n",
            "(128, 2432)\n",
            "1 128 69\n",
            "(128, 69)\n",
            "1 128 115\n",
            "(128, 115)\n",
            "1 128 70\n",
            "(128, 70)\n",
            "1 128 288\n",
            "(128, 288)\n",
            "1 128 478\n",
            "(128, 478)\n",
            "1 128 60\n",
            "(128, 60)\n",
            "1 128 1422\n",
            "(128, 1422)\n",
            "1 128 1822\n",
            "(128, 1822)\n",
            "1 128 133\n",
            "(128, 133)\n",
            "1 128 121\n",
            "(128, 121)\n",
            "1 128 2428\n",
            "(128, 2428)\n",
            "1 128 126\n",
            "(128, 126)\n",
            "1 128 164\n",
            "(128, 164)\n",
            "1 128 1588\n",
            "(128, 1588)\n",
            "1 128 70\n",
            "(128, 70)\n",
            "1 128 1376\n",
            "(128, 1376)\n",
            "1 128 64\n",
            "(128, 64)\n",
            "1 128 982\n",
            "(128, 982)\n",
            "1 128 733\n",
            "(128, 733)\n",
            "1 128 59\n",
            "(128, 59)\n",
            "1 128 56\n",
            "(128, 56)\n",
            "1 128 59\n",
            "(128, 59)\n",
            "1 128 186\n",
            "(128, 186)\n",
            "1 128 899\n",
            "(128, 899)\n",
            "1 128 29\n",
            "(128, 29)\n",
            "1 128 120\n",
            "(128, 120)\n",
            "1 128 1374\n",
            "(128, 1374)\n",
            "1 128 1292\n",
            "(128, 1292)\n",
            "1 128 1560\n",
            "(128, 1560)\n",
            "1 128 739\n",
            "(128, 739)\n",
            "1 128 87\n",
            "(128, 87)\n",
            "1 128 57\n",
            "(128, 57)\n",
            "1 128 74\n",
            "(128, 74)\n",
            "1 128 70\n",
            "(128, 70)\n",
            "1 128 48\n",
            "(128, 48)\n",
            "1 128 208\n",
            "(128, 208)\n",
            "1 128 1560\n",
            "(128, 1560)\n",
            "1 128 78\n",
            "(128, 78)\n",
            "1 128 1310\n",
            "(128, 1310)\n",
            "1 128 767\n",
            "(128, 767)\n",
            "1 128 2240\n",
            "(128, 2240)\n",
            "1 128 196\n",
            "(128, 196)\n",
            "1 128 1558\n",
            "(128, 1558)\n",
            "1 128 126\n",
            "(128, 126)\n",
            "1 128 70\n",
            "(128, 70)\n",
            "1 128 1634\n",
            "(128, 1634)\n",
            "1 128 64\n",
            "(128, 64)\n",
            "1 128 59\n",
            "(128, 59)\n",
            "1 128 367\n",
            "(128, 367)\n",
            "1 128 130\n",
            "(128, 130)\n",
            "1 128 1558\n",
            "(128, 1558)\n",
            "1 128 780\n",
            "(128, 780)\n",
            "1 128 335\n",
            "(128, 335)\n",
            "1 128 130\n",
            "(128, 130)\n",
            "1 128 70\n",
            "(128, 70)\n",
            "1 128 164\n",
            "(128, 164)\n",
            "1 128 296\n",
            "(128, 296)\n",
            "1 128 70\n",
            "(128, 70)\n",
            "1 128 296\n",
            "(128, 296)\n",
            "1 128 164\n",
            "(128, 164)\n",
            "1 128 1588\n",
            "(128, 1588)\n",
            "1 128 335\n",
            "(128, 335)\n",
            "1 128 2428\n",
            "(128, 2428)\n",
            "1 128 335\n",
            "(128, 335)\n",
            "1 128 253\n",
            "(128, 253)\n",
            "1 128 57\n",
            "(128, 57)\n",
            "1 128 1733\n",
            "(128, 1733)\n",
            "1 128 367\n",
            "(128, 367)\n",
            "1 128 335\n",
            "(128, 335)\n",
            "1 128 1376\n",
            "(128, 1376)\n",
            "1 128 221\n",
            "(128, 221)\n",
            "1 128 1054\n",
            "(128, 1054)\n",
            "1 128 1353\n",
            "(128, 1353)\n",
            "1 128 1560\n",
            "(128, 1560)\n",
            "1 128 1132\n",
            "(128, 1132)\n",
            "1 128 1157\n",
            "(128, 1157)\n",
            "1 128 48\n",
            "(128, 48)\n",
            "1 128 49\n",
            "(128, 49)\n",
            "1 128 1376\n",
            "(128, 1376)\n",
            "1 128 69\n",
            "(128, 69)\n",
            "1 128 221\n",
            "(128, 221)\n",
            "1 128 574\n",
            "(128, 574)\n",
            "1 128 1404\n",
            "(128, 1404)\n",
            "1 128 2240\n",
            "(128, 2240)\n",
            "1 128 780\n",
            "(128, 780)\n",
            "1 128 70\n",
            "(128, 70)\n",
            "1 128 2428\n",
            "(128, 2428)\n",
            "1 128 93\n",
            "(128, 93)\n",
            "1 128 208\n",
            "(128, 208)\n",
            "1 128 213\n",
            "(128, 213)\n",
            "1 128 1459\n",
            "(128, 1459)\n",
            "1 128 279\n",
            "(128, 279)\n",
            "1 128 1345\n",
            "(128, 1345)\n",
            "1 128 183\n",
            "(128, 183)\n",
            "1 128 381\n",
            "(128, 381)\n",
            "1 128 293\n",
            "(128, 293)\n",
            "1 128 315\n",
            "(128, 315)\n",
            "1 128 213\n",
            "(128, 213)\n",
            "1 128 310\n",
            "(128, 310)\n",
            "1 128 214\n",
            "(128, 214)\n",
            "1 128 1734\n",
            "(128, 1734)\n",
            "1 128 270\n",
            "(128, 270)\n",
            "1 128 213\n",
            "(128, 213)\n",
            "1 128 214\n",
            "(128, 214)\n",
            "1 128 373\n",
            "(128, 373)\n",
            "1 128 119\n",
            "(128, 119)\n",
            "1 128 459\n",
            "(128, 459)\n",
            "1 128 214\n",
            "(128, 214)\n",
            "1 128 2454\n",
            "(128, 2454)\n",
            "1 128 487\n",
            "(128, 487)\n",
            "1 128 459\n",
            "(128, 459)\n",
            "1 128 1120\n",
            "(128, 1120)\n",
            "1 128 373\n",
            "(128, 373)\n",
            "1 128 1345\n",
            "(128, 1345)\n",
            "1 128 345\n",
            "(128, 345)\n",
            "1 128 959\n",
            "(128, 959)\n",
            "1 128 71\n",
            "(128, 71)\n",
            "1 128 409\n",
            "(128, 409)\n",
            "1 128 1550\n",
            "(128, 1550)\n",
            "1 128 1704\n",
            "(128, 1704)\n",
            "1 128 208\n",
            "(128, 208)\n",
            "1 128 459\n",
            "(128, 459)\n",
            "1 128 164\n",
            "(128, 164)\n",
            "1 128 701\n",
            "(128, 701)\n",
            "1 128 340\n",
            "(128, 340)\n",
            "1 128 131\n",
            "(128, 131)\n",
            "1 128 278\n",
            "(128, 278)\n",
            "1 128 166\n",
            "(128, 166)\n",
            "1 128 321\n",
            "(128, 321)\n",
            "1 128 315\n",
            "(128, 315)\n",
            "1 128 80\n",
            "(128, 80)\n",
            "1 128 164\n",
            "(128, 164)\n",
            "1 128 1120\n",
            "(128, 1120)\n",
            "1 128 247\n",
            "(128, 247)\n",
            "1 128 240\n",
            "(128, 240)\n",
            "1 128 87\n",
            "(128, 87)\n",
            "1 128 71\n",
            "(128, 71)\n",
            "1 128 256\n",
            "(128, 256)\n",
            "1 128 666\n",
            "(128, 666)\n",
            "1 128 108\n",
            "(128, 108)\n",
            "1 128 108\n",
            "(128, 108)\n",
            "1 128 62\n",
            "(128, 62)\n",
            "1 128 178\n",
            "(128, 178)\n",
            "1 128 108\n",
            "(128, 108)\n",
            "1 128 1704\n",
            "(128, 1704)\n",
            "1 128 87\n",
            "(128, 87)\n",
            "1 128 959\n",
            "(128, 959)\n",
            "1 128 107\n",
            "(128, 107)\n",
            "1 128 1261\n",
            "(128, 1261)\n",
            "1 128 71\n",
            "(128, 71)\n",
            "1 128 1234\n",
            "(128, 1234)\n",
            "1 128 1120\n",
            "(128, 1120)\n",
            "1 128 214\n",
            "(128, 214)\n",
            "1 128 222\n",
            "(128, 222)\n",
            "1 128 71\n",
            "(128, 71)\n",
            "1 128 538\n",
            "(128, 538)\n",
            "1 128 71\n",
            "(128, 71)\n",
            "1 128 538\n",
            "(128, 538)\n",
            "1 128 2454\n",
            "(128, 2454)\n",
            "1 128 1550\n",
            "(128, 1550)\n",
            "1 128 87\n",
            "(128, 87)\n",
            "1 128 321\n",
            "(128, 321)\n",
            "1 128 1459\n",
            "(128, 1459)\n",
            "1 128 65\n",
            "(128, 65)\n",
            "1 128 381\n",
            "(128, 381)\n",
            "1 128 824\n",
            "(128, 824)\n",
            "1 128 487\n",
            "(128, 487)\n",
            "1 128 36\n",
            "(128, 36)\n",
            "1 128 1704\n",
            "(128, 1704)\n",
            "1 128 107\n",
            "(128, 107)\n",
            "1 128 1511\n",
            "(128, 1511)\n",
            "1 128 71\n",
            "(128, 71)\n",
            "1 128 1550\n",
            "(128, 1550)\n",
            "1 128 113\n",
            "(128, 113)\n",
            "1 128 258\n",
            "(128, 258)\n",
            "1 128 526\n",
            "(128, 526)\n",
            "1 128 213\n",
            "(128, 213)\n",
            "1 128 247\n",
            "(128, 247)\n",
            "1 128 1550\n",
            "(128, 1550)\n",
            "1 128 214\n",
            "(128, 214)\n",
            "1 128 315\n",
            "(128, 315)\n",
            "1 128 36\n",
            "(128, 36)\n",
            "1 128 240\n",
            "(128, 240)\n",
            "1 128 152\n",
            "(128, 152)\n",
            "1 128 71\n",
            "(128, 71)\n",
            "1 128 213\n",
            "(128, 213)\n",
            "1 128 178\n",
            "(128, 178)\n",
            "1 128 213\n",
            "(128, 213)\n",
            "1 128 459\n",
            "(128, 459)\n",
            "1 128 544\n",
            "(128, 544)\n",
            "1 128 387\n",
            "(128, 387)\n",
            "1 128 242\n",
            "(128, 242)\n",
            "1 128 544\n",
            "(128, 544)\n",
            "1 128 161\n",
            "(128, 161)\n",
            "1 128 1771\n",
            "(128, 1771)\n",
            "1 128 417\n",
            "(128, 417)\n",
            "1 128 205\n",
            "(128, 205)\n",
            "1 128 194\n",
            "(128, 194)\n",
            "1 128 201\n",
            "(128, 201)\n",
            "1 128 293\n",
            "(128, 293)\n",
            "1 128 387\n",
            "(128, 387)\n",
            "1 128 320\n",
            "(128, 320)\n",
            "1 128 260\n",
            "(128, 260)\n",
            "1 128 613\n",
            "(128, 613)\n",
            "1 128 672\n",
            "(128, 672)\n",
            "1 128 247\n",
            "(128, 247)\n",
            "1 128 161\n",
            "(128, 161)\n",
            "1 128 1849\n",
            "(128, 1849)\n",
            "1 128 194\n",
            "(128, 194)\n",
            "1 128 210\n",
            "(128, 210)\n",
            "1 128 232\n",
            "(128, 232)\n",
            "1 128 672\n",
            "(128, 672)\n",
            "1 128 1809\n",
            "(128, 1809)\n",
            "1 128 194\n",
            "(128, 194)\n",
            "1 128 1240\n",
            "(128, 1240)\n",
            "1 128 205\n",
            "(128, 205)\n",
            "1 128 364\n",
            "(128, 364)\n",
            "1 128 431\n",
            "(128, 431)\n",
            "1 128 646\n",
            "(128, 646)\n",
            "1 128 1240\n",
            "(128, 1240)\n",
            "1 128 268\n",
            "(128, 268)\n",
            "1 128 320\n",
            "(128, 320)\n",
            "1 128 1809\n",
            "(128, 1809)\n",
            "1 128 672\n",
            "(128, 672)\n",
            "1 128 194\n",
            "(128, 194)\n",
            "1 128 194\n",
            "(128, 194)\n",
            "1 128 196\n",
            "(128, 196)\n",
            "1 128 1046\n",
            "(128, 1046)\n",
            "1 128 581\n",
            "(128, 581)\n",
            "1 128 320\n",
            "(128, 320)\n",
            "1 128 201\n",
            "(128, 201)\n",
            "1 128 892\n",
            "(128, 892)\n",
            "1 128 320\n",
            "(128, 320)\n",
            "1 128 2379\n",
            "(128, 2379)\n",
            "1 128 320\n",
            "(128, 320)\n",
            "1 128 1809\n",
            "(128, 1809)\n",
            "1 128 581\n",
            "(128, 581)\n",
            "1 128 1857\n",
            "(128, 1857)\n",
            "1 128 646\n",
            "(128, 646)\n",
            "1 128 672\n",
            "(128, 672)\n",
            "1 128 201\n",
            "(128, 201)\n",
            "1 128 88\n",
            "(128, 88)\n",
            "1 128 1809\n",
            "(128, 1809)\n",
            "1 128 1857\n",
            "(128, 1857)\n",
            "1 128 880\n",
            "(128, 880)\n",
            "1 128 205\n",
            "(128, 205)\n",
            "1 128 1046\n",
            "(128, 1046)\n",
            "1 128 1809\n",
            "(128, 1809)\n",
            "1 128 210\n",
            "(128, 210)\n",
            "1 128 364\n",
            "(128, 364)\n",
            "1 128 581\n",
            "(128, 581)\n",
            "1 128 206\n",
            "(128, 206)\n",
            "1 128 880\n",
            "(128, 880)\n",
            "1 128 201\n",
            "(128, 201)\n",
            "1 128 1809\n",
            "(128, 1809)\n",
            "1 128 1809\n",
            "(128, 1809)\n",
            "1 128 121\n",
            "(128, 121)\n",
            "1 128 1809\n",
            "(128, 1809)\n",
            "1 128 653\n",
            "(128, 653)\n",
            "1 128 892\n",
            "(128, 892)\n",
            "1 128 195\n",
            "(128, 195)\n",
            "1 128 498\n",
            "(128, 498)\n",
            "1 128 210\n",
            "(128, 210)\n",
            "1 128 293\n",
            "(128, 293)\n",
            "1 128 80\n",
            "(128, 80)\n",
            "1 128 315\n",
            "(128, 315)\n",
            "1 128 591\n",
            "(128, 591)\n",
            "1 128 718\n",
            "(128, 718)\n",
            "1 128 194\n",
            "(128, 194)\n",
            "1 128 194\n",
            "(128, 194)\n",
            "1 128 880\n",
            "(128, 880)\n",
            "1 128 1809\n",
            "(128, 1809)\n",
            "1 128 210\n",
            "(128, 210)\n",
            "1 128 201\n",
            "(128, 201)\n",
            "1 128 1809\n",
            "(128, 1809)\n",
            "1 128 205\n",
            "(128, 205)\n",
            "1 128 892\n",
            "(128, 892)\n",
            "1 128 880\n",
            "(128, 880)\n",
            "1 128 1004\n",
            "(128, 1004)\n",
            "1 128 1240\n",
            "(128, 1240)\n",
            "1 128 672\n",
            "(128, 672)\n",
            "1 128 1538\n",
            "(128, 1538)\n",
            "1 128 121\n",
            "(128, 121)\n",
            "1 128 880\n",
            "(128, 880)\n",
            "1 128 655\n",
            "(128, 655)\n",
            "1 128 195\n",
            "(128, 195)\n",
            "1 128 2379\n",
            "(128, 2379)\n",
            "1 128 1240\n",
            "(128, 1240)\n",
            "1 128 320\n",
            "(128, 320)\n",
            "1 128 688\n",
            "(128, 688)\n",
            "1 128 2561\n",
            "(128, 2561)\n",
            "1 128 46\n",
            "(128, 46)\n",
            "1 128 809\n",
            "(128, 809)\n",
            "1 128 545\n",
            "(128, 545)\n",
            "1 128 583\n",
            "(128, 583)\n",
            "1 128 162\n",
            "(128, 162)\n",
            "1 128 2240\n",
            "(128, 2240)\n",
            "1 128 784\n",
            "(128, 784)\n",
            "1 128 842\n",
            "(128, 842)\n",
            "1 128 1503\n",
            "(128, 1503)\n",
            "1 128 669\n",
            "(128, 669)\n",
            "1 128 543\n",
            "(128, 543)\n",
            "1 128 1193\n",
            "(128, 1193)\n",
            "1 128 38\n",
            "(128, 38)\n",
            "1 128 303\n",
            "(128, 303)\n",
            "1 128 209\n",
            "(128, 209)\n",
            "1 128 598\n",
            "(128, 598)\n",
            "1 128 842\n",
            "(128, 842)\n",
            "1 128 855\n",
            "(128, 855)\n",
            "1 128 557\n",
            "(128, 557)\n",
            "1 128 594\n",
            "(128, 594)\n",
            "1 128 573\n",
            "(128, 573)\n",
            "1 128 59\n",
            "(128, 59)\n",
            "1 128 502\n",
            "(128, 502)\n",
            "1 128 68\n",
            "(128, 68)\n",
            "1 128 704\n",
            "(128, 704)\n",
            "1 128 669\n",
            "(128, 669)\n",
            "1 128 2561\n",
            "(128, 2561)\n",
            "1 128 623\n",
            "(128, 623)\n",
            "1 128 80\n",
            "(128, 80)\n",
            "1 128 179\n",
            "(128, 179)\n",
            "1 128 464\n",
            "(128, 464)\n",
            "1 128 295\n",
            "(128, 295)\n",
            "1 128 751\n",
            "(128, 751)\n",
            "1 128 713\n",
            "(128, 713)\n",
            "1 128 797\n",
            "(128, 797)\n",
            "1 128 43\n",
            "(128, 43)\n",
            "1 128 60\n",
            "(128, 60)\n",
            "1 128 409\n",
            "(128, 409)\n",
            "1 128 264\n",
            "(128, 264)\n",
            "1 128 53\n",
            "(128, 53)\n",
            "1 128 414\n",
            "(128, 414)\n",
            "1 128 603\n",
            "(128, 603)\n",
            "1 128 699\n",
            "(128, 699)\n",
            "1 128 385\n",
            "(128, 385)\n",
            "1 128 65\n",
            "(128, 65)\n",
            "1 128 138\n",
            "(128, 138)\n",
            "1 128 217\n",
            "(128, 217)\n",
            "1 128 598\n",
            "(128, 598)\n",
            "1 128 94\n",
            "(128, 94)\n",
            "1 128 64\n",
            "(128, 64)\n",
            "1 128 572\n",
            "(128, 572)\n",
            "1 128 37\n",
            "(128, 37)\n",
            "1 128 142\n",
            "(128, 142)\n",
            "1 128 348\n",
            "(128, 348)\n",
            "1 128 1579\n",
            "(128, 1579)\n",
            "1 128 130\n",
            "(128, 130)\n",
            "1 128 566\n",
            "(128, 566)\n",
            "1 128 856\n",
            "(128, 856)\n",
            "1 128 696\n",
            "(128, 696)\n",
            "1 128 328\n",
            "(128, 328)\n",
            "1 128 53\n",
            "(128, 53)\n",
            "1 128 685\n",
            "(128, 685)\n",
            "1 128 806\n",
            "(128, 806)\n",
            "1 128 842\n",
            "(128, 842)\n",
            "1 128 589\n",
            "(128, 589)\n",
            "1 128 342\n",
            "(128, 342)\n",
            "1 128 803\n",
            "(128, 803)\n",
            "1 128 651\n",
            "(128, 651)\n",
            "1 128 52\n",
            "(128, 52)\n",
            "1 128 392\n",
            "(128, 392)\n",
            "1 128 562\n",
            "(128, 562)\n",
            "1 128 80\n",
            "(128, 80)\n",
            "1 128 237\n",
            "(128, 237)\n",
            "1 128 663\n",
            "(128, 663)\n",
            "1 128 397\n",
            "(128, 397)\n",
            "1 128 706\n",
            "(128, 706)\n",
            "1 128 143\n",
            "(128, 143)\n",
            "1 128 341\n",
            "(128, 341)\n",
            "1 128 64\n",
            "(128, 64)\n",
            "1 128 314\n",
            "(128, 314)\n",
            "1 128 244\n",
            "(128, 244)\n",
            "1 128 464\n",
            "(128, 464)\n",
            "1 128 484\n",
            "(128, 484)\n",
            "1 128 598\n",
            "(128, 598)\n",
            "1 128 610\n",
            "(128, 610)\n",
            "1 128 582\n",
            "(128, 582)\n",
            "1 128 34\n",
            "(128, 34)\n",
            "1 128 244\n",
            "(128, 244)\n",
            "1 128 573\n",
            "(128, 573)\n",
            "1 128 807\n",
            "(128, 807)\n",
            "1 128 160\n",
            "(128, 160)\n",
            "1 128 473\n",
            "(128, 473)\n",
            "1 128 256\n",
            "(128, 256)\n",
            "1 128 374\n",
            "(128, 374)\n",
            "1 128 812\n",
            "(128, 812)\n",
            "1 128 201\n",
            "(128, 201)\n",
            "1 128 734\n",
            "(128, 734)\n",
            "1 128 228\n",
            "(128, 228)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The data provided has constant frequency scale in spectrogram.\n",
        "# But, the duration(time) is different for all the provided samples.\n",
        "# Hence, it is necessary to pad the data\n",
        "\n",
        "# get the max_length of spectrograms in the time axis\n",
        "max_duration=0\n",
        "for spec in mel_spectrograms:\n",
        "  m,n=spec.shape\n",
        "  if max_duration<n:\n",
        "      max_duration=n\n",
        "\n",
        "# add padding in the given .npy files\n",
        "features=[]\n",
        "for spec in mel_spectrograms:\n",
        "  mat=numpy.pad(spec, [(0, 0), (0, max_duration-spec[0].size)], mode='constant', constant_values=0)\n",
        "  mat=mat.reshape((mat.shape[0], mat.shape[1], 1))\n",
        "  features.append(mat)"
      ],
      "metadata": {
        "id": "C3a9oLij55tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert features list into numpy.ndarray type\n",
        "features=numpy.array(features)"
      ],
      "metadata": {
        "id": "grQIczgJbaO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['label'].describe()"
      ],
      "metadata": {
        "id": "Myz2C6Fu6VKK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5e5edec-7fca-4b28-b11e-1daa9cff1c10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count     1000\n",
              "unique      10\n",
              "top       Bark\n",
              "freq       100\n",
              "Name: label, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# need to convert training data into tensor datatype\n",
        "i=0\n",
        "for _ in features:\n",
        "    features[i]= tf.convert_to_tensor(features[i])\n",
        "    i=i+1"
      ],
      "metadata": {
        "id": "xGcaW9gT6lZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Splitting Dataset into training and validation**"
      ],
      "metadata": {
        "id": "HUXaGUdhdGc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=features\n",
        "y=data['label']\n",
        "\n",
        "# used 'random_state' of 40 while splitting to get the balanced split of data \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40, shuffle=\"true\")"
      ],
      "metadata": {
        "id": "ZLjVti4_6t3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the count of classes present in y_test\n",
        "print(type(y_test))\n",
        "val_label=pd.Series(list(y_test))\n",
        "val_label.value_counts()"
      ],
      "metadata": {
        "id": "Vb7FX8HUdcjT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f883c784-8eba-4c2c-8641-d99caf0b624f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Bark                                     22\n",
              "Walk_and_footsteps                       22\n",
              "Doorbell                                 22\n",
              "Crying_and_sobbing                       21\n",
              "Siren                                    20\n",
              "Knock                                    20\n",
              "Vehicle_horn_and_car_horn_and_honking    20\n",
              "Microwave_oven                           19\n",
              "Shatter                                  17\n",
              "Meow                                     17\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Convert label data (y_train & y_test) into 'one-hot vector' format**"
      ],
      "metadata": {
        "id": "_1O1vPt9eisG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in y_train:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcqw3V2lJnqA",
        "outputId": "8d33e009-3c3b-4baf-8bcb-4d604a319807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Walk_and_footsteps\n",
            "Meow\n",
            "Bark\n",
            "Meow\n",
            "Shatter\n",
            "Crying_and_sobbing\n",
            "Shatter\n",
            "Doorbell\n",
            "Crying_and_sobbing\n",
            "Walk_and_footsteps\n",
            "Shatter\n",
            "Crying_and_sobbing\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Meow\n",
            "Crying_and_sobbing\n",
            "Doorbell\n",
            "Meow\n",
            "Knock\n",
            "Knock\n",
            "Meow\n",
            "Bark\n",
            "Shatter\n",
            "Crying_and_sobbing\n",
            "Doorbell\n",
            "Microwave_oven\n",
            "Shatter\n",
            "Knock\n",
            "Microwave_oven\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Siren\n",
            "Shatter\n",
            "Bark\n",
            "Microwave_oven\n",
            "Walk_and_footsteps\n",
            "Walk_and_footsteps\n",
            "Doorbell\n",
            "Bark\n",
            "Crying_and_sobbing\n",
            "Bark\n",
            "Walk_and_footsteps\n",
            "Microwave_oven\n",
            "Knock\n",
            "Doorbell\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Doorbell\n",
            "Meow\n",
            "Shatter\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Meow\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Microwave_oven\n",
            "Shatter\n",
            "Siren\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Shatter\n",
            "Walk_and_footsteps\n",
            "Meow\n",
            "Crying_and_sobbing\n",
            "Knock\n",
            "Doorbell\n",
            "Siren\n",
            "Shatter\n",
            "Knock\n",
            "Walk_and_footsteps\n",
            "Walk_and_footsteps\n",
            "Doorbell\n",
            "Crying_and_sobbing\n",
            "Meow\n",
            "Shatter\n",
            "Shatter\n",
            "Meow\n",
            "Doorbell\n",
            "Walk_and_footsteps\n",
            "Doorbell\n",
            "Doorbell\n",
            "Knock\n",
            "Meow\n",
            "Knock\n",
            "Shatter\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Microwave_oven\n",
            "Siren\n",
            "Siren\n",
            "Shatter\n",
            "Siren\n",
            "Crying_and_sobbing\n",
            "Meow\n",
            "Knock\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Shatter\n",
            "Bark\n",
            "Meow\n",
            "Meow\n",
            "Siren\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Doorbell\n",
            "Knock\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Bark\n",
            "Meow\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Microwave_oven\n",
            "Meow\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Doorbell\n",
            "Meow\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Meow\n",
            "Shatter\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Shatter\n",
            "Siren\n",
            "Walk_and_footsteps\n",
            "Doorbell\n",
            "Microwave_oven\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Crying_and_sobbing\n",
            "Microwave_oven\n",
            "Shatter\n",
            "Microwave_oven\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Doorbell\n",
            "Crying_and_sobbing\n",
            "Meow\n",
            "Crying_and_sobbing\n",
            "Siren\n",
            "Shatter\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Crying_and_sobbing\n",
            "Crying_and_sobbing\n",
            "Microwave_oven\n",
            "Siren\n",
            "Shatter\n",
            "Shatter\n",
            "Doorbell\n",
            "Meow\n",
            "Shatter\n",
            "Walk_and_footsteps\n",
            "Meow\n",
            "Meow\n",
            "Walk_and_footsteps\n",
            "Walk_and_footsteps\n",
            "Meow\n",
            "Bark\n",
            "Walk_and_footsteps\n",
            "Bark\n",
            "Bark\n",
            "Crying_and_sobbing\n",
            "Siren\n",
            "Crying_and_sobbing\n",
            "Shatter\n",
            "Meow\n",
            "Bark\n",
            "Walk_and_footsteps\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Walk_and_footsteps\n",
            "Doorbell\n",
            "Knock\n",
            "Siren\n",
            "Walk_and_footsteps\n",
            "Meow\n",
            "Shatter\n",
            "Microwave_oven\n",
            "Meow\n",
            "Doorbell\n",
            "Meow\n",
            "Knock\n",
            "Bark\n",
            "Crying_and_sobbing\n",
            "Knock\n",
            "Siren\n",
            "Meow\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Siren\n",
            "Crying_and_sobbing\n",
            "Knock\n",
            "Doorbell\n",
            "Crying_and_sobbing\n",
            "Siren\n",
            "Shatter\n",
            "Meow\n",
            "Shatter\n",
            "Doorbell\n",
            "Walk_and_footsteps\n",
            "Shatter\n",
            "Walk_and_footsteps\n",
            "Walk_and_footsteps\n",
            "Microwave_oven\n",
            "Shatter\n",
            "Meow\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Crying_and_sobbing\n",
            "Walk_and_footsteps\n",
            "Knock\n",
            "Siren\n",
            "Knock\n",
            "Shatter\n",
            "Shatter\n",
            "Microwave_oven\n",
            "Doorbell\n",
            "Knock\n",
            "Shatter\n",
            "Walk_and_footsteps\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Siren\n",
            "Knock\n",
            "Meow\n",
            "Bark\n",
            "Meow\n",
            "Knock\n",
            "Siren\n",
            "Meow\n",
            "Shatter\n",
            "Crying_and_sobbing\n",
            "Walk_and_footsteps\n",
            "Microwave_oven\n",
            "Shatter\n",
            "Knock\n",
            "Microwave_oven\n",
            "Microwave_oven\n",
            "Bark\n",
            "Doorbell\n",
            "Siren\n",
            "Bark\n",
            "Shatter\n",
            "Bark\n",
            "Bark\n",
            "Knock\n",
            "Walk_and_footsteps\n",
            "Bark\n",
            "Microwave_oven\n",
            "Knock\n",
            "Microwave_oven\n",
            "Bark\n",
            "Walk_and_footsteps\n",
            "Walk_and_footsteps\n",
            "Knock\n",
            "Bark\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Meow\n",
            "Knock\n",
            "Meow\n",
            "Knock\n",
            "Microwave_oven\n",
            "Siren\n",
            "Siren\n",
            "Bark\n",
            "Meow\n",
            "Doorbell\n",
            "Meow\n",
            "Doorbell\n",
            "Bark\n",
            "Meow\n",
            "Knock\n",
            "Meow\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Shatter\n",
            "Shatter\n",
            "Meow\n",
            "Microwave_oven\n",
            "Shatter\n",
            "Knock\n",
            "Siren\n",
            "Siren\n",
            "Knock\n",
            "Crying_and_sobbing\n",
            "Bark\n",
            "Microwave_oven\n",
            "Siren\n",
            "Bark\n",
            "Siren\n",
            "Siren\n",
            "Siren\n",
            "Shatter\n",
            "Microwave_oven\n",
            "Meow\n",
            "Siren\n",
            "Bark\n",
            "Siren\n",
            "Bark\n",
            "Crying_and_sobbing\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Siren\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Microwave_oven\n",
            "Knock\n",
            "Doorbell\n",
            "Siren\n",
            "Meow\n",
            "Meow\n",
            "Walk_and_footsteps\n",
            "Crying_and_sobbing\n",
            "Siren\n",
            "Microwave_oven\n",
            "Bark\n",
            "Shatter\n",
            "Shatter\n",
            "Siren\n",
            "Knock\n",
            "Siren\n",
            "Doorbell\n",
            "Doorbell\n",
            "Microwave_oven\n",
            "Shatter\n",
            "Siren\n",
            "Knock\n",
            "Bark\n",
            "Bark\n",
            "Bark\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Microwave_oven\n",
            "Walk_and_footsteps\n",
            "Meow\n",
            "Meow\n",
            "Siren\n",
            "Meow\n",
            "Shatter\n",
            "Knock\n",
            "Bark\n",
            "Bark\n",
            "Crying_and_sobbing\n",
            "Meow\n",
            "Shatter\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Knock\n",
            "Bark\n",
            "Microwave_oven\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Knock\n",
            "Walk_and_footsteps\n",
            "Microwave_oven\n",
            "Shatter\n",
            "Microwave_oven\n",
            "Doorbell\n",
            "Microwave_oven\n",
            "Doorbell\n",
            "Walk_and_footsteps\n",
            "Knock\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Doorbell\n",
            "Walk_and_footsteps\n",
            "Siren\n",
            "Shatter\n",
            "Shatter\n",
            "Microwave_oven\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Bark\n",
            "Doorbell\n",
            "Crying_and_sobbing\n",
            "Walk_and_footsteps\n",
            "Knock\n",
            "Walk_and_footsteps\n",
            "Microwave_oven\n",
            "Meow\n",
            "Siren\n",
            "Shatter\n",
            "Bark\n",
            "Meow\n",
            "Shatter\n",
            "Crying_and_sobbing\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Crying_and_sobbing\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Knock\n",
            "Crying_and_sobbing\n",
            "Crying_and_sobbing\n",
            "Knock\n",
            "Crying_and_sobbing\n",
            "Doorbell\n",
            "Doorbell\n",
            "Siren\n",
            "Shatter\n",
            "Walk_and_footsteps\n",
            "Crying_and_sobbing\n",
            "Knock\n",
            "Doorbell\n",
            "Siren\n",
            "Walk_and_footsteps\n",
            "Meow\n",
            "Siren\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Microwave_oven\n",
            "Crying_and_sobbing\n",
            "Bark\n",
            "Walk_and_footsteps\n",
            "Shatter\n",
            "Bark\n",
            "Knock\n",
            "Walk_and_footsteps\n",
            "Microwave_oven\n",
            "Meow\n",
            "Shatter\n",
            "Bark\n",
            "Doorbell\n",
            "Knock\n",
            "Meow\n",
            "Microwave_oven\n",
            "Crying_and_sobbing\n",
            "Crying_and_sobbing\n",
            "Doorbell\n",
            "Knock\n",
            "Siren\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Knock\n",
            "Walk_and_footsteps\n",
            "Walk_and_footsteps\n",
            "Doorbell\n",
            "Doorbell\n",
            "Crying_and_sobbing\n",
            "Bark\n",
            "Bark\n",
            "Shatter\n",
            "Knock\n",
            "Microwave_oven\n",
            "Microwave_oven\n",
            "Crying_and_sobbing\n",
            "Meow\n",
            "Microwave_oven\n",
            "Bark\n",
            "Microwave_oven\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Meow\n",
            "Crying_and_sobbing\n",
            "Bark\n",
            "Meow\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Bark\n",
            "Microwave_oven\n",
            "Bark\n",
            "Bark\n",
            "Crying_and_sobbing\n",
            "Microwave_oven\n",
            "Meow\n",
            "Shatter\n",
            "Knock\n",
            "Shatter\n",
            "Crying_and_sobbing\n",
            "Walk_and_footsteps\n",
            "Shatter\n",
            "Knock\n",
            "Doorbell\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Crying_and_sobbing\n",
            "Knock\n",
            "Shatter\n",
            "Siren\n",
            "Knock\n",
            "Crying_and_sobbing\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Crying_and_sobbing\n",
            "Doorbell\n",
            "Shatter\n",
            "Doorbell\n",
            "Microwave_oven\n",
            "Siren\n",
            "Doorbell\n",
            "Knock\n",
            "Walk_and_footsteps\n",
            "Knock\n",
            "Microwave_oven\n",
            "Doorbell\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Doorbell\n",
            "Microwave_oven\n",
            "Crying_and_sobbing\n",
            "Siren\n",
            "Shatter\n",
            "Bark\n",
            "Meow\n",
            "Bark\n",
            "Bark\n",
            "Meow\n",
            "Doorbell\n",
            "Shatter\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Siren\n",
            "Knock\n",
            "Doorbell\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Walk_and_footsteps\n",
            "Meow\n",
            "Meow\n",
            "Knock\n",
            "Walk_and_footsteps\n",
            "Knock\n",
            "Crying_and_sobbing\n",
            "Doorbell\n",
            "Microwave_oven\n",
            "Crying_and_sobbing\n",
            "Walk_and_footsteps\n",
            "Microwave_oven\n",
            "Crying_and_sobbing\n",
            "Microwave_oven\n",
            "Doorbell\n",
            "Bark\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Knock\n",
            "Microwave_oven\n",
            "Bark\n",
            "Siren\n",
            "Bark\n",
            "Doorbell\n",
            "Bark\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Doorbell\n",
            "Bark\n",
            "Shatter\n",
            "Knock\n",
            "Siren\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Crying_and_sobbing\n",
            "Knock\n",
            "Shatter\n",
            "Microwave_oven\n",
            "Knock\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Knock\n",
            "Microwave_oven\n",
            "Doorbell\n",
            "Walk_and_footsteps\n",
            "Meow\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Microwave_oven\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Bark\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Doorbell\n",
            "Siren\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Shatter\n",
            "Microwave_oven\n",
            "Doorbell\n",
            "Bark\n",
            "Crying_and_sobbing\n",
            "Bark\n",
            "Siren\n",
            "Siren\n",
            "Knock\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Crying_and_sobbing\n",
            "Doorbell\n",
            "Siren\n",
            "Crying_and_sobbing\n",
            "Siren\n",
            "Doorbell\n",
            "Walk_and_footsteps\n",
            "Meow\n",
            "Bark\n",
            "Walk_and_footsteps\n",
            "Doorbell\n",
            "Walk_and_footsteps\n",
            "Crying_and_sobbing\n",
            "Microwave_oven\n",
            "Microwave_oven\n",
            "Bark\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Walk_and_footsteps\n",
            "Meow\n",
            "Knock\n",
            "Doorbell\n",
            "Meow\n",
            "Knock\n",
            "Siren\n",
            "Microwave_oven\n",
            "Knock\n",
            "Doorbell\n",
            "Walk_and_footsteps\n",
            "Knock\n",
            "Bark\n",
            "Siren\n",
            "Knock\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Walk_and_footsteps\n",
            "Doorbell\n",
            "Microwave_oven\n",
            "Microwave_oven\n",
            "Doorbell\n",
            "Crying_and_sobbing\n",
            "Meow\n",
            "Crying_and_sobbing\n",
            "Microwave_oven\n",
            "Bark\n",
            "Microwave_oven\n",
            "Crying_and_sobbing\n",
            "Doorbell\n",
            "Siren\n",
            "Siren\n",
            "Knock\n",
            "Doorbell\n",
            "Shatter\n",
            "Crying_and_sobbing\n",
            "Knock\n",
            "Knock\n",
            "Siren\n",
            "Bark\n",
            "Crying_and_sobbing\n",
            "Shatter\n",
            "Walk_and_footsteps\n",
            "Siren\n",
            "Siren\n",
            "Meow\n",
            "Walk_and_footsteps\n",
            "Microwave_oven\n",
            "Walk_and_footsteps\n",
            "Siren\n",
            "Walk_and_footsteps\n",
            "Shatter\n",
            "Microwave_oven\n",
            "Microwave_oven\n",
            "Meow\n",
            "Bark\n",
            "Doorbell\n",
            "Bark\n",
            "Microwave_oven\n",
            "Siren\n",
            "Microwave_oven\n",
            "Knock\n",
            "Doorbell\n",
            "Siren\n",
            "Meow\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Microwave_oven\n",
            "Walk_and_footsteps\n",
            "Bark\n",
            "Siren\n",
            "Meow\n",
            "Doorbell\n",
            "Meow\n",
            "Walk_and_footsteps\n",
            "Crying_and_sobbing\n",
            "Shatter\n",
            "Doorbell\n",
            "Meow\n",
            "Meow\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Shatter\n",
            "Crying_and_sobbing\n",
            "Shatter\n",
            "Siren\n",
            "Walk_and_footsteps\n",
            "Walk_and_footsteps\n",
            "Knock\n",
            "Doorbell\n",
            "Microwave_oven\n",
            "Knock\n",
            "Shatter\n",
            "Meow\n",
            "Meow\n",
            "Shatter\n",
            "Doorbell\n",
            "Knock\n",
            "Shatter\n",
            "Siren\n",
            "Microwave_oven\n",
            "Meow\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Crying_and_sobbing\n",
            "Walk_and_footsteps\n",
            "Crying_and_sobbing\n",
            "Crying_and_sobbing\n",
            "Bark\n",
            "Shatter\n",
            "Microwave_oven\n",
            "Meow\n",
            "Doorbell\n",
            "Shatter\n",
            "Crying_and_sobbing\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Shatter\n",
            "Siren\n",
            "Siren\n",
            "Crying_and_sobbing\n",
            "Walk_and_footsteps\n",
            "Doorbell\n",
            "Crying_and_sobbing\n",
            "Doorbell\n",
            "Microwave_oven\n",
            "Bark\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Walk_and_footsteps\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Meow\n",
            "Meow\n",
            "Siren\n",
            "Siren\n",
            "Crying_and_sobbing\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Walk_and_footsteps\n",
            "Microwave_oven\n",
            "Shatter\n",
            "Crying_and_sobbing\n",
            "Siren\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Meow\n",
            "Walk_and_footsteps\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Siren\n",
            "Walk_and_footsteps\n",
            "Crying_and_sobbing\n",
            "Walk_and_footsteps\n",
            "Bark\n",
            "Knock\n",
            "Crying_and_sobbing\n",
            "Shatter\n",
            "Walk_and_footsteps\n",
            "Crying_and_sobbing\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Knock\n",
            "Shatter\n",
            "Crying_and_sobbing\n",
            "Bark\n",
            "Bark\n",
            "Crying_and_sobbing\n",
            "Doorbell\n",
            "Microwave_oven\n",
            "Walk_and_footsteps\n",
            "Siren\n",
            "Microwave_oven\n",
            "Microwave_oven\n",
            "Meow\n",
            "Knock\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Microwave_oven\n",
            "Bark\n",
            "Doorbell\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Shatter\n",
            "Walk_and_footsteps\n",
            "Bark\n",
            "Walk_and_footsteps\n",
            "Meow\n",
            "Walk_and_footsteps\n",
            "Crying_and_sobbing\n",
            "Siren\n",
            "Walk_and_footsteps\n",
            "Walk_and_footsteps\n",
            "Crying_and_sobbing\n",
            "Shatter\n",
            "Knock\n",
            "Shatter\n",
            "Bark\n",
            "Crying_and_sobbing\n",
            "Knock\n",
            "Walk_and_footsteps\n",
            "Walk_and_footsteps\n",
            "Siren\n",
            "Walk_and_footsteps\n",
            "Walk_and_footsteps\n",
            "Knock\n",
            "Crying_and_sobbing\n",
            "Siren\n",
            "Crying_and_sobbing\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Doorbell\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Meow\n",
            "Bark\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Microwave_oven\n",
            "Microwave_oven\n",
            "Crying_and_sobbing\n",
            "Doorbell\n",
            "Siren\n",
            "Siren\n",
            "Microwave_oven\n",
            "Knock\n",
            "Bark\n",
            "Shatter\n",
            "Microwave_oven\n",
            "Doorbell\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Bark\n",
            "Bark\n",
            "Knock\n",
            "Walk_and_footsteps\n",
            "Bark\n",
            "Doorbell\n",
            "Microwave_oven\n",
            "Crying_and_sobbing\n",
            "Microwave_oven\n",
            "Doorbell\n",
            "Siren\n",
            "Vehicle_horn_and_car_horn_and_honking\n",
            "Shatter\n",
            "Knock\n",
            "Meow\n",
            "Bark\n",
            "Siren\n",
            "Shatter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "train_encoder = LabelEncoder()\n",
        "train_ = train_encoder.fit_transform(y_train)\n",
        "to_onehot=to_categorical(train_)\n",
        "y_train=to_onehot\n",
        "\n",
        "test_encoder = LabelEncoder()\n",
        "test_ = test_encoder.fit_transform(y_test)\n",
        "to_onehot=to_categorical(test_)\n",
        "y_test=to_onehot"
      ],
      "metadata": {
        "id": "Bw4vn3IV8uuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in y_train:\n",
        "  print(numpy.argmax(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hPU3AnNJ0NU",
        "outputId": "9300e41c-5fdf-4429-e29c-e76363f89548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "4\n",
            "0\n",
            "4\n",
            "6\n",
            "1\n",
            "6\n",
            "2\n",
            "1\n",
            "9\n",
            "6\n",
            "1\n",
            "8\n",
            "4\n",
            "1\n",
            "2\n",
            "4\n",
            "3\n",
            "3\n",
            "4\n",
            "0\n",
            "6\n",
            "1\n",
            "2\n",
            "5\n",
            "6\n",
            "3\n",
            "5\n",
            "8\n",
            "7\n",
            "6\n",
            "0\n",
            "5\n",
            "9\n",
            "9\n",
            "2\n",
            "0\n",
            "1\n",
            "0\n",
            "9\n",
            "5\n",
            "3\n",
            "2\n",
            "8\n",
            "2\n",
            "4\n",
            "6\n",
            "8\n",
            "4\n",
            "8\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "6\n",
            "9\n",
            "4\n",
            "1\n",
            "3\n",
            "2\n",
            "7\n",
            "6\n",
            "3\n",
            "9\n",
            "9\n",
            "2\n",
            "1\n",
            "4\n",
            "6\n",
            "6\n",
            "4\n",
            "2\n",
            "9\n",
            "2\n",
            "2\n",
            "3\n",
            "4\n",
            "3\n",
            "6\n",
            "8\n",
            "8\n",
            "5\n",
            "7\n",
            "7\n",
            "6\n",
            "7\n",
            "1\n",
            "4\n",
            "3\n",
            "8\n",
            "6\n",
            "0\n",
            "4\n",
            "4\n",
            "7\n",
            "8\n",
            "2\n",
            "3\n",
            "8\n",
            "0\n",
            "4\n",
            "8\n",
            "5\n",
            "4\n",
            "8\n",
            "2\n",
            "4\n",
            "8\n",
            "4\n",
            "6\n",
            "8\n",
            "6\n",
            "7\n",
            "9\n",
            "2\n",
            "5\n",
            "8\n",
            "1\n",
            "5\n",
            "6\n",
            "5\n",
            "8\n",
            "2\n",
            "1\n",
            "4\n",
            "1\n",
            "7\n",
            "6\n",
            "8\n",
            "1\n",
            "1\n",
            "5\n",
            "7\n",
            "6\n",
            "6\n",
            "2\n",
            "4\n",
            "6\n",
            "9\n",
            "4\n",
            "4\n",
            "9\n",
            "9\n",
            "4\n",
            "0\n",
            "9\n",
            "0\n",
            "0\n",
            "1\n",
            "7\n",
            "1\n",
            "6\n",
            "4\n",
            "0\n",
            "9\n",
            "8\n",
            "9\n",
            "2\n",
            "3\n",
            "7\n",
            "9\n",
            "4\n",
            "6\n",
            "5\n",
            "4\n",
            "2\n",
            "4\n",
            "3\n",
            "0\n",
            "1\n",
            "3\n",
            "7\n",
            "4\n",
            "8\n",
            "7\n",
            "1\n",
            "3\n",
            "2\n",
            "1\n",
            "7\n",
            "6\n",
            "4\n",
            "6\n",
            "2\n",
            "9\n",
            "6\n",
            "9\n",
            "9\n",
            "5\n",
            "6\n",
            "4\n",
            "8\n",
            "1\n",
            "9\n",
            "3\n",
            "7\n",
            "3\n",
            "6\n",
            "6\n",
            "5\n",
            "2\n",
            "3\n",
            "6\n",
            "9\n",
            "8\n",
            "7\n",
            "3\n",
            "4\n",
            "0\n",
            "4\n",
            "3\n",
            "7\n",
            "4\n",
            "6\n",
            "1\n",
            "9\n",
            "5\n",
            "6\n",
            "3\n",
            "5\n",
            "5\n",
            "0\n",
            "2\n",
            "7\n",
            "0\n",
            "6\n",
            "0\n",
            "0\n",
            "3\n",
            "9\n",
            "0\n",
            "5\n",
            "3\n",
            "5\n",
            "0\n",
            "9\n",
            "9\n",
            "3\n",
            "0\n",
            "8\n",
            "4\n",
            "3\n",
            "4\n",
            "3\n",
            "5\n",
            "7\n",
            "7\n",
            "0\n",
            "4\n",
            "2\n",
            "4\n",
            "2\n",
            "0\n",
            "4\n",
            "3\n",
            "4\n",
            "8\n",
            "6\n",
            "6\n",
            "4\n",
            "5\n",
            "6\n",
            "3\n",
            "7\n",
            "7\n",
            "3\n",
            "1\n",
            "0\n",
            "5\n",
            "7\n",
            "0\n",
            "7\n",
            "7\n",
            "7\n",
            "6\n",
            "5\n",
            "4\n",
            "7\n",
            "0\n",
            "7\n",
            "0\n",
            "1\n",
            "8\n",
            "7\n",
            "8\n",
            "5\n",
            "3\n",
            "2\n",
            "7\n",
            "4\n",
            "4\n",
            "9\n",
            "1\n",
            "7\n",
            "5\n",
            "0\n",
            "6\n",
            "6\n",
            "7\n",
            "3\n",
            "7\n",
            "2\n",
            "2\n",
            "5\n",
            "6\n",
            "7\n",
            "3\n",
            "0\n",
            "0\n",
            "0\n",
            "8\n",
            "5\n",
            "9\n",
            "4\n",
            "4\n",
            "7\n",
            "4\n",
            "6\n",
            "3\n",
            "0\n",
            "0\n",
            "1\n",
            "4\n",
            "6\n",
            "8\n",
            "3\n",
            "0\n",
            "5\n",
            "8\n",
            "3\n",
            "9\n",
            "5\n",
            "6\n",
            "5\n",
            "2\n",
            "5\n",
            "2\n",
            "9\n",
            "3\n",
            "8\n",
            "8\n",
            "8\n",
            "2\n",
            "9\n",
            "7\n",
            "6\n",
            "6\n",
            "5\n",
            "8\n",
            "0\n",
            "2\n",
            "1\n",
            "9\n",
            "3\n",
            "9\n",
            "5\n",
            "4\n",
            "7\n",
            "6\n",
            "0\n",
            "4\n",
            "6\n",
            "1\n",
            "8\n",
            "1\n",
            "8\n",
            "3\n",
            "1\n",
            "1\n",
            "3\n",
            "1\n",
            "2\n",
            "2\n",
            "7\n",
            "6\n",
            "9\n",
            "1\n",
            "3\n",
            "2\n",
            "7\n",
            "9\n",
            "4\n",
            "7\n",
            "8\n",
            "5\n",
            "1\n",
            "0\n",
            "9\n",
            "6\n",
            "0\n",
            "3\n",
            "9\n",
            "5\n",
            "4\n",
            "6\n",
            "0\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "1\n",
            "1\n",
            "2\n",
            "3\n",
            "7\n",
            "8\n",
            "3\n",
            "9\n",
            "9\n",
            "2\n",
            "2\n",
            "1\n",
            "0\n",
            "0\n",
            "6\n",
            "3\n",
            "5\n",
            "5\n",
            "1\n",
            "4\n",
            "5\n",
            "0\n",
            "5\n",
            "8\n",
            "4\n",
            "1\n",
            "0\n",
            "4\n",
            "8\n",
            "0\n",
            "5\n",
            "0\n",
            "0\n",
            "1\n",
            "5\n",
            "4\n",
            "6\n",
            "3\n",
            "6\n",
            "1\n",
            "9\n",
            "6\n",
            "3\n",
            "2\n",
            "8\n",
            "1\n",
            "3\n",
            "6\n",
            "7\n",
            "3\n",
            "1\n",
            "8\n",
            "1\n",
            "2\n",
            "6\n",
            "2\n",
            "5\n",
            "7\n",
            "2\n",
            "3\n",
            "9\n",
            "3\n",
            "5\n",
            "2\n",
            "8\n",
            "2\n",
            "5\n",
            "1\n",
            "7\n",
            "6\n",
            "0\n",
            "4\n",
            "0\n",
            "0\n",
            "4\n",
            "2\n",
            "6\n",
            "8\n",
            "8\n",
            "7\n",
            "3\n",
            "2\n",
            "8\n",
            "9\n",
            "4\n",
            "4\n",
            "3\n",
            "9\n",
            "3\n",
            "1\n",
            "2\n",
            "5\n",
            "1\n",
            "9\n",
            "5\n",
            "1\n",
            "5\n",
            "2\n",
            "0\n",
            "8\n",
            "3\n",
            "5\n",
            "0\n",
            "7\n",
            "0\n",
            "2\n",
            "0\n",
            "8\n",
            "2\n",
            "0\n",
            "6\n",
            "3\n",
            "7\n",
            "8\n",
            "1\n",
            "3\n",
            "6\n",
            "5\n",
            "3\n",
            "8\n",
            "3\n",
            "5\n",
            "2\n",
            "9\n",
            "4\n",
            "8\n",
            "5\n",
            "8\n",
            "0\n",
            "8\n",
            "8\n",
            "2\n",
            "7\n",
            "8\n",
            "6\n",
            "5\n",
            "2\n",
            "0\n",
            "1\n",
            "0\n",
            "7\n",
            "7\n",
            "3\n",
            "8\n",
            "1\n",
            "2\n",
            "7\n",
            "1\n",
            "7\n",
            "2\n",
            "9\n",
            "4\n",
            "0\n",
            "9\n",
            "2\n",
            "9\n",
            "1\n",
            "5\n",
            "5\n",
            "0\n",
            "8\n",
            "9\n",
            "4\n",
            "3\n",
            "2\n",
            "4\n",
            "3\n",
            "7\n",
            "5\n",
            "3\n",
            "2\n",
            "9\n",
            "3\n",
            "0\n",
            "7\n",
            "3\n",
            "8\n",
            "9\n",
            "2\n",
            "5\n",
            "5\n",
            "2\n",
            "1\n",
            "4\n",
            "1\n",
            "5\n",
            "0\n",
            "5\n",
            "1\n",
            "2\n",
            "7\n",
            "7\n",
            "3\n",
            "2\n",
            "6\n",
            "1\n",
            "3\n",
            "3\n",
            "7\n",
            "0\n",
            "1\n",
            "6\n",
            "9\n",
            "7\n",
            "7\n",
            "4\n",
            "9\n",
            "5\n",
            "9\n",
            "7\n",
            "9\n",
            "6\n",
            "5\n",
            "5\n",
            "4\n",
            "0\n",
            "2\n",
            "0\n",
            "5\n",
            "7\n",
            "5\n",
            "3\n",
            "2\n",
            "7\n",
            "4\n",
            "8\n",
            "5\n",
            "9\n",
            "0\n",
            "7\n",
            "4\n",
            "2\n",
            "4\n",
            "9\n",
            "1\n",
            "6\n",
            "2\n",
            "4\n",
            "4\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "6\n",
            "1\n",
            "6\n",
            "7\n",
            "9\n",
            "9\n",
            "3\n",
            "2\n",
            "5\n",
            "3\n",
            "6\n",
            "4\n",
            "4\n",
            "6\n",
            "2\n",
            "3\n",
            "6\n",
            "7\n",
            "5\n",
            "4\n",
            "8\n",
            "1\n",
            "9\n",
            "1\n",
            "1\n",
            "0\n",
            "6\n",
            "5\n",
            "4\n",
            "2\n",
            "6\n",
            "1\n",
            "8\n",
            "6\n",
            "7\n",
            "7\n",
            "1\n",
            "9\n",
            "2\n",
            "1\n",
            "2\n",
            "5\n",
            "0\n",
            "8\n",
            "9\n",
            "8\n",
            "8\n",
            "4\n",
            "4\n",
            "7\n",
            "7\n",
            "1\n",
            "8\n",
            "9\n",
            "5\n",
            "6\n",
            "1\n",
            "7\n",
            "8\n",
            "4\n",
            "9\n",
            "8\n",
            "7\n",
            "9\n",
            "1\n",
            "9\n",
            "0\n",
            "3\n",
            "1\n",
            "6\n",
            "9\n",
            "1\n",
            "8\n",
            "3\n",
            "6\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "5\n",
            "9\n",
            "7\n",
            "5\n",
            "5\n",
            "4\n",
            "3\n",
            "8\n",
            "8\n",
            "8\n",
            "5\n",
            "0\n",
            "2\n",
            "8\n",
            "6\n",
            "9\n",
            "0\n",
            "9\n",
            "4\n",
            "9\n",
            "1\n",
            "7\n",
            "9\n",
            "9\n",
            "1\n",
            "6\n",
            "3\n",
            "6\n",
            "0\n",
            "1\n",
            "3\n",
            "9\n",
            "9\n",
            "7\n",
            "9\n",
            "9\n",
            "3\n",
            "1\n",
            "7\n",
            "1\n",
            "8\n",
            "2\n",
            "8\n",
            "4\n",
            "0\n",
            "8\n",
            "5\n",
            "5\n",
            "1\n",
            "2\n",
            "7\n",
            "7\n",
            "5\n",
            "3\n",
            "0\n",
            "6\n",
            "5\n",
            "2\n",
            "8\n",
            "0\n",
            "0\n",
            "3\n",
            "9\n",
            "0\n",
            "2\n",
            "5\n",
            "1\n",
            "5\n",
            "2\n",
            "7\n",
            "8\n",
            "6\n",
            "3\n",
            "4\n",
            "0\n",
            "7\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definitions for recall, precision and f1 metrics"
      ],
      "metadata": {
        "id": "MKh5Njkiflou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reference: https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n",
        "from keras import backend \n",
        "from sklearn.metrics import precision_score , recall_score\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = backend.sum(backend.round(backend.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + backend.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = backend.sum(backend.round(backend.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + backend.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+backend.epsilon())) "
      ],
      "metadata": {
        "id": "QFBZGfkwi1Ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CNN Model**"
      ],
      "metadata": {
        "id": "JKtI2M-tiMPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pool_size = (2, 2)\n",
        "kernel_size = (3, 3)\n",
        "input_shape = (128, 2584, 1)\n",
        "num_classes = 10"
      ],
      "metadata": {
        "id": "00VA1GInKTUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    #first_convolution\n",
        "    tf.keras.layers.Conv2D(32, kernel_size,\n",
        "                padding=\"same\", input_shape=input_shape),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # tf.keras.layers.Dropout(0.25),\n",
        "    #second_convolution\n",
        "    tf.keras.layers.Conv2D(64, kernel_size,\n",
        "                                  padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    #third_convolution\n",
        "    tf.keras.layers.Conv2D(128, kernel_size,\n",
        "                                  padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    #fourth_convolution\n",
        "    tf.keras.layers.Conv2D(256, kernel_size,\n",
        "                                  padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.GlobalMaxPooling2D(),\n",
        "    # tf.keras.layers.Dropout(0.25),\n",
        "    #Fully connected 1st layer\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(10, activation='softmax') \n",
        "]) "
      ],
      "metadata": {
        "id": "WypDxjA4iPnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "k9E_fHvhiuLU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0caa99af-10b7-438a-96d5-5f83938fc30e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_20 (Conv2D)          (None, 128, 2584, 32)     320       \n",
            "                                                                 \n",
            " batch_normalization_20 (Bat  (None, 128, 2584, 32)    128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_20 (Activation)  (None, 128, 2584, 32)     0         \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 64, 1292, 32)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 64, 1292, 64)      18496     \n",
            "                                                                 \n",
            " batch_normalization_21 (Bat  (None, 64, 1292, 64)     256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_21 (Activation)  (None, 64, 1292, 64)      0         \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 32, 646, 64)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 32, 646, 64)       0         \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 32, 646, 128)      73856     \n",
            "                                                                 \n",
            " batch_normalization_22 (Bat  (None, 32, 646, 128)     512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_22 (Activation)  (None, 32, 646, 128)      0         \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 16, 323, 128)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 16, 323, 128)      0         \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 16, 323, 256)      295168    \n",
            "                                                                 \n",
            " batch_normalization_23 (Bat  (None, 16, 323, 256)     1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_23 (Activation)  (None, 16, 323, 256)      0         \n",
            "                                                                 \n",
            " global_max_pooling2d_5 (Glo  (None, 256)              0         \n",
            " balMaxPooling2D)                                                \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 458,122\n",
            "Trainable params: 457,162\n",
            "Non-trainable params: 960\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model using Adam optimizer\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "          loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "          metrics=[\"accuracy\", f1_m, precision_m, recall_m])"
      ],
      "metadata": {
        "id": "c9LejeMgZa_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training**"
      ],
      "metadata": {
        "id": "hP6Hcbq9jhTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To keep track of the best metrices obtained while training the model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "filepath = '/content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
      ],
      "metadata": {
        "id": "Ofn1Gx2QZjUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=32, epochs=160, verbose = 1, callbacks=[checkpoint])"
      ],
      "metadata": {
        "id": "aLeQhciRRCwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddd43391-71b2-4172-962c-e022ff16ded9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 5.6475 - accuracy: 0.1225 - f1_m: 0.0820 - precision_m: 0.1534 - recall_m: 0.0613\n",
            "Epoch 1: val_loss improved from inf to 2.41383, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 30s 587ms/step - loss: 5.6475 - accuracy: 0.1225 - f1_m: 0.0820 - precision_m: 0.1534 - recall_m: 0.0613 - val_loss: 2.4138 - val_accuracy: 0.0900 - val_f1_m: 0.0173 - val_precision_m: 0.2857 - val_recall_m: 0.0089\n",
            "Epoch 2/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.8509 - accuracy: 0.1425 - f1_m: 0.0507 - precision_m: 0.2086 - recall_m: 0.0300\n",
            "Epoch 2: val_loss improved from 2.41383 to 2.33968, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 577ms/step - loss: 2.8509 - accuracy: 0.1425 - f1_m: 0.0507 - precision_m: 0.2086 - recall_m: 0.0300 - val_loss: 2.3397 - val_accuracy: 0.1150 - val_f1_m: 0.0087 - val_precision_m: 0.1429 - val_recall_m: 0.0045\n",
            "Epoch 3/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.5408 - accuracy: 0.1963 - f1_m: 0.0848 - precision_m: 0.3002 - recall_m: 0.0500\n",
            "Epoch 3: val_loss improved from 2.33968 to 2.29883, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 573ms/step - loss: 2.5408 - accuracy: 0.1963 - f1_m: 0.0848 - precision_m: 0.3002 - recall_m: 0.0500 - val_loss: 2.2988 - val_accuracy: 0.1050 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 4/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.4206 - accuracy: 0.2062 - f1_m: 0.0671 - precision_m: 0.2784 - recall_m: 0.0388\n",
            "Epoch 4: val_loss improved from 2.29883 to 2.28673, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 570ms/step - loss: 2.4206 - accuracy: 0.2062 - f1_m: 0.0671 - precision_m: 0.2784 - recall_m: 0.0388 - val_loss: 2.2867 - val_accuracy: 0.1150 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 5/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.2952 - accuracy: 0.1975 - f1_m: 0.0856 - precision_m: 0.3770 - recall_m: 0.0500\n",
            "Epoch 5: val_loss improved from 2.28673 to 2.28088, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 573ms/step - loss: 2.2952 - accuracy: 0.1975 - f1_m: 0.0856 - precision_m: 0.3770 - recall_m: 0.0500 - val_loss: 2.2809 - val_accuracy: 0.1450 - val_f1_m: 0.0171 - val_precision_m: 0.2143 - val_recall_m: 0.0089\n",
            "Epoch 6/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.2584 - accuracy: 0.2450 - f1_m: 0.1015 - precision_m: 0.4599 - recall_m: 0.0587\n",
            "Epoch 6: val_loss improved from 2.28088 to 2.24515, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 576ms/step - loss: 2.2584 - accuracy: 0.2450 - f1_m: 0.1015 - precision_m: 0.4599 - recall_m: 0.0587 - val_loss: 2.2451 - val_accuracy: 0.1500 - val_f1_m: 0.0084 - val_precision_m: 0.0714 - val_recall_m: 0.0045\n",
            "Epoch 7/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.2682 - accuracy: 0.2375 - f1_m: 0.0916 - precision_m: 0.3381 - recall_m: 0.0538\n",
            "Epoch 7: val_loss improved from 2.24515 to 2.20649, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 578ms/step - loss: 2.2682 - accuracy: 0.2375 - f1_m: 0.0916 - precision_m: 0.3381 - recall_m: 0.0538 - val_loss: 2.2065 - val_accuracy: 0.1700 - val_f1_m: 0.0087 - val_precision_m: 0.1429 - val_recall_m: 0.0045\n",
            "Epoch 8/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.1645 - accuracy: 0.2512 - f1_m: 0.0859 - precision_m: 0.3395 - recall_m: 0.0500\n",
            "Epoch 8: val_loss did not improve from 2.20649\n",
            "25/25 [==============================] - 13s 535ms/step - loss: 2.1645 - accuracy: 0.2512 - f1_m: 0.0859 - precision_m: 0.3395 - recall_m: 0.0500 - val_loss: 2.2334 - val_accuracy: 0.1900 - val_f1_m: 0.0329 - val_precision_m: 0.2429 - val_recall_m: 0.0179\n",
            "Epoch 9/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.1444 - accuracy: 0.2700 - f1_m: 0.1281 - precision_m: 0.4470 - recall_m: 0.0763\n",
            "Epoch 9: val_loss did not improve from 2.20649\n",
            "25/25 [==============================] - 13s 534ms/step - loss: 2.1444 - accuracy: 0.2700 - f1_m: 0.1281 - precision_m: 0.4470 - recall_m: 0.0763 - val_loss: 2.2146 - val_accuracy: 0.1950 - val_f1_m: 0.0325 - val_precision_m: 0.1952 - val_recall_m: 0.0179\n",
            "Epoch 10/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.1385 - accuracy: 0.2650 - f1_m: 0.1347 - precision_m: 0.4426 - recall_m: 0.0812\n",
            "Epoch 10: val_loss improved from 2.20649 to 2.16549, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 566ms/step - loss: 2.1385 - accuracy: 0.2650 - f1_m: 0.1347 - precision_m: 0.4426 - recall_m: 0.0812 - val_loss: 2.1655 - val_accuracy: 0.2200 - val_f1_m: 0.0404 - val_precision_m: 0.2190 - val_recall_m: 0.0223\n",
            "Epoch 11/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.0187 - accuracy: 0.3150 - f1_m: 0.1471 - precision_m: 0.5078 - recall_m: 0.0887\n",
            "Epoch 11: val_loss improved from 2.16549 to 2.15134, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 575ms/step - loss: 2.0187 - accuracy: 0.3150 - f1_m: 0.1471 - precision_m: 0.5078 - recall_m: 0.0887 - val_loss: 2.1513 - val_accuracy: 0.2850 - val_f1_m: 0.0393 - val_precision_m: 0.1952 - val_recall_m: 0.0223\n",
            "Epoch 12/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.0020 - accuracy: 0.3187 - f1_m: 0.1597 - precision_m: 0.5284 - recall_m: 0.0950\n",
            "Epoch 12: val_loss did not improve from 2.15134\n",
            "25/25 [==============================] - 13s 533ms/step - loss: 2.0020 - accuracy: 0.3187 - f1_m: 0.1597 - precision_m: 0.5284 - recall_m: 0.0950 - val_loss: 2.1878 - val_accuracy: 0.2000 - val_f1_m: 0.0397 - val_precision_m: 0.1881 - val_recall_m: 0.0223\n",
            "Epoch 13/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.9852 - accuracy: 0.3275 - f1_m: 0.1671 - precision_m: 0.5113 - recall_m: 0.1013\n",
            "Epoch 13: val_loss improved from 2.15134 to 2.14952, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 566ms/step - loss: 1.9852 - accuracy: 0.3275 - f1_m: 0.1671 - precision_m: 0.5113 - recall_m: 0.1013 - val_loss: 2.1495 - val_accuracy: 0.2150 - val_f1_m: 0.0404 - val_precision_m: 0.2143 - val_recall_m: 0.0223\n",
            "Epoch 14/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.8944 - accuracy: 0.3375 - f1_m: 0.1949 - precision_m: 0.5730 - recall_m: 0.1200\n",
            "Epoch 14: val_loss improved from 2.14952 to 2.06288, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 573ms/step - loss: 1.8944 - accuracy: 0.3375 - f1_m: 0.1949 - precision_m: 0.5730 - recall_m: 0.1200 - val_loss: 2.0629 - val_accuracy: 0.2800 - val_f1_m: 0.0472 - val_precision_m: 0.2000 - val_recall_m: 0.0268\n",
            "Epoch 15/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.8490 - accuracy: 0.3787 - f1_m: 0.1672 - precision_m: 0.5677 - recall_m: 0.1000\n",
            "Epoch 15: val_loss improved from 2.06288 to 1.97632, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 575ms/step - loss: 1.8490 - accuracy: 0.3787 - f1_m: 0.1672 - precision_m: 0.5677 - recall_m: 0.1000 - val_loss: 1.9763 - val_accuracy: 0.3550 - val_f1_m: 0.0483 - val_precision_m: 0.2500 - val_recall_m: 0.0268\n",
            "Epoch 16/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.7543 - accuracy: 0.4300 - f1_m: 0.2449 - precision_m: 0.6832 - recall_m: 0.1513\n",
            "Epoch 16: val_loss improved from 1.97632 to 1.88732, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 566ms/step - loss: 1.7543 - accuracy: 0.4300 - f1_m: 0.2449 - precision_m: 0.6832 - recall_m: 0.1513 - val_loss: 1.8873 - val_accuracy: 0.3350 - val_f1_m: 0.0483 - val_precision_m: 0.2500 - val_recall_m: 0.0268\n",
            "Epoch 17/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.7595 - accuracy: 0.4025 - f1_m: 0.2218 - precision_m: 0.6091 - recall_m: 0.1375\n",
            "Epoch 17: val_loss did not improve from 1.88732\n",
            "25/25 [==============================] - 13s 535ms/step - loss: 1.7595 - accuracy: 0.4025 - f1_m: 0.2218 - precision_m: 0.6091 - recall_m: 0.1375 - val_loss: 1.8964 - val_accuracy: 0.3450 - val_f1_m: 0.0554 - val_precision_m: 0.2571 - val_recall_m: 0.0312\n",
            "Epoch 18/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.7345 - accuracy: 0.4187 - f1_m: 0.2275 - precision_m: 0.6095 - recall_m: 0.1437\n",
            "Epoch 18: val_loss improved from 1.88732 to 1.77887, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 565ms/step - loss: 1.7345 - accuracy: 0.4187 - f1_m: 0.2275 - precision_m: 0.6095 - recall_m: 0.1437 - val_loss: 1.7789 - val_accuracy: 0.3700 - val_f1_m: 0.0709 - val_precision_m: 0.3548 - val_recall_m: 0.0402\n",
            "Epoch 19/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.6556 - accuracy: 0.4487 - f1_m: 0.2584 - precision_m: 0.6815 - recall_m: 0.1625\n",
            "Epoch 19: val_loss improved from 1.77887 to 1.71285, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 566ms/step - loss: 1.6556 - accuracy: 0.4487 - f1_m: 0.2584 - precision_m: 0.6815 - recall_m: 0.1625 - val_loss: 1.7129 - val_accuracy: 0.4050 - val_f1_m: 0.0954 - val_precision_m: 0.5000 - val_recall_m: 0.0536\n",
            "Epoch 20/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.6470 - accuracy: 0.4462 - f1_m: 0.2717 - precision_m: 0.6591 - recall_m: 0.1737\n",
            "Epoch 20: val_loss improved from 1.71285 to 1.68035, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 575ms/step - loss: 1.6470 - accuracy: 0.4462 - f1_m: 0.2717 - precision_m: 0.6591 - recall_m: 0.1737 - val_loss: 1.6804 - val_accuracy: 0.4150 - val_f1_m: 0.0932 - val_precision_m: 0.4000 - val_recall_m: 0.0536\n",
            "Epoch 21/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.5693 - accuracy: 0.4863 - f1_m: 0.3068 - precision_m: 0.6855 - recall_m: 0.2013\n",
            "Epoch 21: val_loss improved from 1.68035 to 1.63320, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 576ms/step - loss: 1.5693 - accuracy: 0.4863 - f1_m: 0.3068 - precision_m: 0.6855 - recall_m: 0.2013 - val_loss: 1.6332 - val_accuracy: 0.4500 - val_f1_m: 0.1905 - val_precision_m: 0.7746 - val_recall_m: 0.1116\n",
            "Epoch 22/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.5429 - accuracy: 0.4900 - f1_m: 0.3120 - precision_m: 0.7267 - recall_m: 0.2013\n",
            "Epoch 22: val_loss improved from 1.63320 to 1.59140, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 576ms/step - loss: 1.5429 - accuracy: 0.4900 - f1_m: 0.3120 - precision_m: 0.7267 - recall_m: 0.2013 - val_loss: 1.5914 - val_accuracy: 0.4850 - val_f1_m: 0.1936 - val_precision_m: 0.6398 - val_recall_m: 0.1161\n",
            "Epoch 23/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.4909 - accuracy: 0.4837 - f1_m: 0.3348 - precision_m: 0.7414 - recall_m: 0.2225\n",
            "Epoch 23: val_loss improved from 1.59140 to 1.57000, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 574ms/step - loss: 1.4909 - accuracy: 0.4837 - f1_m: 0.3348 - precision_m: 0.7414 - recall_m: 0.2225 - val_loss: 1.5700 - val_accuracy: 0.4700 - val_f1_m: 0.1977 - val_precision_m: 0.6286 - val_recall_m: 0.1205\n",
            "Epoch 24/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.4662 - accuracy: 0.4938 - f1_m: 0.3696 - precision_m: 0.7213 - recall_m: 0.2525\n",
            "Epoch 24: val_loss improved from 1.57000 to 1.45069, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 573ms/step - loss: 1.4662 - accuracy: 0.4938 - f1_m: 0.3696 - precision_m: 0.7213 - recall_m: 0.2525 - val_loss: 1.4507 - val_accuracy: 0.5100 - val_f1_m: 0.2473 - val_precision_m: 0.8329 - val_recall_m: 0.1518\n",
            "Epoch 25/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.4245 - accuracy: 0.5300 - f1_m: 0.3693 - precision_m: 0.7166 - recall_m: 0.2562\n",
            "Epoch 25: val_loss improved from 1.45069 to 1.44911, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 566ms/step - loss: 1.4245 - accuracy: 0.5300 - f1_m: 0.3693 - precision_m: 0.7166 - recall_m: 0.2562 - val_loss: 1.4491 - val_accuracy: 0.5150 - val_f1_m: 0.2188 - val_precision_m: 0.6965 - val_recall_m: 0.1339\n",
            "Epoch 26/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.3591 - accuracy: 0.5412 - f1_m: 0.4000 - precision_m: 0.7512 - recall_m: 0.2775\n",
            "Epoch 26: val_loss did not improve from 1.44911\n",
            "25/25 [==============================] - 13s 535ms/step - loss: 1.3591 - accuracy: 0.5412 - f1_m: 0.4000 - precision_m: 0.7512 - recall_m: 0.2775 - val_loss: 1.4570 - val_accuracy: 0.5250 - val_f1_m: 0.2900 - val_precision_m: 0.7354 - val_recall_m: 0.1830\n",
            "Epoch 27/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.4089 - accuracy: 0.5150 - f1_m: 0.3910 - precision_m: 0.6851 - recall_m: 0.2775\n",
            "Epoch 27: val_loss did not improve from 1.44911\n",
            "25/25 [==============================] - 13s 534ms/step - loss: 1.4089 - accuracy: 0.5150 - f1_m: 0.3910 - precision_m: 0.6851 - recall_m: 0.2775 - val_loss: 1.4607 - val_accuracy: 0.5250 - val_f1_m: 0.3424 - val_precision_m: 0.7611 - val_recall_m: 0.2232\n",
            "Epoch 28/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.4014 - accuracy: 0.5275 - f1_m: 0.4062 - precision_m: 0.7027 - recall_m: 0.2887\n",
            "Epoch 28: val_loss improved from 1.44911 to 1.40335, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 567ms/step - loss: 1.4014 - accuracy: 0.5275 - f1_m: 0.4062 - precision_m: 0.7027 - recall_m: 0.2887 - val_loss: 1.4033 - val_accuracy: 0.5250 - val_f1_m: 0.3420 - val_precision_m: 0.7754 - val_recall_m: 0.2232\n",
            "Epoch 29/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.3057 - accuracy: 0.5788 - f1_m: 0.4478 - precision_m: 0.7720 - recall_m: 0.3200\n",
            "Epoch 29: val_loss improved from 1.40335 to 1.33919, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 573ms/step - loss: 1.3057 - accuracy: 0.5788 - f1_m: 0.4478 - precision_m: 0.7720 - recall_m: 0.3200 - val_loss: 1.3392 - val_accuracy: 0.6000 - val_f1_m: 0.3801 - val_precision_m: 0.8871 - val_recall_m: 0.2500\n",
            "Epoch 30/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.3227 - accuracy: 0.5875 - f1_m: 0.4462 - precision_m: 0.7567 - recall_m: 0.3212\n",
            "Epoch 30: val_loss improved from 1.33919 to 1.31902, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 572ms/step - loss: 1.3227 - accuracy: 0.5875 - f1_m: 0.4462 - precision_m: 0.7567 - recall_m: 0.3212 - val_loss: 1.3190 - val_accuracy: 0.6250 - val_f1_m: 0.3604 - val_precision_m: 0.8250 - val_recall_m: 0.2366\n",
            "Epoch 31/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.2536 - accuracy: 0.6000 - f1_m: 0.4699 - precision_m: 0.8051 - recall_m: 0.3350\n",
            "Epoch 31: val_loss improved from 1.31902 to 1.29324, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 575ms/step - loss: 1.2536 - accuracy: 0.6000 - f1_m: 0.4699 - precision_m: 0.8051 - recall_m: 0.3350 - val_loss: 1.2932 - val_accuracy: 0.6150 - val_f1_m: 0.4242 - val_precision_m: 0.7643 - val_recall_m: 0.3036\n",
            "Epoch 32/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.2014 - accuracy: 0.5950 - f1_m: 0.5063 - precision_m: 0.8088 - recall_m: 0.3738\n",
            "Epoch 32: val_loss improved from 1.29324 to 1.19923, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 574ms/step - loss: 1.2014 - accuracy: 0.5950 - f1_m: 0.5063 - precision_m: 0.8088 - recall_m: 0.3738 - val_loss: 1.1992 - val_accuracy: 0.6300 - val_f1_m: 0.4644 - val_precision_m: 0.8212 - val_recall_m: 0.3304\n",
            "Epoch 33/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.1939 - accuracy: 0.6225 - f1_m: 0.5118 - precision_m: 0.7832 - recall_m: 0.3875\n",
            "Epoch 33: val_loss did not improve from 1.19923\n",
            "25/25 [==============================] - 13s 534ms/step - loss: 1.1939 - accuracy: 0.6225 - f1_m: 0.5118 - precision_m: 0.7832 - recall_m: 0.3875 - val_loss: 1.2346 - val_accuracy: 0.6500 - val_f1_m: 0.4613 - val_precision_m: 0.8642 - val_recall_m: 0.3170\n",
            "Epoch 34/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.1949 - accuracy: 0.6012 - f1_m: 0.5020 - precision_m: 0.7715 - recall_m: 0.3750\n",
            "Epoch 34: val_loss improved from 1.19923 to 1.14116, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 567ms/step - loss: 1.1949 - accuracy: 0.6012 - f1_m: 0.5020 - precision_m: 0.7715 - recall_m: 0.3750 - val_loss: 1.1412 - val_accuracy: 0.6650 - val_f1_m: 0.4934 - val_precision_m: 0.8696 - val_recall_m: 0.3482\n",
            "Epoch 35/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0995 - accuracy: 0.6500 - f1_m: 0.5573 - precision_m: 0.8276 - recall_m: 0.4250\n",
            "Epoch 35: val_loss did not improve from 1.14116\n",
            "25/25 [==============================] - 13s 535ms/step - loss: 1.0995 - accuracy: 0.6500 - f1_m: 0.5573 - precision_m: 0.8276 - recall_m: 0.4250 - val_loss: 1.1841 - val_accuracy: 0.6400 - val_f1_m: 0.4955 - val_precision_m: 0.8592 - val_recall_m: 0.3527\n",
            "Epoch 36/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.1246 - accuracy: 0.6488 - f1_m: 0.5368 - precision_m: 0.8008 - recall_m: 0.4112\n",
            "Epoch 36: val_loss did not improve from 1.14116\n",
            "25/25 [==============================] - 13s 535ms/step - loss: 1.1246 - accuracy: 0.6488 - f1_m: 0.5368 - precision_m: 0.8008 - recall_m: 0.4112 - val_loss: 1.2073 - val_accuracy: 0.6200 - val_f1_m: 0.4945 - val_precision_m: 0.8714 - val_recall_m: 0.3482\n",
            "Epoch 37/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.1321 - accuracy: 0.6400 - f1_m: 0.5308 - precision_m: 0.7894 - recall_m: 0.4038\n",
            "Epoch 37: val_loss did not improve from 1.14116\n",
            "25/25 [==============================] - 13s 534ms/step - loss: 1.1321 - accuracy: 0.6400 - f1_m: 0.5308 - precision_m: 0.7894 - recall_m: 0.4038 - val_loss: 1.1589 - val_accuracy: 0.6700 - val_f1_m: 0.5186 - val_precision_m: 0.8760 - val_recall_m: 0.3705\n",
            "Epoch 38/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0651 - accuracy: 0.6525 - f1_m: 0.5600 - precision_m: 0.7932 - recall_m: 0.4363\n",
            "Epoch 38: val_loss improved from 1.14116 to 1.08316, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 565ms/step - loss: 1.0651 - accuracy: 0.6525 - f1_m: 0.5600 - precision_m: 0.7932 - recall_m: 0.4363 - val_loss: 1.0832 - val_accuracy: 0.7100 - val_f1_m: 0.5712 - val_precision_m: 0.8855 - val_recall_m: 0.4241\n",
            "Epoch 39/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9720 - accuracy: 0.6825 - f1_m: 0.5984 - precision_m: 0.8416 - recall_m: 0.4675\n",
            "Epoch 39: val_loss improved from 1.08316 to 1.07450, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 572ms/step - loss: 0.9720 - accuracy: 0.6825 - f1_m: 0.5984 - precision_m: 0.8416 - recall_m: 0.4675 - val_loss: 1.0745 - val_accuracy: 0.7000 - val_f1_m: 0.5998 - val_precision_m: 0.8983 - val_recall_m: 0.4554\n",
            "Epoch 40/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0018 - accuracy: 0.6725 - f1_m: 0.5937 - precision_m: 0.8190 - recall_m: 0.4712\n",
            "Epoch 40: val_loss improved from 1.07450 to 1.02476, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 567ms/step - loss: 1.0018 - accuracy: 0.6725 - f1_m: 0.5937 - precision_m: 0.8190 - recall_m: 0.4712 - val_loss: 1.0248 - val_accuracy: 0.7150 - val_f1_m: 0.5875 - val_precision_m: 0.9204 - val_recall_m: 0.4375\n",
            "Epoch 41/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9250 - accuracy: 0.7350 - f1_m: 0.6333 - precision_m: 0.8773 - recall_m: 0.4988\n",
            "Epoch 41: val_loss improved from 1.02476 to 0.98894, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 565ms/step - loss: 0.9250 - accuracy: 0.7350 - f1_m: 0.6333 - precision_m: 0.8773 - recall_m: 0.4988 - val_loss: 0.9889 - val_accuracy: 0.7300 - val_f1_m: 0.6473 - val_precision_m: 0.9058 - val_recall_m: 0.5089\n",
            "Epoch 42/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9643 - accuracy: 0.6950 - f1_m: 0.6213 - precision_m: 0.8250 - recall_m: 0.5050\n",
            "Epoch 42: val_loss did not improve from 0.98894\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.9643 - accuracy: 0.6950 - f1_m: 0.6213 - precision_m: 0.8250 - recall_m: 0.5050 - val_loss: 1.0291 - val_accuracy: 0.7350 - val_f1_m: 0.6352 - val_precision_m: 0.8922 - val_recall_m: 0.4955\n",
            "Epoch 43/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9134 - accuracy: 0.7237 - f1_m: 0.6323 - precision_m: 0.8478 - recall_m: 0.5063\n",
            "Epoch 43: val_loss did not improve from 0.98894\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.9134 - accuracy: 0.7237 - f1_m: 0.6323 - precision_m: 0.8478 - recall_m: 0.5063 - val_loss: 1.0084 - val_accuracy: 0.7050 - val_f1_m: 0.6508 - val_precision_m: 0.8856 - val_recall_m: 0.5179\n",
            "Epoch 44/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8870 - accuracy: 0.7350 - f1_m: 0.6567 - precision_m: 0.8623 - recall_m: 0.5337\n",
            "Epoch 44: val_loss improved from 0.98894 to 0.95474, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 568ms/step - loss: 0.8870 - accuracy: 0.7350 - f1_m: 0.6567 - precision_m: 0.8623 - recall_m: 0.5337 - val_loss: 0.9547 - val_accuracy: 0.7400 - val_f1_m: 0.6386 - val_precision_m: 0.9243 - val_recall_m: 0.4955\n",
            "Epoch 45/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9046 - accuracy: 0.7063 - f1_m: 0.6451 - precision_m: 0.8425 - recall_m: 0.5263\n",
            "Epoch 45: val_loss improved from 0.95474 to 0.94721, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 582ms/step - loss: 0.9046 - accuracy: 0.7063 - f1_m: 0.6451 - precision_m: 0.8425 - recall_m: 0.5263 - val_loss: 0.9472 - val_accuracy: 0.7200 - val_f1_m: 0.6782 - val_precision_m: 0.8824 - val_recall_m: 0.5580\n",
            "Epoch 46/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8534 - accuracy: 0.7300 - f1_m: 0.6780 - precision_m: 0.8543 - recall_m: 0.5675\n",
            "Epoch 46: val_loss did not improve from 0.94721\n",
            "25/25 [==============================] - 13s 533ms/step - loss: 0.8534 - accuracy: 0.7300 - f1_m: 0.6780 - precision_m: 0.8543 - recall_m: 0.5675 - val_loss: 0.9628 - val_accuracy: 0.7200 - val_f1_m: 0.6528 - val_precision_m: 0.9037 - val_recall_m: 0.5223\n",
            "Epoch 47/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8216 - accuracy: 0.7425 - f1_m: 0.7009 - precision_m: 0.8852 - recall_m: 0.5838\n",
            "Epoch 47: val_loss did not improve from 0.94721\n",
            "25/25 [==============================] - 13s 534ms/step - loss: 0.8216 - accuracy: 0.7425 - f1_m: 0.7009 - precision_m: 0.8852 - recall_m: 0.5838 - val_loss: 0.9640 - val_accuracy: 0.7050 - val_f1_m: 0.6614 - val_precision_m: 0.8422 - val_recall_m: 0.5491\n",
            "Epoch 48/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8168 - accuracy: 0.7550 - f1_m: 0.7091 - precision_m: 0.8882 - recall_m: 0.5938\n",
            "Epoch 48: val_loss improved from 0.94721 to 0.91738, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 568ms/step - loss: 0.8168 - accuracy: 0.7550 - f1_m: 0.7091 - precision_m: 0.8882 - recall_m: 0.5938 - val_loss: 0.9174 - val_accuracy: 0.7400 - val_f1_m: 0.6887 - val_precision_m: 0.9039 - val_recall_m: 0.5625\n",
            "Epoch 49/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7470 - accuracy: 0.7763 - f1_m: 0.7175 - precision_m: 0.8838 - recall_m: 0.6087\n",
            "Epoch 49: val_loss improved from 0.91738 to 0.89757, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 566ms/step - loss: 0.7470 - accuracy: 0.7763 - f1_m: 0.7175 - precision_m: 0.8838 - recall_m: 0.6087 - val_loss: 0.8976 - val_accuracy: 0.7250 - val_f1_m: 0.6863 - val_precision_m: 0.8894 - val_recall_m: 0.5625\n",
            "Epoch 50/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7677 - accuracy: 0.7663 - f1_m: 0.6975 - precision_m: 0.8720 - recall_m: 0.5863\n",
            "Epoch 50: val_loss improved from 0.89757 to 0.85047, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 572ms/step - loss: 0.7677 - accuracy: 0.7663 - f1_m: 0.6975 - precision_m: 0.8720 - recall_m: 0.5863 - val_loss: 0.8505 - val_accuracy: 0.7800 - val_f1_m: 0.7059 - val_precision_m: 0.9045 - val_recall_m: 0.5804\n",
            "Epoch 51/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7772 - accuracy: 0.7738 - f1_m: 0.7283 - precision_m: 0.8729 - recall_m: 0.6275\n",
            "Epoch 51: val_loss improved from 0.85047 to 0.84521, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 575ms/step - loss: 0.7772 - accuracy: 0.7738 - f1_m: 0.7283 - precision_m: 0.8729 - recall_m: 0.6275 - val_loss: 0.8452 - val_accuracy: 0.7400 - val_f1_m: 0.7149 - val_precision_m: 0.8846 - val_recall_m: 0.6071\n",
            "Epoch 52/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6992 - accuracy: 0.8062 - f1_m: 0.7518 - precision_m: 0.8831 - recall_m: 0.6600\n",
            "Epoch 52: val_loss improved from 0.84521 to 0.81403, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 567ms/step - loss: 0.6992 - accuracy: 0.8062 - f1_m: 0.7518 - precision_m: 0.8831 - recall_m: 0.6600 - val_loss: 0.8140 - val_accuracy: 0.7700 - val_f1_m: 0.7196 - val_precision_m: 0.9130 - val_recall_m: 0.5982\n",
            "Epoch 53/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7200 - accuracy: 0.7837 - f1_m: 0.7275 - precision_m: 0.8651 - recall_m: 0.6313\n",
            "Epoch 53: val_loss improved from 0.81403 to 0.81154, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 563ms/step - loss: 0.7200 - accuracy: 0.7837 - f1_m: 0.7275 - precision_m: 0.8651 - recall_m: 0.6313 - val_loss: 0.8115 - val_accuracy: 0.7550 - val_f1_m: 0.7335 - val_precision_m: 0.9155 - val_recall_m: 0.6161\n",
            "Epoch 54/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6947 - accuracy: 0.7937 - f1_m: 0.7485 - precision_m: 0.8809 - recall_m: 0.6550\n",
            "Epoch 54: val_loss did not improve from 0.81154\n",
            "25/25 [==============================] - 13s 535ms/step - loss: 0.6947 - accuracy: 0.7937 - f1_m: 0.7485 - precision_m: 0.8809 - recall_m: 0.6550 - val_loss: 0.8531 - val_accuracy: 0.7500 - val_f1_m: 0.7184 - val_precision_m: 0.8882 - val_recall_m: 0.6071\n",
            "Epoch 55/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6697 - accuracy: 0.7975 - f1_m: 0.7623 - precision_m: 0.8990 - recall_m: 0.6650\n",
            "Epoch 55: val_loss did not improve from 0.81154\n",
            "25/25 [==============================] - 13s 534ms/step - loss: 0.6697 - accuracy: 0.7975 - f1_m: 0.7623 - precision_m: 0.8990 - recall_m: 0.6650 - val_loss: 0.8283 - val_accuracy: 0.7250 - val_f1_m: 0.7216 - val_precision_m: 0.8763 - val_recall_m: 0.6205\n",
            "Epoch 56/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6412 - accuracy: 0.8062 - f1_m: 0.7940 - precision_m: 0.8983 - recall_m: 0.7163\n",
            "Epoch 56: val_loss improved from 0.81154 to 0.77386, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 568ms/step - loss: 0.6412 - accuracy: 0.8062 - f1_m: 0.7940 - precision_m: 0.8983 - recall_m: 0.7163 - val_loss: 0.7739 - val_accuracy: 0.7500 - val_f1_m: 0.7199 - val_precision_m: 0.8800 - val_recall_m: 0.6116\n",
            "Epoch 57/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6247 - accuracy: 0.8163 - f1_m: 0.7831 - precision_m: 0.9012 - recall_m: 0.6963\n",
            "Epoch 57: val_loss improved from 0.77386 to 0.73361, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 575ms/step - loss: 0.6247 - accuracy: 0.8163 - f1_m: 0.7831 - precision_m: 0.9012 - recall_m: 0.6963 - val_loss: 0.7336 - val_accuracy: 0.7950 - val_f1_m: 0.7779 - val_precision_m: 0.9247 - val_recall_m: 0.6741\n",
            "Epoch 58/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6303 - accuracy: 0.8062 - f1_m: 0.7772 - precision_m: 0.8887 - recall_m: 0.6925\n",
            "Epoch 58: val_loss did not improve from 0.73361\n",
            "25/25 [==============================] - 13s 534ms/step - loss: 0.6303 - accuracy: 0.8062 - f1_m: 0.7772 - precision_m: 0.8887 - recall_m: 0.6925 - val_loss: 0.7479 - val_accuracy: 0.7650 - val_f1_m: 0.7495 - val_precision_m: 0.9215 - val_recall_m: 0.6429\n",
            "Epoch 59/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6088 - accuracy: 0.8275 - f1_m: 0.7896 - precision_m: 0.8897 - recall_m: 0.7113\n",
            "Epoch 59: val_loss did not improve from 0.73361\n",
            "25/25 [==============================] - 13s 534ms/step - loss: 0.6088 - accuracy: 0.8275 - f1_m: 0.7896 - precision_m: 0.8897 - recall_m: 0.7113 - val_loss: 0.7624 - val_accuracy: 0.7700 - val_f1_m: 0.7589 - val_precision_m: 0.9164 - val_recall_m: 0.6562\n",
            "Epoch 60/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6316 - accuracy: 0.8112 - f1_m: 0.7948 - precision_m: 0.8911 - recall_m: 0.7200\n",
            "Epoch 60: val_loss did not improve from 0.73361\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.6316 - accuracy: 0.8112 - f1_m: 0.7948 - precision_m: 0.8911 - recall_m: 0.7200 - val_loss: 0.7367 - val_accuracy: 0.7750 - val_f1_m: 0.7745 - val_precision_m: 0.9017 - val_recall_m: 0.6830\n",
            "Epoch 61/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5864 - accuracy: 0.8425 - f1_m: 0.8078 - precision_m: 0.9145 - recall_m: 0.7275\n",
            "Epoch 61: val_loss did not improve from 0.73361\n",
            "25/25 [==============================] - 13s 535ms/step - loss: 0.5864 - accuracy: 0.8425 - f1_m: 0.8078 - precision_m: 0.9145 - recall_m: 0.7275 - val_loss: 0.7508 - val_accuracy: 0.7450 - val_f1_m: 0.7632 - val_precision_m: 0.8999 - val_recall_m: 0.6652\n",
            "Epoch 62/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5739 - accuracy: 0.8238 - f1_m: 0.8139 - precision_m: 0.9055 - recall_m: 0.7412\n",
            "Epoch 62: val_loss improved from 0.73361 to 0.72233, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 569ms/step - loss: 0.5739 - accuracy: 0.8238 - f1_m: 0.8139 - precision_m: 0.9055 - recall_m: 0.7412 - val_loss: 0.7223 - val_accuracy: 0.7650 - val_f1_m: 0.7537 - val_precision_m: 0.8663 - val_recall_m: 0.6696\n",
            "Epoch 63/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5536 - accuracy: 0.8462 - f1_m: 0.8230 - precision_m: 0.9240 - recall_m: 0.7450\n",
            "Epoch 63: val_loss improved from 0.72233 to 0.70647, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 571ms/step - loss: 0.5536 - accuracy: 0.8462 - f1_m: 0.8230 - precision_m: 0.9240 - recall_m: 0.7450 - val_loss: 0.7065 - val_accuracy: 0.7900 - val_f1_m: 0.7613 - val_precision_m: 0.8726 - val_recall_m: 0.6786\n",
            "Epoch 64/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5628 - accuracy: 0.8213 - f1_m: 0.8058 - precision_m: 0.8913 - recall_m: 0.7375\n",
            "Epoch 64: val_loss did not improve from 0.70647\n",
            "25/25 [==============================] - 13s 535ms/step - loss: 0.5628 - accuracy: 0.8213 - f1_m: 0.8058 - precision_m: 0.8913 - recall_m: 0.7375 - val_loss: 0.7179 - val_accuracy: 0.7700 - val_f1_m: 0.7464 - val_precision_m: 0.8856 - val_recall_m: 0.6473\n",
            "Epoch 65/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5147 - accuracy: 0.8612 - f1_m: 0.8302 - precision_m: 0.9222 - recall_m: 0.7575\n",
            "Epoch 65: val_loss improved from 0.70647 to 0.68486, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 564ms/step - loss: 0.5147 - accuracy: 0.8612 - f1_m: 0.8302 - precision_m: 0.9222 - recall_m: 0.7575 - val_loss: 0.6849 - val_accuracy: 0.8000 - val_f1_m: 0.7886 - val_precision_m: 0.9274 - val_recall_m: 0.6875\n",
            "Epoch 66/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5088 - accuracy: 0.8650 - f1_m: 0.8366 - precision_m: 0.9143 - recall_m: 0.7725\n",
            "Epoch 66: val_loss did not improve from 0.68486\n",
            "25/25 [==============================] - 13s 535ms/step - loss: 0.5088 - accuracy: 0.8650 - f1_m: 0.8366 - precision_m: 0.9143 - recall_m: 0.7725 - val_loss: 0.6914 - val_accuracy: 0.7850 - val_f1_m: 0.7954 - val_precision_m: 0.9157 - val_recall_m: 0.7054\n",
            "Epoch 67/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4800 - accuracy: 0.8587 - f1_m: 0.8429 - precision_m: 0.9138 - recall_m: 0.7837\n",
            "Epoch 67: val_loss improved from 0.68486 to 0.67853, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 567ms/step - loss: 0.4800 - accuracy: 0.8587 - f1_m: 0.8429 - precision_m: 0.9138 - recall_m: 0.7837 - val_loss: 0.6785 - val_accuracy: 0.7950 - val_f1_m: 0.7709 - val_precision_m: 0.8933 - val_recall_m: 0.6786\n",
            "Epoch 68/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4973 - accuracy: 0.8475 - f1_m: 0.8429 - precision_m: 0.9240 - recall_m: 0.7763\n",
            "Epoch 68: val_loss improved from 0.67853 to 0.67781, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 568ms/step - loss: 0.4973 - accuracy: 0.8475 - f1_m: 0.8429 - precision_m: 0.9240 - recall_m: 0.7763 - val_loss: 0.6778 - val_accuracy: 0.7700 - val_f1_m: 0.7593 - val_precision_m: 0.8708 - val_recall_m: 0.6741\n",
            "Epoch 69/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5018 - accuracy: 0.8537 - f1_m: 0.8429 - precision_m: 0.9118 - recall_m: 0.7850\n",
            "Epoch 69: val_loss improved from 0.67781 to 0.65431, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 577ms/step - loss: 0.5018 - accuracy: 0.8537 - f1_m: 0.8429 - precision_m: 0.9118 - recall_m: 0.7850 - val_loss: 0.6543 - val_accuracy: 0.8250 - val_f1_m: 0.8040 - val_precision_m: 0.9310 - val_recall_m: 0.7098\n",
            "Epoch 70/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4815 - accuracy: 0.8637 - f1_m: 0.8493 - precision_m: 0.9260 - recall_m: 0.7862\n",
            "Epoch 70: val_loss did not improve from 0.65431\n",
            "25/25 [==============================] - 13s 535ms/step - loss: 0.4815 - accuracy: 0.8637 - f1_m: 0.8493 - precision_m: 0.9260 - recall_m: 0.7862 - val_loss: 0.7191 - val_accuracy: 0.7400 - val_f1_m: 0.7738 - val_precision_m: 0.8836 - val_recall_m: 0.6920\n",
            "Epoch 71/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4870 - accuracy: 0.8550 - f1_m: 0.8351 - precision_m: 0.9144 - recall_m: 0.7700\n",
            "Epoch 71: val_loss did not improve from 0.65431\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.4870 - accuracy: 0.8550 - f1_m: 0.8351 - precision_m: 0.9144 - recall_m: 0.7700 - val_loss: 0.6663 - val_accuracy: 0.8000 - val_f1_m: 0.8102 - val_precision_m: 0.9303 - val_recall_m: 0.7232\n",
            "Epoch 72/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4732 - accuracy: 0.8487 - f1_m: 0.8378 - precision_m: 0.9020 - recall_m: 0.7837\n",
            "Epoch 72: val_loss improved from 0.65431 to 0.65322, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 567ms/step - loss: 0.4732 - accuracy: 0.8487 - f1_m: 0.8378 - precision_m: 0.9020 - recall_m: 0.7837 - val_loss: 0.6532 - val_accuracy: 0.8200 - val_f1_m: 0.7941 - val_precision_m: 0.8933 - val_recall_m: 0.7188\n",
            "Epoch 73/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4312 - accuracy: 0.8850 - f1_m: 0.8672 - precision_m: 0.9298 - recall_m: 0.8138\n",
            "Epoch 73: val_loss improved from 0.65322 to 0.62683, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 572ms/step - loss: 0.4312 - accuracy: 0.8850 - f1_m: 0.8672 - precision_m: 0.9298 - recall_m: 0.8138 - val_loss: 0.6268 - val_accuracy: 0.8100 - val_f1_m: 0.8352 - val_precision_m: 0.9247 - val_recall_m: 0.7634\n",
            "Epoch 74/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4349 - accuracy: 0.8775 - f1_m: 0.8699 - precision_m: 0.9367 - recall_m: 0.8138\n",
            "Epoch 74: val_loss did not improve from 0.62683\n",
            "25/25 [==============================] - 13s 535ms/step - loss: 0.4349 - accuracy: 0.8775 - f1_m: 0.8699 - precision_m: 0.9367 - recall_m: 0.8138 - val_loss: 0.6661 - val_accuracy: 0.7850 - val_f1_m: 0.7884 - val_precision_m: 0.8734 - val_recall_m: 0.7232\n",
            "Epoch 75/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4092 - accuracy: 0.8838 - f1_m: 0.8763 - precision_m: 0.9295 - recall_m: 0.8313\n",
            "Epoch 75: val_loss did not improve from 0.62683\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.4092 - accuracy: 0.8838 - f1_m: 0.8763 - precision_m: 0.9295 - recall_m: 0.8313 - val_loss: 0.6546 - val_accuracy: 0.7950 - val_f1_m: 0.7997 - val_precision_m: 0.8974 - val_recall_m: 0.7232\n",
            "Epoch 76/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4243 - accuracy: 0.8863 - f1_m: 0.8691 - precision_m: 0.9277 - recall_m: 0.8200\n",
            "Epoch 76: val_loss improved from 0.62683 to 0.61637, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 570ms/step - loss: 0.4243 - accuracy: 0.8863 - f1_m: 0.8691 - precision_m: 0.9277 - recall_m: 0.8200 - val_loss: 0.6164 - val_accuracy: 0.8150 - val_f1_m: 0.8351 - val_precision_m: 0.9081 - val_recall_m: 0.7768\n",
            "Epoch 77/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4045 - accuracy: 0.8875 - f1_m: 0.8826 - precision_m: 0.9341 - recall_m: 0.8375\n",
            "Epoch 77: val_loss improved from 0.61637 to 0.61396, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 570ms/step - loss: 0.4045 - accuracy: 0.8875 - f1_m: 0.8826 - precision_m: 0.9341 - recall_m: 0.8375 - val_loss: 0.6140 - val_accuracy: 0.8050 - val_f1_m: 0.8331 - val_precision_m: 0.9260 - val_recall_m: 0.7589\n",
            "Epoch 78/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4090 - accuracy: 0.8700 - f1_m: 0.8575 - precision_m: 0.9195 - recall_m: 0.8062\n",
            "Epoch 78: val_loss did not improve from 0.61396\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.4090 - accuracy: 0.8700 - f1_m: 0.8575 - precision_m: 0.9195 - recall_m: 0.8062 - val_loss: 0.6186 - val_accuracy: 0.8200 - val_f1_m: 0.8256 - val_precision_m: 0.9173 - val_recall_m: 0.7545\n",
            "Epoch 79/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3685 - accuracy: 0.8988 - f1_m: 0.8902 - precision_m: 0.9431 - recall_m: 0.8450\n",
            "Epoch 79: val_loss improved from 0.61396 to 0.59825, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 570ms/step - loss: 0.3685 - accuracy: 0.8988 - f1_m: 0.8902 - precision_m: 0.9431 - recall_m: 0.8450 - val_loss: 0.5982 - val_accuracy: 0.8400 - val_f1_m: 0.8300 - val_precision_m: 0.9255 - val_recall_m: 0.7545\n",
            "Epoch 80/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3760 - accuracy: 0.8975 - f1_m: 0.8887 - precision_m: 0.9403 - recall_m: 0.8438\n",
            "Epoch 80: val_loss did not improve from 0.59825\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.3760 - accuracy: 0.8975 - f1_m: 0.8887 - precision_m: 0.9403 - recall_m: 0.8438 - val_loss: 0.6108 - val_accuracy: 0.8000 - val_f1_m: 0.8124 - val_precision_m: 0.8824 - val_recall_m: 0.7545\n",
            "Epoch 81/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3339 - accuracy: 0.8950 - f1_m: 0.8987 - precision_m: 0.9472 - recall_m: 0.8562\n",
            "Epoch 81: val_loss did not improve from 0.59825\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.3339 - accuracy: 0.8950 - f1_m: 0.8987 - precision_m: 0.9472 - recall_m: 0.8562 - val_loss: 0.6312 - val_accuracy: 0.7900 - val_f1_m: 0.7753 - val_precision_m: 0.8499 - val_recall_m: 0.7143\n",
            "Epoch 82/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3612 - accuracy: 0.8938 - f1_m: 0.8865 - precision_m: 0.9404 - recall_m: 0.8400\n",
            "Epoch 82: val_loss improved from 0.59825 to 0.58289, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 569ms/step - loss: 0.3612 - accuracy: 0.8938 - f1_m: 0.8865 - precision_m: 0.9404 - recall_m: 0.8400 - val_loss: 0.5829 - val_accuracy: 0.8050 - val_f1_m: 0.8013 - val_precision_m: 0.8686 - val_recall_m: 0.7455\n",
            "Epoch 83/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3617 - accuracy: 0.8875 - f1_m: 0.8885 - precision_m: 0.9414 - recall_m: 0.8425\n",
            "Epoch 83: val_loss improved from 0.58289 to 0.56904, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 573ms/step - loss: 0.3617 - accuracy: 0.8875 - f1_m: 0.8885 - precision_m: 0.9414 - recall_m: 0.8425 - val_loss: 0.5690 - val_accuracy: 0.8200 - val_f1_m: 0.8219 - val_precision_m: 0.8995 - val_recall_m: 0.7589\n",
            "Epoch 84/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3278 - accuracy: 0.9150 - f1_m: 0.9103 - precision_m: 0.9453 - recall_m: 0.8788\n",
            "Epoch 84: val_loss improved from 0.56904 to 0.56634, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 15s 590ms/step - loss: 0.3278 - accuracy: 0.9150 - f1_m: 0.9103 - precision_m: 0.9453 - recall_m: 0.8788 - val_loss: 0.5663 - val_accuracy: 0.8250 - val_f1_m: 0.8298 - val_precision_m: 0.8920 - val_recall_m: 0.7768\n",
            "Epoch 85/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3281 - accuracy: 0.9013 - f1_m: 0.9001 - precision_m: 0.9468 - recall_m: 0.8587\n",
            "Epoch 85: val_loss did not improve from 0.56634\n",
            "25/25 [==============================] - 13s 534ms/step - loss: 0.3281 - accuracy: 0.9013 - f1_m: 0.9001 - precision_m: 0.9468 - recall_m: 0.8587 - val_loss: 0.5736 - val_accuracy: 0.8550 - val_f1_m: 0.8481 - val_precision_m: 0.9037 - val_recall_m: 0.7991\n",
            "Epoch 86/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3129 - accuracy: 0.9187 - f1_m: 0.9026 - precision_m: 0.9389 - recall_m: 0.8700\n",
            "Epoch 86: val_loss improved from 0.56634 to 0.56243, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 571ms/step - loss: 0.3129 - accuracy: 0.9187 - f1_m: 0.9026 - precision_m: 0.9389 - recall_m: 0.8700 - val_loss: 0.5624 - val_accuracy: 0.8400 - val_f1_m: 0.8732 - val_precision_m: 0.9293 - val_recall_m: 0.8259\n",
            "Epoch 87/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3066 - accuracy: 0.9038 - f1_m: 0.9058 - precision_m: 0.9478 - recall_m: 0.8687\n",
            "Epoch 87: val_loss improved from 0.56243 to 0.51246, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 578ms/step - loss: 0.3066 - accuracy: 0.9038 - f1_m: 0.9058 - precision_m: 0.9478 - recall_m: 0.8687 - val_loss: 0.5125 - val_accuracy: 0.8450 - val_f1_m: 0.8807 - val_precision_m: 0.9340 - val_recall_m: 0.8348\n",
            "Epoch 88/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3124 - accuracy: 0.9112 - f1_m: 0.9011 - precision_m: 0.9492 - recall_m: 0.8600\n",
            "Epoch 88: val_loss did not improve from 0.51246\n",
            "25/25 [==============================] - 13s 535ms/step - loss: 0.3124 - accuracy: 0.9112 - f1_m: 0.9011 - precision_m: 0.9492 - recall_m: 0.8600 - val_loss: 0.5243 - val_accuracy: 0.8350 - val_f1_m: 0.8507 - val_precision_m: 0.8946 - val_recall_m: 0.8125\n",
            "Epoch 89/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3218 - accuracy: 0.9087 - f1_m: 0.9030 - precision_m: 0.9386 - recall_m: 0.8712\n",
            "Epoch 89: val_loss did not improve from 0.51246\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.3218 - accuracy: 0.9087 - f1_m: 0.9030 - precision_m: 0.9386 - recall_m: 0.8712 - val_loss: 0.5529 - val_accuracy: 0.8500 - val_f1_m: 0.8720 - val_precision_m: 0.9325 - val_recall_m: 0.8214\n",
            "Epoch 90/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2927 - accuracy: 0.9237 - f1_m: 0.9238 - precision_m: 0.9572 - recall_m: 0.8938\n",
            "Epoch 90: val_loss did not improve from 0.51246\n",
            "25/25 [==============================] - 13s 537ms/step - loss: 0.2927 - accuracy: 0.9237 - f1_m: 0.9238 - precision_m: 0.9572 - recall_m: 0.8938 - val_loss: 0.5844 - val_accuracy: 0.8050 - val_f1_m: 0.8340 - val_precision_m: 0.9146 - val_recall_m: 0.7679\n",
            "Epoch 91/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3097 - accuracy: 0.9250 - f1_m: 0.9141 - precision_m: 0.9481 - recall_m: 0.8838\n",
            "Epoch 91: val_loss did not improve from 0.51246\n",
            "25/25 [==============================] - 13s 535ms/step - loss: 0.3097 - accuracy: 0.9250 - f1_m: 0.9141 - precision_m: 0.9481 - recall_m: 0.8838 - val_loss: 0.5521 - val_accuracy: 0.8600 - val_f1_m: 0.8771 - val_precision_m: 0.9262 - val_recall_m: 0.8348\n",
            "Epoch 92/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2837 - accuracy: 0.9175 - f1_m: 0.9164 - precision_m: 0.9526 - recall_m: 0.8838\n",
            "Epoch 92: val_loss did not improve from 0.51246\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.2837 - accuracy: 0.9175 - f1_m: 0.9164 - precision_m: 0.9526 - recall_m: 0.8838 - val_loss: 0.5889 - val_accuracy: 0.8250 - val_f1_m: 0.8306 - val_precision_m: 0.9002 - val_recall_m: 0.7723\n",
            "Epoch 93/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2982 - accuracy: 0.9162 - f1_m: 0.9085 - precision_m: 0.9441 - recall_m: 0.8763\n",
            "Epoch 93: val_loss did not improve from 0.51246\n",
            "25/25 [==============================] - 13s 535ms/step - loss: 0.2982 - accuracy: 0.9162 - f1_m: 0.9085 - precision_m: 0.9441 - recall_m: 0.8763 - val_loss: 0.5454 - val_accuracy: 0.8500 - val_f1_m: 0.8606 - val_precision_m: 0.9174 - val_recall_m: 0.8125\n",
            "Epoch 94/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3055 - accuracy: 0.9175 - f1_m: 0.9131 - precision_m: 0.9471 - recall_m: 0.8825\n",
            "Epoch 94: val_loss did not improve from 0.51246\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.3055 - accuracy: 0.9175 - f1_m: 0.9131 - precision_m: 0.9471 - recall_m: 0.8825 - val_loss: 0.5718 - val_accuracy: 0.8350 - val_f1_m: 0.8440 - val_precision_m: 0.8796 - val_recall_m: 0.8125\n",
            "Epoch 95/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2909 - accuracy: 0.9212 - f1_m: 0.9105 - precision_m: 0.9472 - recall_m: 0.8775\n",
            "Epoch 95: val_loss did not improve from 0.51246\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.2909 - accuracy: 0.9212 - f1_m: 0.9105 - precision_m: 0.9472 - recall_m: 0.8775 - val_loss: 0.5828 - val_accuracy: 0.8250 - val_f1_m: 0.8103 - val_precision_m: 0.8711 - val_recall_m: 0.7589\n",
            "Epoch 96/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2750 - accuracy: 0.9250 - f1_m: 0.9218 - precision_m: 0.9473 - recall_m: 0.8988\n",
            "Epoch 96: val_loss did not improve from 0.51246\n",
            "25/25 [==============================] - 13s 535ms/step - loss: 0.2750 - accuracy: 0.9250 - f1_m: 0.9218 - precision_m: 0.9473 - recall_m: 0.8988 - val_loss: 0.5419 - val_accuracy: 0.8100 - val_f1_m: 0.8335 - val_precision_m: 0.8937 - val_recall_m: 0.7812\n",
            "Epoch 97/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2719 - accuracy: 0.9187 - f1_m: 0.9154 - precision_m: 0.9503 - recall_m: 0.8838\n",
            "Epoch 97: val_loss improved from 0.51246 to 0.50325, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 581ms/step - loss: 0.2719 - accuracy: 0.9187 - f1_m: 0.9154 - precision_m: 0.9503 - recall_m: 0.8838 - val_loss: 0.5032 - val_accuracy: 0.8750 - val_f1_m: 0.8885 - val_precision_m: 0.9342 - val_recall_m: 0.8482\n",
            "Epoch 98/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2380 - accuracy: 0.9300 - f1_m: 0.9360 - precision_m: 0.9666 - recall_m: 0.9087\n",
            "Epoch 98: val_loss did not improve from 0.50325\n",
            "25/25 [==============================] - 13s 535ms/step - loss: 0.2380 - accuracy: 0.9300 - f1_m: 0.9360 - precision_m: 0.9666 - recall_m: 0.9087 - val_loss: 0.5224 - val_accuracy: 0.8550 - val_f1_m: 0.8755 - val_precision_m: 0.9297 - val_recall_m: 0.8304\n",
            "Epoch 99/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2232 - accuracy: 0.9488 - f1_m: 0.9423 - precision_m: 0.9753 - recall_m: 0.9125\n",
            "Epoch 99: val_loss improved from 0.50325 to 0.47614, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 571ms/step - loss: 0.2232 - accuracy: 0.9488 - f1_m: 0.9423 - precision_m: 0.9753 - recall_m: 0.9125 - val_loss: 0.4761 - val_accuracy: 0.8650 - val_f1_m: 0.8795 - val_precision_m: 0.9255 - val_recall_m: 0.8393\n",
            "Epoch 100/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2510 - accuracy: 0.9337 - f1_m: 0.9308 - precision_m: 0.9589 - recall_m: 0.9050\n",
            "Epoch 100: val_loss did not improve from 0.47614\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.2510 - accuracy: 0.9337 - f1_m: 0.9308 - precision_m: 0.9589 - recall_m: 0.9050 - val_loss: 0.5247 - val_accuracy: 0.8800 - val_f1_m: 0.8832 - val_precision_m: 0.9184 - val_recall_m: 0.8527\n",
            "Epoch 101/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2362 - accuracy: 0.9325 - f1_m: 0.9344 - precision_m: 0.9626 - recall_m: 0.9087\n",
            "Epoch 101: val_loss did not improve from 0.47614\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.2362 - accuracy: 0.9325 - f1_m: 0.9344 - precision_m: 0.9626 - recall_m: 0.9087 - val_loss: 0.4914 - val_accuracy: 0.8850 - val_f1_m: 0.8841 - val_precision_m: 0.9138 - val_recall_m: 0.8571\n",
            "Epoch 102/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2389 - accuracy: 0.9425 - f1_m: 0.9363 - precision_m: 0.9679 - recall_m: 0.9075\n",
            "Epoch 102: val_loss improved from 0.47614 to 0.47159, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 571ms/step - loss: 0.2389 - accuracy: 0.9425 - f1_m: 0.9363 - precision_m: 0.9679 - recall_m: 0.9075 - val_loss: 0.4716 - val_accuracy: 0.8750 - val_f1_m: 0.8892 - val_precision_m: 0.9314 - val_recall_m: 0.8527\n",
            "Epoch 103/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2278 - accuracy: 0.9375 - f1_m: 0.9347 - precision_m: 0.9604 - recall_m: 0.9112\n",
            "Epoch 103: val_loss did not improve from 0.47159\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.2278 - accuracy: 0.9375 - f1_m: 0.9347 - precision_m: 0.9604 - recall_m: 0.9112 - val_loss: 0.4957 - val_accuracy: 0.8750 - val_f1_m: 0.8825 - val_precision_m: 0.9210 - val_recall_m: 0.8482\n",
            "Epoch 104/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2376 - accuracy: 0.9375 - f1_m: 0.9315 - precision_m: 0.9566 - recall_m: 0.9087\n",
            "Epoch 104: val_loss did not improve from 0.47159\n",
            "25/25 [==============================] - 13s 537ms/step - loss: 0.2376 - accuracy: 0.9375 - f1_m: 0.9315 - precision_m: 0.9566 - recall_m: 0.9087 - val_loss: 0.5239 - val_accuracy: 0.8450 - val_f1_m: 0.8720 - val_precision_m: 0.9037 - val_recall_m: 0.8438\n",
            "Epoch 105/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2221 - accuracy: 0.9362 - f1_m: 0.9408 - precision_m: 0.9636 - recall_m: 0.9200\n",
            "Epoch 105: val_loss did not improve from 0.47159\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.2221 - accuracy: 0.9362 - f1_m: 0.9408 - precision_m: 0.9636 - recall_m: 0.9200 - val_loss: 0.4894 - val_accuracy: 0.8700 - val_f1_m: 0.8791 - val_precision_m: 0.9131 - val_recall_m: 0.8482\n",
            "Epoch 106/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2373 - accuracy: 0.9312 - f1_m: 0.9281 - precision_m: 0.9520 - recall_m: 0.9062\n",
            "Epoch 106: val_loss improved from 0.47159 to 0.46082, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 568ms/step - loss: 0.2373 - accuracy: 0.9312 - f1_m: 0.9281 - precision_m: 0.9520 - recall_m: 0.9062 - val_loss: 0.4608 - val_accuracy: 0.8900 - val_f1_m: 0.8954 - val_precision_m: 0.9273 - val_recall_m: 0.8661\n",
            "Epoch 107/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2034 - accuracy: 0.9463 - f1_m: 0.9504 - precision_m: 0.9740 - recall_m: 0.9287\n",
            "Epoch 107: val_loss did not improve from 0.46082\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.2034 - accuracy: 0.9463 - f1_m: 0.9504 - precision_m: 0.9740 - recall_m: 0.9287 - val_loss: 0.4797 - val_accuracy: 0.8600 - val_f1_m: 0.8697 - val_precision_m: 0.9037 - val_recall_m: 0.8393\n",
            "Epoch 108/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1910 - accuracy: 0.9538 - f1_m: 0.9525 - precision_m: 0.9727 - recall_m: 0.9337\n",
            "Epoch 108: val_loss did not improve from 0.46082\n",
            "25/25 [==============================] - 13s 535ms/step - loss: 0.1910 - accuracy: 0.9538 - f1_m: 0.9525 - precision_m: 0.9727 - recall_m: 0.9337 - val_loss: 0.4842 - val_accuracy: 0.8550 - val_f1_m: 0.8637 - val_precision_m: 0.9022 - val_recall_m: 0.8304\n",
            "Epoch 109/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2046 - accuracy: 0.9463 - f1_m: 0.9471 - precision_m: 0.9696 - recall_m: 0.9262\n",
            "Epoch 109: val_loss did not improve from 0.46082\n",
            "25/25 [==============================] - 13s 537ms/step - loss: 0.2046 - accuracy: 0.9463 - f1_m: 0.9471 - precision_m: 0.9696 - recall_m: 0.9262 - val_loss: 0.4827 - val_accuracy: 0.8600 - val_f1_m: 0.8897 - val_precision_m: 0.9215 - val_recall_m: 0.8616\n",
            "Epoch 110/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1917 - accuracy: 0.9588 - f1_m: 0.9575 - precision_m: 0.9764 - recall_m: 0.9400\n",
            "Epoch 110: val_loss did not improve from 0.46082\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.1917 - accuracy: 0.9588 - f1_m: 0.9575 - precision_m: 0.9764 - recall_m: 0.9400 - val_loss: 0.4822 - val_accuracy: 0.8600 - val_f1_m: 0.8812 - val_precision_m: 0.9201 - val_recall_m: 0.8482\n",
            "Epoch 111/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1793 - accuracy: 0.9450 - f1_m: 0.9495 - precision_m: 0.9637 - recall_m: 0.9362\n",
            "Epoch 111: val_loss did not improve from 0.46082\n",
            "25/25 [==============================] - 13s 537ms/step - loss: 0.1793 - accuracy: 0.9450 - f1_m: 0.9495 - precision_m: 0.9637 - recall_m: 0.9362 - val_loss: 0.5050 - val_accuracy: 0.8600 - val_f1_m: 0.8778 - val_precision_m: 0.9175 - val_recall_m: 0.8438\n",
            "Epoch 112/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2048 - accuracy: 0.9413 - f1_m: 0.9416 - precision_m: 0.9637 - recall_m: 0.9212\n",
            "Epoch 112: val_loss did not improve from 0.46082\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.2048 - accuracy: 0.9413 - f1_m: 0.9416 - precision_m: 0.9637 - recall_m: 0.9212 - val_loss: 0.5431 - val_accuracy: 0.8350 - val_f1_m: 0.8594 - val_precision_m: 0.8934 - val_recall_m: 0.8304\n",
            "Epoch 113/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1980 - accuracy: 0.9500 - f1_m: 0.9479 - precision_m: 0.9689 - recall_m: 0.9287\n",
            "Epoch 113: val_loss did not improve from 0.46082\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.1980 - accuracy: 0.9500 - f1_m: 0.9479 - precision_m: 0.9689 - recall_m: 0.9287 - val_loss: 0.5086 - val_accuracy: 0.8500 - val_f1_m: 0.8716 - val_precision_m: 0.9092 - val_recall_m: 0.8393\n",
            "Epoch 114/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1903 - accuracy: 0.9575 - f1_m: 0.9549 - precision_m: 0.9723 - recall_m: 0.9388\n",
            "Epoch 114: val_loss did not improve from 0.46082\n",
            "25/25 [==============================] - 13s 534ms/step - loss: 0.1903 - accuracy: 0.9575 - f1_m: 0.9549 - precision_m: 0.9723 - recall_m: 0.9388 - val_loss: 0.5559 - val_accuracy: 0.8450 - val_f1_m: 0.8463 - val_precision_m: 0.8965 - val_recall_m: 0.8036\n",
            "Epoch 115/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1903 - accuracy: 0.9513 - f1_m: 0.9426 - precision_m: 0.9638 - recall_m: 0.9237\n",
            "Epoch 115: val_loss did not improve from 0.46082\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.1903 - accuracy: 0.9513 - f1_m: 0.9426 - precision_m: 0.9638 - recall_m: 0.9237 - val_loss: 0.5056 - val_accuracy: 0.8500 - val_f1_m: 0.8560 - val_precision_m: 0.8840 - val_recall_m: 0.8304\n",
            "Epoch 116/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1727 - accuracy: 0.9563 - f1_m: 0.9539 - precision_m: 0.9703 - recall_m: 0.9388\n",
            "Epoch 116: val_loss did not improve from 0.46082\n",
            "25/25 [==============================] - 13s 537ms/step - loss: 0.1727 - accuracy: 0.9563 - f1_m: 0.9539 - precision_m: 0.9703 - recall_m: 0.9388 - val_loss: 0.5442 - val_accuracy: 0.8250 - val_f1_m: 0.8262 - val_precision_m: 0.8712 - val_recall_m: 0.7857\n",
            "Epoch 117/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1711 - accuracy: 0.9538 - f1_m: 0.9560 - precision_m: 0.9728 - recall_m: 0.9400\n",
            "Epoch 117: val_loss did not improve from 0.46082\n",
            "25/25 [==============================] - 13s 538ms/step - loss: 0.1711 - accuracy: 0.9538 - f1_m: 0.9560 - precision_m: 0.9728 - recall_m: 0.9400 - val_loss: 0.5001 - val_accuracy: 0.8400 - val_f1_m: 0.8521 - val_precision_m: 0.8813 - val_recall_m: 0.8259\n",
            "Epoch 118/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1734 - accuracy: 0.9625 - f1_m: 0.9547 - precision_m: 0.9716 - recall_m: 0.9388\n",
            "Epoch 118: val_loss did not improve from 0.46082\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.1734 - accuracy: 0.9625 - f1_m: 0.9547 - precision_m: 0.9716 - recall_m: 0.9388 - val_loss: 0.4800 - val_accuracy: 0.8550 - val_f1_m: 0.8870 - val_precision_m: 0.9148 - val_recall_m: 0.8616\n",
            "Epoch 119/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1538 - accuracy: 0.9625 - f1_m: 0.9634 - precision_m: 0.9793 - recall_m: 0.9488\n",
            "Epoch 119: val_loss did not improve from 0.46082\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.1538 - accuracy: 0.9625 - f1_m: 0.9634 - precision_m: 0.9793 - recall_m: 0.9488 - val_loss: 0.4815 - val_accuracy: 0.8600 - val_f1_m: 0.8798 - val_precision_m: 0.9104 - val_recall_m: 0.8527\n",
            "Epoch 120/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1610 - accuracy: 0.9638 - f1_m: 0.9627 - precision_m: 0.9830 - recall_m: 0.9438\n",
            "Epoch 120: val_loss did not improve from 0.46082\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.1610 - accuracy: 0.9638 - f1_m: 0.9627 - precision_m: 0.9830 - recall_m: 0.9438 - val_loss: 0.4816 - val_accuracy: 0.8650 - val_f1_m: 0.8710 - val_precision_m: 0.9016 - val_recall_m: 0.8438\n",
            "Epoch 121/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1672 - accuracy: 0.9525 - f1_m: 0.9536 - precision_m: 0.9722 - recall_m: 0.9362\n",
            "Epoch 121: val_loss did not improve from 0.46082\n",
            "25/25 [==============================] - 13s 537ms/step - loss: 0.1672 - accuracy: 0.9525 - f1_m: 0.9536 - precision_m: 0.9722 - recall_m: 0.9362 - val_loss: 0.4978 - val_accuracy: 0.8500 - val_f1_m: 0.8573 - val_precision_m: 0.8870 - val_recall_m: 0.8304\n",
            "Epoch 122/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1399 - accuracy: 0.9638 - f1_m: 0.9637 - precision_m: 0.9768 - recall_m: 0.9513\n",
            "Epoch 122: val_loss did not improve from 0.46082\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.1399 - accuracy: 0.9638 - f1_m: 0.9637 - precision_m: 0.9768 - recall_m: 0.9513 - val_loss: 0.4848 - val_accuracy: 0.8550 - val_f1_m: 0.8755 - val_precision_m: 0.9011 - val_recall_m: 0.8527\n",
            "Epoch 123/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1354 - accuracy: 0.9712 - f1_m: 0.9669 - precision_m: 0.9821 - recall_m: 0.9525\n",
            "Epoch 123: val_loss improved from 0.46082 to 0.45779, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 567ms/step - loss: 0.1354 - accuracy: 0.9712 - f1_m: 0.9669 - precision_m: 0.9821 - recall_m: 0.9525 - val_loss: 0.4578 - val_accuracy: 0.8650 - val_f1_m: 0.8743 - val_precision_m: 0.9137 - val_recall_m: 0.8393\n",
            "Epoch 124/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1582 - accuracy: 0.9588 - f1_m: 0.9573 - precision_m: 0.9715 - recall_m: 0.9438\n",
            "Epoch 124: val_loss did not improve from 0.45779\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.1582 - accuracy: 0.9588 - f1_m: 0.9573 - precision_m: 0.9715 - recall_m: 0.9438 - val_loss: 0.4823 - val_accuracy: 0.8600 - val_f1_m: 0.8741 - val_precision_m: 0.9073 - val_recall_m: 0.8438\n",
            "Epoch 125/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1523 - accuracy: 0.9675 - f1_m: 0.9592 - precision_m: 0.9769 - recall_m: 0.9425\n",
            "Epoch 125: val_loss did not improve from 0.45779\n",
            "25/25 [==============================] - 13s 535ms/step - loss: 0.1523 - accuracy: 0.9675 - f1_m: 0.9592 - precision_m: 0.9769 - recall_m: 0.9425 - val_loss: 0.4832 - val_accuracy: 0.8550 - val_f1_m: 0.8753 - val_precision_m: 0.8999 - val_recall_m: 0.8527\n",
            "Epoch 126/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1474 - accuracy: 0.9625 - f1_m: 0.9604 - precision_m: 0.9742 - recall_m: 0.9475\n",
            "Epoch 126: val_loss did not improve from 0.45779\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.1474 - accuracy: 0.9625 - f1_m: 0.9604 - precision_m: 0.9742 - recall_m: 0.9475 - val_loss: 0.5185 - val_accuracy: 0.8500 - val_f1_m: 0.8755 - val_precision_m: 0.9005 - val_recall_m: 0.8527\n",
            "Epoch 127/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1604 - accuracy: 0.9625 - f1_m: 0.9621 - precision_m: 0.9793 - recall_m: 0.9463\n",
            "Epoch 127: val_loss did not improve from 0.45779\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.1604 - accuracy: 0.9625 - f1_m: 0.9621 - precision_m: 0.9793 - recall_m: 0.9463 - val_loss: 0.4661 - val_accuracy: 0.8450 - val_f1_m: 0.8763 - val_precision_m: 0.9129 - val_recall_m: 0.8438\n",
            "Epoch 128/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1277 - accuracy: 0.9688 - f1_m: 0.9653 - precision_m: 0.9830 - recall_m: 0.9488\n",
            "Epoch 128: val_loss did not improve from 0.45779\n",
            "25/25 [==============================] - 13s 537ms/step - loss: 0.1277 - accuracy: 0.9688 - f1_m: 0.9653 - precision_m: 0.9830 - recall_m: 0.9488 - val_loss: 0.4711 - val_accuracy: 0.8700 - val_f1_m: 0.9036 - val_precision_m: 0.9245 - val_recall_m: 0.8839\n",
            "Epoch 129/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1444 - accuracy: 0.9663 - f1_m: 0.9619 - precision_m: 0.9733 - recall_m: 0.9513\n",
            "Epoch 129: val_loss improved from 0.45779 to 0.44202, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 572ms/step - loss: 0.1444 - accuracy: 0.9663 - f1_m: 0.9619 - precision_m: 0.9733 - recall_m: 0.9513 - val_loss: 0.4420 - val_accuracy: 0.8750 - val_f1_m: 0.8852 - val_precision_m: 0.9065 - val_recall_m: 0.8661\n",
            "Epoch 130/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1421 - accuracy: 0.9650 - f1_m: 0.9624 - precision_m: 0.9756 - recall_m: 0.9500\n",
            "Epoch 130: val_loss did not improve from 0.44202\n",
            "25/25 [==============================] - 13s 535ms/step - loss: 0.1421 - accuracy: 0.9650 - f1_m: 0.9624 - precision_m: 0.9756 - recall_m: 0.9500 - val_loss: 0.4543 - val_accuracy: 0.8700 - val_f1_m: 0.8897 - val_precision_m: 0.9109 - val_recall_m: 0.8705\n",
            "Epoch 131/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1465 - accuracy: 0.9638 - f1_m: 0.9651 - precision_m: 0.9770 - recall_m: 0.9538\n",
            "Epoch 131: val_loss did not improve from 0.44202\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.1465 - accuracy: 0.9638 - f1_m: 0.9651 - precision_m: 0.9770 - recall_m: 0.9538 - val_loss: 0.4810 - val_accuracy: 0.8550 - val_f1_m: 0.8845 - val_precision_m: 0.9096 - val_recall_m: 0.8616\n",
            "Epoch 132/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1176 - accuracy: 0.9762 - f1_m: 0.9721 - precision_m: 0.9822 - recall_m: 0.9625\n",
            "Epoch 132: val_loss did not improve from 0.44202\n",
            "25/25 [==============================] - 13s 537ms/step - loss: 0.1176 - accuracy: 0.9762 - f1_m: 0.9721 - precision_m: 0.9822 - recall_m: 0.9625 - val_loss: 0.4653 - val_accuracy: 0.8650 - val_f1_m: 0.8807 - val_precision_m: 0.9072 - val_recall_m: 0.8571\n",
            "Epoch 133/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1061 - accuracy: 0.9850 - f1_m: 0.9823 - precision_m: 0.9911 - recall_m: 0.9737\n",
            "Epoch 133: val_loss did not improve from 0.44202\n",
            "25/25 [==============================] - 13s 534ms/step - loss: 0.1061 - accuracy: 0.9850 - f1_m: 0.9823 - precision_m: 0.9911 - recall_m: 0.9737 - val_loss: 0.5183 - val_accuracy: 0.8500 - val_f1_m: 0.8758 - val_precision_m: 0.8961 - val_recall_m: 0.8571\n",
            "Epoch 134/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1285 - accuracy: 0.9800 - f1_m: 0.9769 - precision_m: 0.9910 - recall_m: 0.9638\n",
            "Epoch 134: val_loss did not improve from 0.44202\n",
            "25/25 [==============================] - 13s 537ms/step - loss: 0.1285 - accuracy: 0.9800 - f1_m: 0.9769 - precision_m: 0.9910 - recall_m: 0.9638 - val_loss: 0.5081 - val_accuracy: 0.8450 - val_f1_m: 0.8712 - val_precision_m: 0.8914 - val_recall_m: 0.8527\n",
            "Epoch 135/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1359 - accuracy: 0.9650 - f1_m: 0.9601 - precision_m: 0.9720 - recall_m: 0.9488\n",
            "Epoch 135: val_loss did not improve from 0.44202\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.1359 - accuracy: 0.9650 - f1_m: 0.9601 - precision_m: 0.9720 - recall_m: 0.9488 - val_loss: 0.4681 - val_accuracy: 0.8800 - val_f1_m: 0.8933 - val_precision_m: 0.9183 - val_recall_m: 0.8705\n",
            "Epoch 136/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1240 - accuracy: 0.9712 - f1_m: 0.9677 - precision_m: 0.9757 - recall_m: 0.9600\n",
            "Epoch 136: val_loss did not improve from 0.44202\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.1240 - accuracy: 0.9712 - f1_m: 0.9677 - precision_m: 0.9757 - recall_m: 0.9600 - val_loss: 0.4854 - val_accuracy: 0.8800 - val_f1_m: 0.8855 - val_precision_m: 0.9167 - val_recall_m: 0.8571\n",
            "Epoch 137/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1327 - accuracy: 0.9613 - f1_m: 0.9637 - precision_m: 0.9716 - recall_m: 0.9563\n",
            "Epoch 137: val_loss did not improve from 0.44202\n",
            "25/25 [==============================] - 13s 538ms/step - loss: 0.1327 - accuracy: 0.9613 - f1_m: 0.9637 - precision_m: 0.9716 - recall_m: 0.9563 - val_loss: 0.4756 - val_accuracy: 0.8800 - val_f1_m: 0.8869 - val_precision_m: 0.9144 - val_recall_m: 0.8616\n",
            "Epoch 138/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1218 - accuracy: 0.9663 - f1_m: 0.9670 - precision_m: 0.9770 - recall_m: 0.9575\n",
            "Epoch 138: val_loss did not improve from 0.44202\n",
            "25/25 [==============================] - 13s 535ms/step - loss: 0.1218 - accuracy: 0.9663 - f1_m: 0.9670 - precision_m: 0.9770 - recall_m: 0.9575 - val_loss: 0.4464 - val_accuracy: 0.8500 - val_f1_m: 0.8870 - val_precision_m: 0.9155 - val_recall_m: 0.8616\n",
            "Epoch 139/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1297 - accuracy: 0.9588 - f1_m: 0.9632 - precision_m: 0.9758 - recall_m: 0.9513\n",
            "Epoch 139: val_loss did not improve from 0.44202\n",
            "25/25 [==============================] - 13s 537ms/step - loss: 0.1297 - accuracy: 0.9588 - f1_m: 0.9632 - precision_m: 0.9758 - recall_m: 0.9513 - val_loss: 0.4850 - val_accuracy: 0.8700 - val_f1_m: 0.8967 - val_precision_m: 0.9206 - val_recall_m: 0.8750\n",
            "Epoch 140/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1211 - accuracy: 0.9775 - f1_m: 0.9724 - precision_m: 0.9845 - recall_m: 0.9613\n",
            "Epoch 140: val_loss did not improve from 0.44202\n",
            "25/25 [==============================] - 14s 549ms/step - loss: 0.1211 - accuracy: 0.9775 - f1_m: 0.9724 - precision_m: 0.9845 - recall_m: 0.9613 - val_loss: 0.4995 - val_accuracy: 0.8450 - val_f1_m: 0.8717 - val_precision_m: 0.8921 - val_recall_m: 0.8527\n",
            "Epoch 141/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1244 - accuracy: 0.9638 - f1_m: 0.9645 - precision_m: 0.9746 - recall_m: 0.9550\n",
            "Epoch 141: val_loss did not improve from 0.44202\n",
            "25/25 [==============================] - 13s 537ms/step - loss: 0.1244 - accuracy: 0.9638 - f1_m: 0.9645 - precision_m: 0.9746 - recall_m: 0.9550 - val_loss: 0.4481 - val_accuracy: 0.8650 - val_f1_m: 0.8925 - val_precision_m: 0.9111 - val_recall_m: 0.8750\n",
            "Epoch 142/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1136 - accuracy: 0.9762 - f1_m: 0.9714 - precision_m: 0.9835 - recall_m: 0.9600\n",
            "Epoch 142: val_loss did not improve from 0.44202\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.1136 - accuracy: 0.9762 - f1_m: 0.9714 - precision_m: 0.9835 - recall_m: 0.9600 - val_loss: 0.4558 - val_accuracy: 0.8700 - val_f1_m: 0.8855 - val_precision_m: 0.9024 - val_recall_m: 0.8705\n",
            "Epoch 143/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1188 - accuracy: 0.9750 - f1_m: 0.9758 - precision_m: 0.9899 - recall_m: 0.9625\n",
            "Epoch 143: val_loss did not improve from 0.44202\n",
            "25/25 [==============================] - 13s 537ms/step - loss: 0.1188 - accuracy: 0.9750 - f1_m: 0.9758 - precision_m: 0.9899 - recall_m: 0.9625 - val_loss: 0.4579 - val_accuracy: 0.8750 - val_f1_m: 0.8904 - val_precision_m: 0.9071 - val_recall_m: 0.8750\n",
            "Epoch 144/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0990 - accuracy: 0.9812 - f1_m: 0.9787 - precision_m: 0.9824 - recall_m: 0.9750\n",
            "Epoch 144: val_loss did not improve from 0.44202\n",
            "25/25 [==============================] - 13s 535ms/step - loss: 0.0990 - accuracy: 0.9812 - f1_m: 0.9787 - precision_m: 0.9824 - recall_m: 0.9750 - val_loss: 0.4705 - val_accuracy: 0.8750 - val_f1_m: 0.8876 - val_precision_m: 0.9059 - val_recall_m: 0.8705\n",
            "Epoch 145/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1114 - accuracy: 0.9775 - f1_m: 0.9761 - precision_m: 0.9798 - recall_m: 0.9725\n",
            "Epoch 145: val_loss did not improve from 0.44202\n",
            "25/25 [==============================] - 13s 538ms/step - loss: 0.1114 - accuracy: 0.9775 - f1_m: 0.9761 - precision_m: 0.9798 - recall_m: 0.9725 - val_loss: 0.4829 - val_accuracy: 0.8600 - val_f1_m: 0.8740 - val_precision_m: 0.8927 - val_recall_m: 0.8571\n",
            "Epoch 146/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0934 - accuracy: 0.9787 - f1_m: 0.9771 - precision_m: 0.9860 - recall_m: 0.9688\n",
            "Epoch 146: val_loss did not improve from 0.44202\n",
            "25/25 [==============================] - 13s 538ms/step - loss: 0.0934 - accuracy: 0.9787 - f1_m: 0.9771 - precision_m: 0.9860 - recall_m: 0.9688 - val_loss: 0.4930 - val_accuracy: 0.8700 - val_f1_m: 0.8759 - val_precision_m: 0.8963 - val_recall_m: 0.8571\n",
            "Epoch 147/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1028 - accuracy: 0.9775 - f1_m: 0.9790 - precision_m: 0.9885 - recall_m: 0.9700\n",
            "Epoch 147: val_loss did not improve from 0.44202\n",
            "25/25 [==============================] - 13s 538ms/step - loss: 0.1028 - accuracy: 0.9775 - f1_m: 0.9790 - precision_m: 0.9885 - recall_m: 0.9700 - val_loss: 0.4688 - val_accuracy: 0.8700 - val_f1_m: 0.8829 - val_precision_m: 0.9067 - val_recall_m: 0.8616\n",
            "Epoch 148/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1054 - accuracy: 0.9787 - f1_m: 0.9766 - precision_m: 0.9835 - recall_m: 0.9700\n",
            "Epoch 148: val_loss did not improve from 0.44202\n",
            "25/25 [==============================] - 13s 538ms/step - loss: 0.1054 - accuracy: 0.9787 - f1_m: 0.9766 - precision_m: 0.9835 - recall_m: 0.9700 - val_loss: 0.4566 - val_accuracy: 0.8800 - val_f1_m: 0.8928 - val_precision_m: 0.9067 - val_recall_m: 0.8795\n",
            "Epoch 149/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0866 - accuracy: 0.9800 - f1_m: 0.9792 - precision_m: 0.9848 - recall_m: 0.9737\n",
            "Epoch 149: val_loss did not improve from 0.44202\n",
            "25/25 [==============================] - 13s 538ms/step - loss: 0.0866 - accuracy: 0.9800 - f1_m: 0.9792 - precision_m: 0.9848 - recall_m: 0.9737 - val_loss: 0.4875 - val_accuracy: 0.8600 - val_f1_m: 0.8786 - val_precision_m: 0.8968 - val_recall_m: 0.8616\n",
            "Epoch 150/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0867 - accuracy: 0.9837 - f1_m: 0.9810 - precision_m: 0.9885 - recall_m: 0.9737\n",
            "Epoch 150: val_loss did not improve from 0.44202\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.0867 - accuracy: 0.9837 - f1_m: 0.9810 - precision_m: 0.9885 - recall_m: 0.9737 - val_loss: 0.5089 - val_accuracy: 0.8600 - val_f1_m: 0.8874 - val_precision_m: 0.9107 - val_recall_m: 0.8661\n",
            "Epoch 151/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0945 - accuracy: 0.9737 - f1_m: 0.9715 - precision_m: 0.9785 - recall_m: 0.9650\n",
            "Epoch 151: val_loss did not improve from 0.44202\n",
            "25/25 [==============================] - 13s 537ms/step - loss: 0.0945 - accuracy: 0.9737 - f1_m: 0.9715 - precision_m: 0.9785 - recall_m: 0.9650 - val_loss: 0.5066 - val_accuracy: 0.8800 - val_f1_m: 0.8973 - val_precision_m: 0.9163 - val_recall_m: 0.8795\n",
            "Epoch 152/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0908 - accuracy: 0.9812 - f1_m: 0.9772 - precision_m: 0.9835 - recall_m: 0.9712\n",
            "Epoch 152: val_loss did not improve from 0.44202\n",
            "25/25 [==============================] - 13s 538ms/step - loss: 0.0908 - accuracy: 0.9812 - f1_m: 0.9772 - precision_m: 0.9835 - recall_m: 0.9712 - val_loss: 0.5101 - val_accuracy: 0.8700 - val_f1_m: 0.8941 - val_precision_m: 0.9148 - val_recall_m: 0.8750\n",
            "Epoch 153/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0883 - accuracy: 0.9762 - f1_m: 0.9766 - precision_m: 0.9848 - recall_m: 0.9688\n",
            "Epoch 153: val_loss did not improve from 0.44202\n",
            "25/25 [==============================] - 13s 537ms/step - loss: 0.0883 - accuracy: 0.9762 - f1_m: 0.9766 - precision_m: 0.9848 - recall_m: 0.9688 - val_loss: 0.4792 - val_accuracy: 0.8800 - val_f1_m: 0.8947 - val_precision_m: 0.9110 - val_recall_m: 0.8795\n",
            "Epoch 154/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9862 - f1_m: 0.9867 - precision_m: 0.9925 - recall_m: 0.9812\n",
            "Epoch 154: val_loss did not improve from 0.44202\n",
            "25/25 [==============================] - 13s 536ms/step - loss: 0.0764 - accuracy: 0.9862 - f1_m: 0.9867 - precision_m: 0.9925 - recall_m: 0.9812 - val_loss: 0.5238 - val_accuracy: 0.8700 - val_f1_m: 0.8897 - val_precision_m: 0.9057 - val_recall_m: 0.8750\n",
            "Epoch 155/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0758 - accuracy: 0.9862 - f1_m: 0.9836 - precision_m: 0.9899 - recall_m: 0.9775\n",
            "Epoch 155: val_loss did not improve from 0.44202\n",
            "25/25 [==============================] - 13s 537ms/step - loss: 0.0758 - accuracy: 0.9862 - f1_m: 0.9836 - precision_m: 0.9899 - recall_m: 0.9775 - val_loss: 0.4723 - val_accuracy: 0.8800 - val_f1_m: 0.8865 - val_precision_m: 0.8984 - val_recall_m: 0.8750\n",
            "Epoch 156/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0684 - accuracy: 0.9862 - f1_m: 0.9861 - precision_m: 0.9912 - recall_m: 0.9812\n",
            "Epoch 156: val_loss did not improve from 0.44202\n",
            "25/25 [==============================] - 13s 538ms/step - loss: 0.0684 - accuracy: 0.9862 - f1_m: 0.9861 - precision_m: 0.9912 - recall_m: 0.9812 - val_loss: 0.4730 - val_accuracy: 0.8750 - val_f1_m: 0.8992 - val_precision_m: 0.9158 - val_recall_m: 0.8839\n",
            "Epoch 157/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0831 - accuracy: 0.9787 - f1_m: 0.9786 - precision_m: 0.9849 - recall_m: 0.9725\n",
            "Epoch 157: val_loss did not improve from 0.44202\n",
            "25/25 [==============================] - 13s 537ms/step - loss: 0.0831 - accuracy: 0.9787 - f1_m: 0.9786 - precision_m: 0.9849 - recall_m: 0.9725 - val_loss: 0.4780 - val_accuracy: 0.8750 - val_f1_m: 0.8936 - val_precision_m: 0.9143 - val_recall_m: 0.8750\n",
            "Epoch 158/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1021 - accuracy: 0.9712 - f1_m: 0.9733 - precision_m: 0.9833 - recall_m: 0.9638\n",
            "Epoch 158: val_loss did not improve from 0.44202\n",
            "25/25 [==============================] - 13s 538ms/step - loss: 0.1021 - accuracy: 0.9712 - f1_m: 0.9733 - precision_m: 0.9833 - recall_m: 0.9638 - val_loss: 0.4717 - val_accuracy: 0.8650 - val_f1_m: 0.8929 - val_precision_m: 0.9078 - val_recall_m: 0.8795\n",
            "Epoch 159/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0759 - accuracy: 0.9875 - f1_m: 0.9841 - precision_m: 0.9897 - recall_m: 0.9787\n",
            "Epoch 159: val_loss did not improve from 0.44202\n",
            "25/25 [==============================] - 13s 537ms/step - loss: 0.0759 - accuracy: 0.9875 - f1_m: 0.9841 - precision_m: 0.9897 - recall_m: 0.9787 - val_loss: 0.4701 - val_accuracy: 0.8850 - val_f1_m: 0.8949 - val_precision_m: 0.9112 - val_recall_m: 0.8795\n",
            "Epoch 160/160\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0827 - accuracy: 0.9787 - f1_m: 0.9779 - precision_m: 0.9860 - recall_m: 0.9700\n",
            "Epoch 160: val_loss improved from 0.44202 to 0.43016, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_cnn.hdf5\n",
            "25/25 [==============================] - 14s 569ms/step - loss: 0.0827 - accuracy: 0.9787 - f1_m: 0.9779 - precision_m: 0.9860 - recall_m: 0.9700 - val_loss: 0.4302 - val_accuracy: 0.8850 - val_f1_m: 0.9071 - val_precision_m: 0.9175 - val_recall_m: 0.8973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Plots and Evaluation Metrices**"
      ],
      "metadata": {
        "id": "HnlfDZx5k6ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "model.metrics_names\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HrkY2VZoSnDC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "54151bbd-e1b6-4520-aed1-cdef22d301ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3iUVdrA4d+ZSQ9ppEAKIfTeQxNEFBWkqYgiVlYBy9p1d13dVVf323VXV117WbCCoGAvoChdWug1BEhCEpKQXkmbOd8fZ0IKCQRIGEie+7pyzcxbZs6E8D7vac9RWmuEEEK0XBZnF0AIIYRzSSAQQogWTgKBEEK0cBIIhBCihZNAIIQQLZwEAiGEaOEkEIgWRSn1gVLq7w08NkEpdXlTl0kIZ5NAIIQQLZwEAiEuQEopF2eXQTQfEgjEecfRJPMHpdQOpVSRUmqOUqqNUupHpVSBUmqZUiqg2vGTlVK7lVK5SqkVSqke1fYNUEptcZy3EPCo9VkTlVLbHOf+ppTq28AyTlBKbVVK5SulkpRSz9TaP9LxfrmO/TMc2z2VUv9RSiUqpfKUUmsc20YrpZLr+D1c7nj+jFJqkVLqE6VUPjBDKTVEKbXO8RmpSqnXlVJu1c7vpZT6WSmVrZRKV0o9oZRqq5QqVkoFVjtuoFIqQynl2pDvLpofCQTifHUdcAXQFZgE/Ag8AQRj/m4fAFBKdQU+BR5y7PsB+FYp5ea4KH4FfAy0Bj53vC+OcwcAc4G7gEDgHeAbpZR7A8pXBNwG+AMTgHuUUtc43re9o7yvOcrUH9jmOO9FYBBwkaNMfwTsDfydXA0scnzmPMAGPAwEAcOBMcC9jjL4AMuAJUAY0Bn4RWudBqwAbqj2vrcCC7TW5Q0sh2hmJBCI89VrWut0rXUKsBrYoLXeqrUuAb4EBjiOmwZ8r7X+2XEhexHwxFxohwGuwCta63Kt9SJgU7XPmA28o7XeoLW2aa0/BEod552U1nqF1nqn1tqutd6BCUaXOHbfBCzTWn/q+NwsrfU2pZQFuAN4UGud4vjM37TWpQ38nazTWn/l+MxjWuvNWuv1WusKrXUCJpBVlmEikKa1/o/WukRrXaC13uDY9yFwC4BSygpMxwRL0UJJIBDnq/Rqz4/V8bqV43kYkFi5Q2ttB5KAcMe+FF0zs2JiteftgUcdTSu5SqlcoJ3jvJNSSg1VSi13NKnkAXdj7sxxvMfBOk4LwjRN1bWvIZJqlaGrUuo7pVSao7noHw0oA8DXQE+lVAdMrStPa73xDMskmgEJBOJCdwRzQQdAKaUwF8EUIBUId2yrFFnteRLwf1pr/2o/XlrrTxvwufOBb4B2Wms/4G2g8nOSgE51nJMJlNSzrwjwqvY9rJhmpepqpwp+C9gHdNFa+2KazqqXoWNdBXfUqj7D1ApuRWoDLZ4EAnGh+wyYoJQa4+jsfBTTvPMbsA6oAB5QSrkqpaYAQ6qd+x5wt+PuXimlvB2dwD4N+FwfIFtrXaKUGoJpDqo0D7hcKXWDUspFKRWolOrvqK3MBV5SSoUppaxKqeGOPon9gIfj812BvwCn6qvwAfKBQqVUd+Ceavu+A0KVUg8ppdyVUj5KqaHV9n8EzAAmI4GgxZNAIC5oWutYzJ3ta5g77knAJK11mda6DJiCueBlY/oTvqh2bgwwC3gdyAEOOI5tiHuBZ5VSBcBTmIBU+b6HgfGYoJSN6Sju59j9GLAT01eRDfwLsGit8xzv+T9MbaYIqDGKqA6PYQJQASaoLaxWhgJMs88kIA2IAy6ttn8tppN6i9a6enOZaIGULEwjRMuklPoVmK+1/p+zyyKcSwKBEC2QUmow8DOmj6PA2eURziVNQ0K0MEqpDzFzDB6SICBAagRCCNHiSY1ACCFauAsucVVQUJCOiopydjGEEOKCsnnz5kytde25KcAFGAiioqKIiYlxdjGEEOKCopSqd5iwNA0JIUQLJ4FACCFauCYLBEqpuUqpo0qpXfXsV0qpV5VSB5TJOz+wqcoihBCifk3ZR/ABZur+R/Xsvwro4vgZikmgNbSeY0+qvLyc5ORkSkpKzuT0C4aHhwcRERG4usr6IUKIxtNkgUBrvUopFXWSQ64GPnKkCF6vlPJXSoVqrVNP97OSk5Px8fEhKiqKmokmmw+tNVlZWSQnJ9OhQwdnF0cI0Yw4s48gnJr51ZMd206glJqtlIpRSsVkZGScsL+kpITAwMBmGwQAlFIEBgY2+1qPEOLcuyA6i7XW72qto7XW0cHBdQ6DbdZBoFJL+I5CiHPPmfMIUjALiFSKcGwTQohmr7TCxq6UPKpn+ekc0gp/L7cax3234wh9w/2JDPSiqTgzEHwD3KeUWoDpJM47k/6B80Fubi7z58/n3nvvPa3zxo8fz/z58/H392+ikgnRMhWXVXDvvC2UlNt4YnwP+kY0zv8xu11TYde4uZy8McVm1yzbm86K2KPcd1kXwv090VpTWFqBj4crJeU2bnpvPVsO59Y4L9Dbjf/dHs2AyAAA1h/K4r75Wwn2cWfB7GF0Cm5V18edtSZLOqeU+hQYjVlDNR14GrOQOFrrtx3LB74OjAOKgd85Fgo5qejoaF17ZvHevXvp0aNHo5b/dCQkJDBx4kR27ao5UraiogIXl8aNtc7+rkKc74rLKvjd+5vYlJCNv5cbOcVl/Pmq7sweVdcKoTXZ7Zr4rKIaF1ytNUopNifm8OCCreQWlzN1UATd2vqQmFWMh6uFyNZeFJRUkJBVREJmEXtTC0jLN/153dr4MG/WUJ77bg/fbj/CTUMjySgo5ac96TwzqRcdg70BKCm389x3e0jPL+GVaf0Z17st1775G0dyj2HXGotSfHoWwUAptVlrHV3XvqYcNTT9FPs18Pum+vxz6fHHH+fgwYP0798fV1dXPDw8CAgIYN++fezfv59rrrmGpKQkSkpKePDBB5k9ezZQlS6jsLCQq666ipEjR/Lbb78RHh7O119/jaenp5O/mRAXFq01D3y6lU0J2bw8rT+XdQ/h4YXbeXHpfsb1Cj1l88pbKw/ywtJY5twezZgebfjnj3uZszqeiABPknKOEebvwWXdQ5i3IZFym8bVqqiw6+PNO15uVqICvRnUPoCJfUPxcnfhzg82cfG/lnOs3MbobsF8ujEJm13zlwk9uP2iqBqfPzDSn1kfxXDv/C2M7xPKtqRc/nVdHwZGBjD9vQ1sO5zbJLWCCy4N9alqBH/7djd7juQ36mf2DPPl6Um96t1fvUawYsUKJkyYwK5du44P88zOzqZ169YcO3aMwYMHs3LlSgIDA2sEgs6dOxMTE0P//v254YYbmDx5MrfccssJnyU1AtFcJecU8/DCbYzp0Ya7LzF37yXlNtxdLDUGShSVVrD+UBZ9wv0I8fWo8R7zNxzmiS938teJPblzpPn/l55fwqUvrmBk5yDuHNmBZ77dw81DI7llWPsa55aU2xjx/K9kFZUR5ufB05N7cdfHm7m4SxC+Hq4E+7jzyJVd8fVwJbuojKLSCsL8PSm32UnOOYavhwvBPu4nDOpYvDmZ//thL89M7sXkfmHsTy8gLr2Q8X3a1jkApKTcxqOfbef7nal0CvZm6UOjcLFaKCgpx8fjzOcQOaVG0JINGTKkxlj/V199lS+//BKApKQk4uLiCAwMrHFOhw4d6N+/PwCDBg0iISHhnJVXiHMpv6SchMwiwvw9CWrlDsCO5Fzu+CCGzMJSNifmMDgqgIKSCu76eDPRUQH8dWJPurf1ZXtSLg8u2EpCVjEAXdu0onNIK6ICvQn19+Qf3+/l4i5B/K7anXYbXw9+f2lnXlgay89703G1Wvjr17sI9nGnpNzG/A2Huf+yLsRnFZFVVMYfxnbjhaWx3P3JZjoFe/PurdF4ullrfIfW3m609jadulaLlc4h9d+lXzcogikDw49f9Lu28aFrG596j/dwtfLa9AFc1DmQAe0CcLGa/oizCQKn0uwCwcnu3M8Vb2/v489XrFjBsmXLWLduHV5eXowePbrOuQDu7u7Hn1utVo4dO3ZOyipEQx0rs2G1qFN2lNamteZfS2J5d9VB7NUaIPw8Xfnu/pEA3DpnI63cXfjy3ot4YMFWfj9vK9nFZbQL8GRXSj7jXll9/LwwPw/euGkgidlFbIzPZs+RfJbuTsdm1/h5uvLC1H5YLDXvtO8c2YGVsRl0DPbmsbHduPPDGO76eDMA7i4WZry/EV9PV/q38+fe0Z1Izy/h042HeXla/xOCwJk43aHfFovi5qHtT31gI2l2gcAZfHx8KCioe8W/vLw8AgIC8PLyYt++faxfv/4cl06IM6O1xmbXx5slJr22hmAfdxbOHn7ChXZzYjZPfb2bqYMimHFRFNuT8/hu+xH6RPixPSmPuWvjmdA3lM7BrfBysxLi685TX+/m3nlb0GjsWjN/1lDaB3rz0g39ueGddfRo68v8WSbrzOcxyRSWVuDlZuXGwZH4eZm743tHm88vt9lJyTmGp5uVNrWai8DcZX929/Djr+fcHs1fv9rFJV2Duap3KPd9uoXVcZn8c0oflFI8M6kX91/WhWAf9xPeqzmSQNAIAgMDGTFiBL1798bT05M2bdoc3zdu3DjefvttevToQbdu3Rg2bJgTSypEw+QUlXH3J5tJzjnGnBnRzF0TT0JWMQlZxczbkMitw6OOH/vdjiM88tl2XCyKv327h/kbDhN3tBClON6Jevvw9jwzuVeNO+NW7q7M+sj09713WzTtA01NenBUa3588GIiArxo5W4uUbNGdTxpeV2tFqKCvE96THVBrdx565ZBx1/PnTGYvan5x4eZWiyqxQQBaIadxc1dS/qu4sxorblt7kZ6hvry5/Gn/7eSlF3MbXM3kpJ7DF8PVwpLyykpt3Pv6E7sTMlj6+Fclj1yCW39PPgsJok/Ld7BoMgA3r0tmu92HOG1Xw9w/aAI7h7diYNHC8kpLuPSbiF1No/M33AYgJuGRp719xYnJ53FQrQgq+IyWR2XyZoDmUzuH0avMD/AjEZ5Z+UhLu4axEDHhKXatNY8vHAbWYWlzJ85lPAAT2Z+GIObi4WHLu9KWl4JV76ykgmvrubS7iEs3pLMyM5BvHdbNB6uVm4bHsVt1WoLA+r5nEoSAM4PEgiEaGbeXnGQEB93ym12/vbtHhbOHobW8Ojn2/l+RyovL9vPxL6hdAnxwcWqCPf3pHuoD93b+vLtjlRiEnN4fkofoqNaA/Dd/SOxa7BaFJGBXsybOYy3Vhw4IQiIC5cEAiGake1Juaw7lMUT47vj5ebCX77axaOfbcemNd/vSOWRK7pSWmFjzpp4vttRM6PLFT3bsCslj97hvlwfXZUGTCmFtVqrzqD2Afzv9sEcLSihtZfb8eGN4sIlgUCIZkJrzX9/icPHw4XpQyLxcnNh/aEsft6TTkFpBTMuiuL+yzqjlOKxK7uhNZTZ7CRlF/PTnnTeXH6AojIbr04fgNVy6uGOIT4njs4RFyYJBEKcR7TWLN6SwubEHLKLSrnrkk71tuen5B7jk/WJlJbbefDyLizenMyv+47y5PgexycfvX7TQLTWFJXZjo/AAXOXrxR4WKx0aeNDlzY+XB8dQUJmMYMdTUKi5ZBAIMQ5diTXTBYM8z8xl9QPO9N47PPt+Hu5YlGKFbHr+c8N/ZjQJxSlFDa7ZnNiDh/8Fs/S3enHE6L9uCuVjIJSruzZhpkX11zBTilVIwjUJ8THQ+7yWygJBE7QqlUrCgsLnV0McY7EphWwLy2fq/uHU1Zh54Z31lFus/Pro6PxrnaBPlZm4x8/7KVHqC/f3T+S3OIyZn+8mfvmb+VPbjsI8nEnNbeEMpsdP09XZl7cgVuHtSezsIwHF2wlsrUXL1zfTxYwEqdNAoEQTez5H/eyPDaDEB8PErOKSM4xNYK3Vhzkvss688qyOCpsdgpLK0jJPcZ/buiH1aIIbOXOvJlD+WJLCnFHC8goKGVc77Z0b+vD2F5t8XIz/30jArz45ZFLqLBrGb0jzogEgkbw+OOP065dO37/e5NV+5lnnsHFxYXly5eTk5NDeXk5f//737n66qudXFJxrhWWVrD2QBYAT365k3K7nX4RfkQFefPu6kOsjstgR0oerhYLZTY7E/qEMqxjVUJCD1drg8bau1gtuEgMEGeo+QWCHx+HtJ2N+55t+8BVz9e7e9q0aTz00EPHA8Fnn33G0qVLeeCBB/D19SUzM5Nhw4YxefJkqba3MCtij1Jms/PAZZ159dcDAPxtci96hPry0+509qUV8OZNA7mkWzBbD+fSN8LPySUWLVHzCwROMGDAAI4ePcqRI0fIyMggICCAtm3b8vDDD7Nq1SosFgspKSmkp6fTtm1bZxdXNJLMwlKufn0t7q4WOga14qJOgYzqGkxUoNfxsfVLd6cT6O3Gg5d3pajMRkJm0fF0C/NnDcXb3eV4SuIRnYOc+XVEC9b8AsFJ7tyb0vXXX8+iRYtIS0tj2rRpzJs3j4yMDDZv3oyrqytRUVF1pp8WF66f96STknuMS7sFczCjkGV70wFwtSq6tfXhyfE9Wb7vKBP7hmK1KP46sWeN80+VfkGIc6X5BQInmTZtGrNmzSIzM5OVK1fy2WefERISgqurK8uXLycxMdHZRRRnISm7mL2p+STnHOOKnm1o19qLZXvSiQjwZO6MwSilSMouZt2hLOIzi/h2+xGmv2dSjo/tdYHUArd8DCueh/s2gdvJl3QUzYsEgkbSq1cvCgoKCA8PJzQ0lJtvvplJkybRp08foqOj6d69u7OLKBrgg7Xx/LLvKC9e34/W3m68u+oQizcncyiz6Pgxy2OP8u6t0aw5kMn0IZHH+33atfaiXWtzAb1ndCee/no3O1PyGN4psM7POie0hp2LYPV/YMhMGDyz7uPsNlj9IuQnQ8Jq6Dr23JZT1K28BOZeCTmOG8mx/wcDTlzC9mxJIGhEO3dWdVIHBQWxbt26Oo+TOQTnrwWbktiXVsC1b6wlxNeDbUm5jOwcxG3D29M/MoCVsRm8vGw/r/4aR2mFnct7tKnzfXw9XHl5Wv9zXPpa7DaYNxUO/grufvD9Y9CqLfSYeOKx+5dCTkLV8+YYCBbPhLRdVa+tLjD5NQgb0DjvX5gB3z0EF90PkdXWHcnYDz//Fcb+AwI7wa7FsOsLuOZN8PCDVS+YAS6X/gWCu9Z8z12LIXU79L3RHNu6U+OUtRYJBEI45BWXE5tewOR+YWyIz+JgRiGv3zSAiX3Djh/TtU0rPlyXwFsrDuLj7sKQDudJOoZdi6HwKAy7p2rb5g9MELjiOYi+Az662lwMI4eBiwdM+A/4hZtj178JvhHQphfE/WxqEufzCDe7HbbPh6QNMOQuaNv75MfnHoadn0PYQPCLMNvifoKt804dCMqKYf0bkLDWvO4x8cSaVVkxfHojpMRAcTbc8WPVvlX/hv1LIDMOLnsSvpgN9gpYWADdroJf/w7KCvu+h/YXmed9rof+N8GGtyC4B1z7dpP+e0ggEMIhJjEbrU2O/Oeu6Y3drglwLFBeycvNhdmjOvL8j/sY1S34tNfvbTIb34PkTdDzavANg2M55gLTfoS5Q1UKpi8wd6yF6XBoOUQOhZEPQ/pu0xx0+d/MXWfcUsiIhZDztDkzPxUWTIcjW8HiAls/gWH3wpV/r/9iWXkRn/xaVdCYf6P5rvoF8/v67VUY9Qdwc6x0prUJsD8/bZrM2vaFsiJTs4oYYoaVb3jb3LFnxkHKZug6zlz0U7dDaD9T1t1fQsdLIfE3WHQHhPSC6N/BD49B/EroehVMesXUDFJ3QHEWfH2v+XdJ2wmT/tvkQfk8+Ss+exfaSmtnoiV8x8ZytKCEj9cnsj+97rWk7XZNYlZRjW0b47Nxs1ro384fP0/XE4JApVuHtWdE50BuHnIeLaqSHW/uMjf9z7xe/k9zcRv3fNVFpFUw3DgPZi6DNn3MnT+Yu2KLKwy8DbpcYbbF/dR0ZdUa9v9kmqBq2/E5xK8+cXt1G942F8xr34XH4syd87rXzR01QNJGUxOqLnENeAZASLWRW12uMDWFzDgTBNa8bJpswGyfOw4W3wleATDje7h7Ncz6xbzPksfN8Useh0MrzcV70itw7Tvg6g3r3zbvEzPHNNFNfAmmzoWoi+Hmz2DILNNU1G0CTJ0DPm1NDW3mz3DPb9BuqKmFeAZAnxvO7Pd8GppFjcDDw4OsrCwCAwOb7YQtrTVZWVl4eEhSsFN5/sd9zFlziHKbxs3FwpPje3Db8PbH/za01vxx8Q4WbU7mqYk9uWOkSdK2MSGbvhF+p0zT4O3uwryZTbz2tNYQ+wN0uRKsric/tqwYCtNAWSDmffBvDxvfMc0XoX3rPqfrlbDmFdOMsfsLc1H0ag20NnessT/A8PvAYjEX1iNba50/FgKiTv97pe+BpX+GQyvA6gb3rjft5gCb5sD3j5jn3SfClc9B61prFWttLtYdR0O/aWbbxP9C8mZY+oSp0cybarbftwn8HcE6YY2pHVmq3ftWBr09X5tmNIBdi2DgraYWkLYTJr1qOmctjr8JzwC47C+mnIlrofdUmPJezfftfxNs+dDUGGLmmuaf1h3NT/X+meG/Nz+1uXrAjZ/Cp9Og93XnZARXswgEERERJCcnk5GR4eyiNCkPDw8iIiKcXYzzWm5xGW+vPMjlPUK499LOvPZLHE9/s5vsojIevsJ0xL326wEWbU4mKtCLZ7/bA8CNQ9qxMznvlIukn5XCo1BaUHXhO5kjW2DBTTD5dXNhOplcs+4vA28zF7RvHzB3nmP/Wf85Xa40I4mW/x8UpELvv1ft6z0Ffn0O/jcG/NuZC2VtcT/BLYtP/T0qleTDL8+aO2R3XxjztPn8pU/CTQsg9kfTVNJlLLQbAqtfgjeGmiafUY+Bu5l0R9JGyDsMl/656r2tLmb+0EdXw0eTwa+d+V3/9Fe44UPISzYd4UPvrlkm/0jT/r76RagoMb+z+FUm6O352vS3DLr9xO8yaAZsX2Au0Ne8WTMIgDlvy0cm4KFM09zp8g40NbdzpFkEAldXVzp06HDqA0Wzty0pF4A7RnRgYGQAc2cM5rHPd/Dqr3H0Dvdjc2IOb688yJSB4Tw/pS8PfLqVZ7/bw4+7Uqmw66bt/P36PkjeCPdvcdx915KfCl6B4OIGR/eZbQmrTSDQ2lzwA9qfeF7laJ/+t5hRMWWFMO1j8z71CY8GD3/TlOTqbe5aK418xHSoLnsGju6F0X82nc0Wx+Vi1YumeaYoE7yDIC8FvIPN52kNeUlVd+KVvnvItJUPnmnez6u1abJa9gx8ch0cWGba1KfOBfdW0P9mEzjWvgLb5sOYp8y2XYvA6m5qDNV1HA09rzEX8lu+MG37K/5hagJ5KeaY9iNO/D10vRLW/tfcvY9/Ad4cBgtvAzQMmV33785ihTuWmBpYXS0QgZ3gTwkmuFhdq4LYeazZ9BGIlisuvYB4xzj/rYdzUQr6tvMHTC7+v1/Tm+5tfZn1UQxvrzzI9CGRPD+lL24uFl6/aQAPjunC5sQclDLLMDaJsmLTHHIsB5b/w2wrLwFbhXmefQhe7W/augEy95vHhDXm4rpjIfy3n7nQ1VYZCFp3gNu/hbsd7eEnY3WBzmPM8+7jqzpIwdzh9rsRHtwOfzgAox+HViHm4u3VGvpPB22DPV+ZwPPfvvDWcHMX/MEEeKWPubBXSvzNXJhH/cFcbCuD4LB7TXNJ/CoY8ZBph3dvZfb5hsK1b8HMX00T1Df3wXuXmvfpOhY8fE/8TtfNgYd2QFBnGPEA+EWaDuE1L5ug16aOkUXdxjvK8nsI6WGOyTtsttcVdI//jqwn78B18zLf8wIIAtBMagSiZdmVkseBo4VcMyAcm10z4/1N+Hi4sOShUWxLyqVbG58aC7F4ull5+5aB/OWrXdw8NJJxvUOP73OxWnj4iq5c0i2YI7nH8PU4RXv8mYpfBbZSc9cbMwc8/c1In5AecOuXphmjosQ0fUBVIMhPMRf67Z8C2iRVvGuVuZBXykkAt1amNnE6fWRdx5kLa5/r697v4m5+amvTG4K6wc7FsPsrx8VOwTf3mzK4+8K2T6Hz5aaj9Mc/gW84jHjwxPe/Y6np5PYNO/FzACIGwZ0/mUlxy542nbL1ldfqAlbHhdfVE27/GpY8Aft/NDWI2k04YIbS3rPO/DsA9JkK6btqDsNtASQQiAvOv5bsY+2BTAZE+pOYVUyKY8Wv2LQCtiXlclXvE1M6tA/05uM7h9b7ngMjA+pdErJeOYkw5wqY+j5E1dHsUF3cT6YJ5qbPTNv3qhcgfBAcXmfuolM2m/1pO8zxmfvNxTYz1lys41eZMfBHtsCWD2qOY8+JN3fNpztQovd1pmmn46Wnd55S5oK5/P/M6wn/gYG3m9pL2ADT3LNjoRlquXOR+U7XzalZ66jUKqRhn9f3elNzObweOl3WsHK27mj6H5I31x9oANpUG0k09B7zHaJGNuwzmglpGhIXlJJyGxvjs7FreG/1IRbGJOHr4YJFwau/xJF3rJwBkf7npjAb3jFj8uPqGAZZndZmqGbH0WaY4C2Lzc/MX8xkr5TN5kJ+8SOmBpB/xAwH7TERvIJMx6m2wzVvmQ7NX/9e1UEMpkZwJiN4LFZzUT2TkXa9rzOPIb1g4AzTFt7pUlPT6TMVyotNMPjlWYgcXnX82XDzNs1Zp1veiEGmqakhXD3Mv1MLIzUCcd4rt9k5nF1Mp+BWbIjPprTCTsdgbz6PSUZruHlYJAeOFvL9zlTgHGX1LC2ArR+b58kxJz82I9a0O1/sGBoZEV2176L7zcUztD+UmI5udn9l2uCDu5uaxp6vTXNMSHeY+DK8NwbmXW+aVTz8TCDofHmjf8WTCuwEE14yF3lrrctI5HDwCYUf/miafcYtPr9nKQupEYjz31srDnLFSyvZfSSPlbEZuLlYeG36AMpsdspsdqYNbsekfqbq7+PuQufgVvW/WVEWfPugabY4G9s+hdJ8M8P0yNaqTt/aKsrMmH6oGrdenVJm2GdoXzNzFUwqBICgLqYGAFV31EFdzIigrIPw2W1m6GdFyZnVCM7W4DtrNqtUslih1xSwl5sRT2FOziB0dBUAACAASURBVLkkTkkCgTivldvszNuQiF3DC0tjWRWXwdAOrekV5sc1/cMZ3jGQ7m19GdurLW5WC33b+WGxnOTuc/8SM9Y+eVPN7Wm7YP1bphnnVOw2c3EPHwRD7zLNIEf3nHhc2k4zHDFmLvSbXpXjpj6e/mYy2JEt5nVgF+gxGXpMqplxsuMlMP7fJj3Byn+ZbQHn2fDpITNNB+1lTzm7JKIBpGlInHf2pxfw0k/7+cO4bsSlF5CeX8rIzkGsiDUTBm8c3A6Al27od/wcP09X/j21LxEBnid/88xY81iQVnP7dw+Z4FCUCWP+euJ5cctMh2Obnia3TdYBuP4D06QD5tzqs3jtNvjyHjOm/+ZFddcG6hLaD3ITTQI491bmZ9onJx43cIYpR+WMWGfUCE6mdUeTzkJcEJq0RqCUGqeUilVKHVBKPV7H/kil1HKl1Fal1A6l1PimLI84/x3NL+F3729iye40Zry/kXdXHSLMz4N3bh1EW1+TXmNU12DAzBGonlLkmgHhREedYkJYZpx5LEit2pa82VzIW3c0s0y3fFTznPxUk1ny/atMf8Avz0K7YWYCU0CU6dCt3U+w5SNI32ly/TQ0CEBVMAnqcvLjLBYY56gNoMwMYCHOUJMFAqWUFXgDuAroCUxXStVuUPwL8JnWegBwI/BmU5VHnB+W7Eplw6GsOvcVlJRzx4ebyCku459T+pBRUMqWw7lMHxKJt7sLz13TmykDwukScpI+gFOpHJ9fvUaw4S0z9n3mL9BhlEl7UF5tWdGYOabT02KFOVeasexXOZK5KQURg0364UrHckyKhvYjoNe1p1e+yhpGcLdTH9tusEl3ENq37vH+QjRQU9YIhgAHtNaHtNZlwALg6lrHaKByiqAfcKQJyyOcrMJm5w+LdvDnL3aekEm1sLSCGe9vYl9qAa/fNIDpQyJ546aBRLcP4EZHls8rerbhpWn9T51YsPCo6aQ9oQBlZlgmmCGaUJUmeMAtZiboiIdMJ/ABR2bO8hKTyK3rOLj5c3PBHTSjZg77iGgTYI7lmNcr/22SuVXP/NlQYQPAxdP0PzTEhJdh1vLT+wwhamnKPoJwIKna62Sg9oyeZ4CflFL3A97AOR4DJ86lHSl5FJRUUFBSwaaEHIZ0aI3Wmi2Hc/j793vZkZzH69MHcFn3NlBRypgebRhTzwpg9aooMx20nS+HKe+abbZyM849+5AZlglVNYJdi8zd/pBZ5nWHS0zenJ2LTCftrkVQnGlmmoYPgkf2mNW+qqtcjWrDu9DrGtj4rklWVl/mz5PxDoKHd586RUSlumbLCnGanP1XNB34QGsdAYwHPlZKnVAmpdRspVSMUiqmuWcYbc7WxmUC4OVmZeGmJPJLypn2znque2sdB44W8tr0AVzVJ9Qs6vGPcPN4ug6vM003OxaaWagHl8Pz7WHPN1UdxcHdqwJBRqy58FemO7a6mLb//UvMzOFVL5gc9h1Gmf2eASdefNuPgL7TTJKzT280M4Qvq6PDuaG8A+UCL86ppqwRpADVe7AiHNuquxMYB6C1XqeU8gCCgKPVD9Javwu8CxAdHS2rs1ygVh/IpFeYL30j/PlyazIpucVsOZzDM5N6cn10O7wr8wMlrDFj0Pd8bUbRnMqiO0xzyjVvmFQOVjeT8+abB0yncHmRGcJZmQYi6mIz2kZrMx6/9jqwfabCpvdMkrPSQpPI7WRNPEqZla/yUswCKGP/ae7shbhANOVtxyagi1Kqg1LKDdMZ/E2tYw4DYwCUUj0AD0Bu+ZuhotIKth7OYWSXIG6IjqCk3M76Q9n867q+zBjRoSoIQFVNoCGrZBWkmYVKts0z7f9xP5s79CueMzUAVy/od5MZc5+w1gzLDOxsAk1xNmQfPHF9gIghJqd9cRZMeccs6XgqLu5muOS179afvliI81ST1Qi01hVKqfuApYAVmKu13q2UehaI0Vp/AzwKvKeUehjTcTxDy3qMzcv2BZAdz8awOym3aUZ2DqJ/O3+uGxhBrzBfrhtUxySrVEfitbSdplP3ZAnDdn8JaJMb/qe/mIv/oBnmrr44y+SN0Y6Fzg8tN7l1fBxJ6bLiTK6g2qtgWSxmwZGS/JorSp2Kp3/VqllCXECadEKZ1voH4Ida256q9nwPcIq0jeJC9P7aeL7adoRF7u/jmradtX0n4OZiYXBUa5RS/OeGepp8yorNxbz7RNj3nclrP/A2M0Fry0cmKdtlf6k6fucis/5uSPeq1Axdx5rmmmHVVqQK6Wlm/wZ1NXlwwCw1CKaGUFtln4AQLYD0SIlGV1ph4/VfD7A9KZfilL1QcYxNG1YzqkswHvu+NAu01OfoHnMH3+9Gk8N+/1KTgvmdUWb276oXTLs+mKaglBjoc51JHwzm7r6upSCr5+qprBEkrDGPDVk6UohmTAKBaHRLdqWRVVTG7Gh//HQeANcGH+GlqT3g24fg899VjbmvrbJ/ILSfWVc39gf4cJJpphn3vNlX2Xewy7Fmbu/rTKrhvjfCkLvqft/+N5nhnx0vrQoEhzeYx9pNQ0K0MBIIRKObt+Ewka29eDy66s/rtshMfI9uhrICOJYNK56v++TU7WZZQb92plbgHWKagu7baMbyB3U1gcBuM7l2IodXrY875Z2azUHV+YbBrF/N3b+LuxlVVF5kmonqWjBFiBZEAoFoVPvTC9gYn81NQyOxZDnSOYT0wpISY5p5LK7mzn3je5BeV8bOHaY2oJSZqPVYrFnr1tWRTK7LlaZJZ/eXZmWuMx2hU9lPUHvoqBAtkAQC0Wi01vx7SSxuLhauHxRh0i64eEDva022zt1fmbH8Y/9hFh+fcyWs/W9VOghbOaTvPvmM3C5XgK0Mvn/U9CH0mHRmha1sHgqUZiEhJBCIRvN5TDLL9qbzx7HdCGzlbgJBYBdo5xiHn58MXcaambMzfzFB4eenTMZPMMNGbWVVidfqEjncLNRekmvW7bWe4WLzlYFAagRCSCAQjeNwVjF/+3Y3wzsGcscIxyIpmfvNKJ2wAWacP5imHTBt9TcthE5jzFwDrWH3F6bpqPOY+j/Ixd3MDXDxNPMFzpRPWFU5hGjhJBCI01OYAS/3Njl8HGx2zSOfbcOiFG/0icPy5hAz4zcn0aRTdvcx4/gDok688PaZahZiSdpoZgh3vvzUCdeu+jfM+N5kCz1TlZPU6ppDIEQLI4FA1OtPi3aw4vtPYe44074PZO5YAnlJFC6rGvXzzqqDxCTm8Ow1vWgd/52pCXwxG9BVC6xM+i9Mee/EnD3dJ4LVHZb8CQqOmMBwKn7hZrjo2eh9HVz7jklAJ0QLJ0tVijrZbHaG7XiC0ZbVZoPFhZKuk9i04luuAlqlroe0ncSpKF7+eT8T+oRyTd+2sGSdSfoWv9KcF+RYYCUiuu4P8vCFrlfC3m9NXqBuVzX1V6v63H43npvPEuI8JzUCUaeczYu51rKaOfaJ2IbeC4fX8X9fbKBbyXZ2WHpwDHf0+reYt+EwSimevboXKn0XlObBFc86cvarhrXB93bUArpdJWP6hXACqRGIE5WX0GrlM+y1t+MfZdO4JNiDzvY3UTsW0NE1jW3dbmHRzm3cvHMRve1HeTkklED30VW5e3pebXL8H15XNf7/ZLqONcNAh9/XpF9LCFE3CQTiROtew6MomWcrnsSGlXWlHWnn0ooH9JcAtB80loe2hXGF3sUl9g0EZ+fDWsdCMq07mo7YPlMb1t4PJlhM+6QJv5AQ4mQkEAjISzbpmMMHmbTPq19iX8BoNmf0IdjblS3JhXRyGchFFavA3ZeAjoMIaFfOsMMv0drbjZhu87CseQUsLmbymBDigiJ9BAKW/NnM8j20En5+Guw2PvKZSfvWXgxo58/aA5l8WdjTHBs5HCxWLnesJTy5XxiWK58FtMkj1H6k876HEOKMSCBo6bQ2Y/jtFbDgJtj5GVx0P1vy/Wgf6MWAyACOFpTya0U/7FZ3M84fmNQ3jM4hrbh5aKRJ+jbyETMZrMPFTv5CQojTJYGgpctPgcI0uOh+M2LHJxQ98iESs4ppH+jNgEh/AFSrEHhgOwy+E4DIQC+WPXIJXdr4mPe55I/w4LaTryYmhDgvSR9BS5e8yTz2mgIXPQC2cjJKXTlWbqN9oBd9I/xwtSrGdA/B4hda//soBX51LDsphDjvSSBo6ZJjzMzeNr3BxQ2AhPhsANoHeuPl5sK8mcPoFCzj+4VoriQQtHTJMRDWH1zcOFpQgs2uScwqAiAq0AuAIR3OIqePEOK8J4GgJasog9RtJp0zcN+8rexNy2dk5yCsFkWYfwMmgwkhLngSCFqy9F1QUQLhg8guKmNTYjZaw4+70mgf6IWrVcYSCNESyP/0lixls3mMGMzquAy0hueu6Y2nq5WOQdInIERLITWClqCs2Kzx23caWKv9kx/ZBl5B4BfB8n3bCPR24+YhkQzt0BpPV6vzyiuEOKckELQEK/4Jv71qcvr0nlK1/egeaNMLm4aV+zO4tHsIFouia+XcACFEiyBNQ81d1kFY/5Z5vmtx1Xa7HTL2QUhPtiXlklNczqXdQpxTRiGEU0kgaO6WPmnW+e09FR33EylpqZSU2yA3AcqLoU1Pft6TjkXBqC7Bzi6tEMIJpGmoOUtcB/t/hMv/BlEXo3Yt4pXXXmKRfTR3BO7mr8Bhl/a8vzaeK3u2xc/L1dklFkI4gQSC5mz9G2Yh+CGzwdWTbPdwrravI2z0LFzWfg3Ag7+W4u3uwnPX9HZyYYUQziKBoLnKSYR935v8QW5mhvBq91FMLF3IyKE+5B4pIjk+hK1p5bxz6yCCfdydXGAhhLNIH0Fztek9QMGQWcc3zS0aiUJDzFz8Cw/gF9Wf/97Yn7G92jqvnEIIp5NA0ByVFsCWj8w6wI6MoJmFpWwvCiApaBTEzIXMOHza9eHq/uFOLqwQwtkaFAiUUl8opSYopSRwnK/WvQnxq83zVS9ASR6MeJBjZTYAYtMKACjodycUZ4K2QUhPZ5VWCHEeaeiF/U3gJiBOKfW8UqpbE5ZJnK6sg7D0zzDveti5yASF/jezz9qZvn9byqr9GexNzQcgtP/YqgAggUAIQQMDgdZ6mdb6ZmAgkAAsU0r9ppT6nVJKxhw6264vzKNXa1h8p5k3MOYpvtueSrlNM2dNPPvSCghq5U6gjwdc+iREDIagLs4ttxDivNDgph6lVCAwA5gJbAX+iwkMP5/knHFKqVil1AGl1OP1HHODUmqPUmq3Umr+aZVemDWHdy0yi8rf+iX4RsDlz4BPW5buTkMpWBWXwZq4THqEOlJH9JgIM5eBVWK4EKLhfQRfAqsBL2CS1nqy1nqh1vp+oFU951iBN4CrgJ7AdKVUz1rHdAH+DIzQWvcCHjrjb9JSpe82qSJ6XwfB3eDhXTBkFocyCok7WsjsUR2xKEVafgnd20oOISHEiRo6j+BVrfXyunZoraPrOWcIcEBrfQhAKbUAuBrYU+2YWcAbWuscx3sdbWB5RKVdi0BZode1AOQdq6CVhwtLd6cDcNvwKOIzivhpTzrd2vo6s6RCiPNUQwNBT6XUVq11LoBSKgCYrrV+8yTnhANJ1V4nA0NrHdPV8X5rASvwjNZ6SQPLJABif4QOo8A7iP3pBVz9+lraB3pRVmGnd7gv4f6ezLy4I2sOZBLdPsDZpRVCnIca2kcwqzIIADju4Ged5PiGcgG6AKOB6cB7Sin/2gcppWYrpWKUUjEZGRmN8LHNhNaQHQ9te1NWYeehBdvwdLNSWFrBocwixvY0E8WGdGjN7r+NJUoWmxFC1KGhNQKrUkpprTUcb/93O8U5KUC7aq8jHNuqSwY2aK3LgXil1H5MYNhU/SCt9bvAuwDR0dG6gWVu/ooywVYKfu14edl+9qTm895t0VzcJYif96QzpkdVWmmllBMLKoQ4nzW0RrAEWKiUGqOUGgN86th2MpuALkqpDkopN+BG4Jtax3yFqQ2glArCNBUdamCZRJ5peVue5sZbKw5y4+B2XNGzDR6uVib1C8PLTVJJCSFOraFXij8BdwH3OF7/DPzvZCdorSuUUvcBSzHt/3O11ruVUs8CMVrrbxz7rlRK7QFswB+01lln8D1apnxTwXpxfRGX92jDs1dLBlEhxOlrUCDQWtuBtxw/Daa1/gH4oda2p6o918Ajjh9xuvKSAWgb2Zk3bx6Im4tkABFCnL4GBQLHeP9/YuYDeFRu11p3bKJyiQY4lpEA2o3hvbpIEBBCnLGGXj3ex9QGKoBLgY+AT5qqUKJhijIPc0QH0lXmBwghzkJDA4Gn1voXQGmtE7XWzwATmq5YoiF0bhJHdCDdZMawEOIsNDQQlDpSUMcppe5TSl1LPaklxLnjXnSEDGswIbK6mBDiLDQ0EDyIyTP0ADAIuAW4vakKJRqgooxWFdmUe4fLHAEhxFk5ZWexY/LYNK31Y0Ah8LsmL5U4JZ2fggWNS0CEs4sihLjAnbJGoLW2ASPPQVnESVTY7OQWlx1/nZsaD0CrkCgnlUgI0Vw0dELZVqXUN8DnQFHlRq31F01SKlFDuc3Oze9tICX3GCv/MBoXq4WjyQcIAIIjOju7eEKIC1xDA4EHkAVcVm2bBiQQnAP/+nEfGxOyAdgYn81FnYMoOJoIQGQHCQRCiLPT0JnF0i/gJL/sTed/a+K5cXA7vt52hO93pnJR5yAqspPIwZegAEktLYQ4Ow2dWfw+pgZQg9b6jkYvkajhi60ptPF157k+mUxJ+B+ZO0ooq2hDVM5acl1DkDAghDhbDW0a+q7acw/gWuBI4xdHVKe1ZlN8NtNDU3Fd+Cj9rZ4csbmTtfcApdqKtfc1zi6iEKIZaGjT0OLqr5VSnwJrmqRE4rjErGICCuO4J/V58Aun4rYljPvPFkqK7dw1qiN/Ht/D2UUUQjQDZ5qwvgsQcsqjxJkrP0bZ93/kO7dPUVY/uHkRXv5tmNwvjH1pBTxyZVdnl1AI0Uw0tI+ggJp9BGmYNQpEU9n4Hl3jP2GRupwpv38LfEzc/dd1fdEaLBaZTSyEaBwNbRqSrGbn2uH1JKkwlnb4M1N9ai45KRklhBCNqUG5hpRS1yql/Kq99ldKSU9lU9EaW/ImNlZ0ZEhUa2eXRgjRzDU06dzTWuu8yhda61zg6aYpkiAvCWvRUbbZOzO4gwQCIUTTamhncV0BQ1ZGbySHMgr58LcE1h3K4s6RHRhRupoIICegH73DZNEZIUTTaujFPEYp9RLwhuP174HNTVOkliUpu5ir/ruaEJ3FKx7v8tAXMyh2/ZnpFjeevGMqLlZZglII0bQaepW5HygDFgILgBJMMBBnad2hLEor7Cwclckg23Y+DvuSwS6HsLXpS2hrqQ0IIZpeQ0cNFQGPN3FZWqSth3Px8XAhNCcGgKisVYCCjhJnhRDnRkNHDf2slPKv9jpAKbW06YrVcmxLymVAhC/q8G/Qeyq07ghoiIh2dtGEEC1EQ5uGghwjhQDQWucgM4vPWlFpBbFp+YwJzIHiLOh0GYx/EQI6QHtZC0gIcW40tLPYrpSK1FofBlBKRVFHNlJxenam5GHXMNxln9kQNRIC2sOD25xbMCFEi9LQQPAksEYptRJQwMXA7CYrVQux9bCpZEUVbAG/diYICCHEOdagpiGt9RIgGogFPgUeBY41YblahK2Hc4hq7Ylb8jpTGxBCCCdoaNK5mcCDQASwDRgGrKPm0pWiAex2zd2fbMbVamFTQjY3tC+C+EwJBEIIp2loZ/GDwGAgUWt9KTAAyD35KaIuO1Py+GlPOiv3Z5BTXM6VXnFmR/sRzi2YEKLFamgfQYnWusRkvlTuWut9SqluTVqyZmp57FGUgpV/GE1xmY3wZZ+DbwQERDm7aEKIFqqhgSDZMY/gK+BnpVQOkNh0xWq+lsdm0L+dP4Gt3AnUGhLXmGGjkltaCOEkDZ1ZfK3j6TNKqeWAH7CkyUrVTCzenIzNrrlhcDsAMgtL2ZGcyyOXO1YXy4yDogzpHxBCONVpZxDVWq9sioI0R2+uOEBWURlTBobjYrWwMjYDreHS7o65eAmrzaMEAiGEE0lqyyZSWmEjIauY3OJyNsZnA6Z/INjHnZ6hjmRyCWvAJ8zMJBZCCCeRQNBE4jOLsNnN5Oulu9PIKSpjRWwGl3YLNusNaw2Ja01tQPoHhBBO1KSBQCk1TikVq5Q6oJSqN3upUuo6pZRWSjWbTGuxaQUARAV68dOedF5ffoDisgpmXtzRHLDmJShMh86XO7GUQgjRhIFAKWXFLGRzFdATmK6U6lnHcT6YeQobmqoszhCXXojVopg9qhOpeSXMXRvPlIERdG3jAzs+h1+ehT7XQ98bnF1UIUQL15Q1giHAAa31Ia11GWZBm6vrOO454F+YxW6ajf3pBUQFejG+T1usFoWr1cLDV3SFsmL49gGIvAiufkOahYQQTteU6w6HA0nVXicDQ6sfoJQaCLTTWn+vlPpDE5blnNufXkDPMF/8vdy4c2QHQnzcCff3hEMroLwYLn4UXNydXUwhhHDeAvRKKQvwEjCjAcfOxpHtNDIysmkL1ghKym0kZhdzdf9wAJ4Y36NqZ8IaUFaIHFrP2UIIcW41ZdNQCtCu2usIx7ZKPkBvYIVSKgGTyO6bujqMtdbvaq2jtdbRwcHBTVjkxnHgaCFaQ7e2PifuTFgLYf3BvY59QgjhBE0ZCDYBXZRSHZRSbsCNwDeVO7XWeVrrIK11lNY6ClgPTNZaxzRhmc6J/elmxFDXNq1q7igrhpQYmUAmhDivNFkg0FpXAPcBS4G9wGda691KqWeVUpOb6nPPB/vTC3G1KtoHetfckbwJbGWyDKUQ4rzSpH0EWusfgB9qbXuqnmNHN2VZzqW9qfl0Cm6Fq7VWnE1cC8oCkcOcUzAhhKiDzCxuZFprtifn0i/C/8SdCWsgtB94+J77ggkhRD0kEDSyw9kmv1C/drUCQXE2JG2ADpc4p2BCCFEPCQSNbFuSWbitXzu/mjv2fA32Cug9xQmlEkKI+kkgaGTbk/Lwc62gq5+95o5diyGwC7Tt65yCCSFEPSQQNLLtybn8p9V8XOdcBrYKszH/iOkf6DNVUkoIIc47EggaUbnNzu4jeXSzJEP2IYj93uzY/RWgofdUp5ZPCCHqIoGgEe1PL6Ck3E6QLcNsWP82lBZAzFwzWiios3MLKIQQdXBarqHmaHtSHi5U4FFyFLxD4PBv8OEkUzu4+TNnF08IIeokNYJGkldczpw1h+jlU4RCw4gHwNUbjmyFCf+RBWiEEOctqRE0gtIKG3d9EsPh7GK+mhhgkmqE9ISJL0NZIUT/ztlFFEKIekkgOEvlNjsPLdjG+kPZvDKtP72sa80Ov3bQeYxzCyeEEA0gTUNnoazCzoMLtvLjrjSemtiTawaEQ16y2ekX7tzCCSFEA0mN4AzY7Jq3Vhzgo3WJHC0o5S8TenDHyA5mZ14yeAaAm/fJ30QIIc4TEgjOwA87U3nxp/1c3CWIF6/vx6iu1RbLyUsGvwjnFU4IIU6TBIIzsCc1H1erYs7tg3FzqdW6lp8C/uf/cppCCFFJ+gjOQGxaAR2DWp0YBADyksBX+geEEBcOCQRnIDatgK51rUdcWgAledI0JIS4oEggOE0FJeWk5B6je12BIC/FPEogEEJcQCQQnKb96YUAdG1TVyCoHDoqgUAIceGQQHCaYtMKaEsWI7Y+BqWFNXfmJZlHCQRCiAuIBILTtD+9gCvdduIV9w2kbq+5My8ZlBVatXVO4YQQ4gxIIDhN+9Ly6eudY14UpNbcmXsYfMPAKqNyhRAXDgkEDWC3a77cmkxyTrEZMeSaaXbUDgQ5CRAQda6LJ4QQZ0VuXRtgye40Hl64HTcXC2UVdsK8082OgrSaB+YkQNex57x8QghxNqRGcApaa95eeZD2gV6M7dUWiwL/Mscw0eo1grIiKDoKrTs4p6BCCHGGJBCcwrqDWexIzuOuUZ14bfoA9j4xDJfSPLOzeo0gJ8E8StOQEOICI4HgFN5edYigVu5MGWjSRrgXOIaIunrVrBFIIBBCXKAkEJzE2gOZrNqfwR0jo/BwtZqNOfHmMWKwqRFo7dieYB4DpGlICHFhkUBQyz2fbObRz7aTV1zOE1/uJCrQiztGVLu4V17wI4dBeTGU5ldtd/c1axEIIcQFREYNVVNcVsGS3WloDb/sSye3uJz5M4dW1QbAXPC9AiGoq3mdnwoefpAdb5qFlHJG0YUQ4oxJjaCafWkFaA3TottxrMzGDdERXNQ5qOZBOQmm+ccn1Lyu7CeQOQRCiAuU1Aiq2ZdaAMB9l3XmifE98PGo49eTkwDh0eDjSCNRkAZ2O+QmQrerzl1hhRCikUiNoJq9qfn4uLsQEeCJn5crFkutZh5bOeQmmTv/44Eg1fzYyqRGIIS4IEkgqGZvaj7dQ31Q9bXz5yWDtpkLvps3uPuZGkHlSCKZTCaEuABJIHCw2zX70groEepb/0HJMeYxuLt59A01tQGZQyCEuIBJIHBIyT1GYWkF3dueJBDsWmTWIw4fZF77tDU1gv1LwNUb/Nqdm8IKIUQjatJAoJQap5SKVUodUEo9Xsf+R5RSe5RSO5RSvyil2jdleeqyNzWfbUm57Ek18wF6hNax8hhAcTYc+AV6XQsWx6/NJ9SsSbD3Wxj5MFhdz1GphRCi8TTZqCGllBV4A7gCSAY2KaW+0VrvqXbYViBaa12slLoH+DcwranKVNueI/nc8M46SitsRLdvjVLQra61iAH2fgP2cugztWqbT1uwlYJfJFx037kptBBCNLKmrBEMAQ5orQ9prcuABcDV1Q/QWi/XWhc7Xq4Hztkaj2l5JdzxwSZaubvQI9SXdYey6BDojZdbPbFx12Jo3QlC+1dt8zX5h7jyOXD1bPpCCyFEE2jKeQThQFK118nA0JMcfyfwY107lFKzgdkAkZGRjVK4l36O01zeXAAACo1JREFUJe9YOYvvuYjwAE9mfRhD3wi/Ew+sKINN70H8arjkjzVnDvedZlYk6za+UcokhBDOcF5MKFNK3QJEA5fUtV9r/S7wLkB0dLRujM/ck5pPdFQAPcNM5/Bndw8/8aDyY/C/yyF9F3QaA0Pvrrnfwxe6T2iM4gghhNM0ZdNQClB9GE2EY1sNSqnLgSeByVrr0iYsz3F2u+bg0SK6hNTTH1Bpx0ITBK59F25ZDF6tz0XxhBDinGrKQLAJ6KKU6qCUcvv/9u4+yKq6juP4+yO4KKAuiAgKIwhoGYrgE2aWoSU6DFqZYkY+NU1ONllNJVE2+Z/aZDWZ4PQwmvgAiMowFiIZjU2CioAIAqtSwMhTJQ8qxMK3P85v5bLsEuByfzfO5zWzw73nHC4fvrvnfvf8zrm/A4wCplZuIGkwMJ6iCaw9gFl2sert93hv23b6d+/c+kYR8Pw46HEqnHalJ5Mzs4PWAWsEEdEI3AxMBxYDEyPiVUm3SxqZNrsL6AxMkjRP0tRWXq5NNazbDLDnRvDmLFi3GM65yU3AzA5qB/QcQUQ8BTzVbNltFY8vOpD/fmteX1s0ggF7agTP3wsdu8HAz1UplZlZHqX8ZPGyNZs5ulMdXTrVtbzBP1+HpdPhzBvg0MOqG87MrMpK2Qga1m2m356OBubcB4e0h7NurF4oM7NMStcIIoJlaza1Piy0ZSO8PAEGfnbnVNNmZgex0jWCdZu3snFLY+snil9+EP6zaffPDJiZHaRq4gNl1dSwpulEcbPPEOzYDvMegr/cCb3PgeOHZEhnZlZ95WsErV06OuUrxTTTvc6Gkb/MkMzMLI/SNYK/Nqyna6c6jj2yw86FWzbAoifgjOthxN3+3ICZlUqpzhGs+Ne7zFi0hqvO6r3r7Sjf+DPsaPQniM2slErVCB7423IkMXpos/vfLHu6uP9wr7Oz5DIzy6k0jeCdrY088sIKhg/swXH1FfcOiIBlM6D/MGhXupEyM7PyNILH5q5k05ZGbjiv764rVi+AzWtgwMV5gpmZZVaaRjCoVz1f/UQ/hvQ4FNYu3rli2dPFn/2zTHtkZpZdacZCBvWuZ1DvenjyZpg3Aa5+BI45GWaPL84NdD4md0QzsyxK0wgA2LYFFj1ZnBeYdD107g7bt8Hlv8qdzMwsm9IMDQHQMAO2bize+Dt2hY2rYNRD0G1A7mRmZtmU64jglcnFPQZOvRL6DYN31kOPgblTmZllVZ5GsHUTLP0jDB5dXCZ6RA/PLmpmRpmGhl57Chq3wKlX5E5iZlZTytMIDjsSPjTCnx42M2umPENDJ19SfJmZ2S7Kc0RgZmYtciMwMys5NwIzs5JzIzAzKzk3AjOzknMjMDMrOTcCM7OScyMwMys5RUTuDPtE0jrg7/v517sB69swTluq1WzOtW9qNRfUbjbn2nf7k+2EiGjxxiv/d43gg5D0YkScmTtHS2o1m3Ptm1rNBbWbzbn2XVtn89CQmVnJuRGYmZVc2RrBfbkD7EGtZnOufVOruaB2sznXvmvTbKU6R2BmZrsr2xGBmZk140ZgZlZypWkEkoZLWiKpQdKtGXP0lvSspEWSXpX0jbS8q6QZkpalP7tkytdO0suSpqXnfSXNTnV7VFJdplz1kiZLek3SYknn1kLNJH0zfR8XSnpY0mE5aibpt5LWSlpYsazF+qjwi5RvgaQhGbLdlb6XCyQ9Lqm+Yt2YlG2JpIurmati3bclhaRu6XnVatZaLklfTzV7VdKdFcs/eL0i4qD/AtoBrwMnAnXAfOCUTFl6AkPS4yOApcApwJ3ArWn5rcAdmfJ9C3gImJaeTwRGpcfjgJsy5bof+HJ6XAfU564ZcDzwJnB4Ra2uy1Ez4OPAEGBhxbIW6wNcCvwBEDAUmJ0h26eB9unxHRXZTkn7Zwegb9pv21UrV1reG5hO8cHVbtWuWSv1+iTwDNAhPe/elvWq2k6T8ws4F5he8XwMMCZ3rpTlSeBTwBKgZ1rWE1iSIUsvYCYwDJiWfujXV+ywu9SxirmOSm+4arY8a81SI1gBdKW47es04OJcNQP6NHvzaLE+wHjg6pa2q1a2Zus+A0xIj3fZN9Mb8rnVzAVMBgYByysaQVVr1sL3ciJwUQvbtUm9yjI01LTDNlmZlmUlqQ8wGJgNHBsRb6VVq4FjM0T6GfBdYEd6fjTwdkQ0pue56tYXWAf8Lg1b/VpSJzLXLCJWAT8B/gG8BWwAXqI2agat16fW9ocbKH7bhszZJF0GrIqI+c1W5a7ZScD5achxlqSz2jJXWRpBzZHUGXgMuCUiNlaui6K1V/W6XkkjgLUR8VI1/9291J7iUPneiBgMvEMx1PG+TDXrAlxG0aiOAzoBw6uZYW/lqM/ekDQWaAQm1ECWjsD3gdtyZ2lBe4ojz6HAd4CJktRWL16WRrCKYtyvSa+0LAtJh1I0gQkRMSUtXiOpZ1rfE1hb5VjnASMlLQceoRge+jlQL6l92iZX3VYCKyNidno+maIx5K7ZRcCbEbEuIrYBUyjqWAs1g9brUxP7g6TrgBHANalRQd5s/Sia+vy0H/QC5krqkTkXFPvAlCjMoThq79ZWucrSCF4ABqSrOeqAUcDUHEFSF/8NsDgiflqxaipwbXp8LcW5g6qJiDER0Ssi+lDU508RcQ3wLHBFrlwp22pghaST06ILgUVkrhnFkNBQSR3T97UpV/aaJa3VZyrwpXQlzFBgQ8UQUlVIGk4xDDkyIt6tWDUVGCWpg6S+wABgTjUyRcQrEdE9Ivqk/WAlxYUdq8lfsycoThgj6SSKCybW01b1OlAnO2rti+Ks/1KKs+pjM+b4GMUh+gJgXvq6lGI8fiawjOLqgK4ZM17AzquGTkw/WA3AJNJVCxkynQ68mOr2BNClFmoG/Bh4DVgI/J7i6o2q1wx4mOI8xTaKN7AbW6sPxUUA96R94RXgzAzZGijGtpv2gXEV249N2ZYAl1QzV7P1y9l5srhqNWulXnXAg+nnbC4wrC3r5SkmzMxKrixDQ2Zm1go3AjOzknMjMDMrOTcCM7OScyMwMys5NwKzKpJ0gdLMrma1wo3AzKzk3AjMWiDpi5LmSJonabyK+zRslnR3mg9+pqRj0ranS3q+Ym79pnn/+0t6RtJ8SXMl9Usv31k7760woS3njDHbH24EZs1I+jBwFXBeRJwObAeuoZhU7sWI+AgwC/hR+isPAN+LiNMoPnXatHwCcE9EDAI+SvFpUShmnL2FYi75EynmJzLLpv3/3sSsdC4EzgBeSL+sH04xYdsO4NG0zYPAFElHAfURMSstvx+YJOkI4PiIeBwgIrYApNebExEr0/N5FHPPP3fg/1tmLXMjMNudgPsjYswuC6UfNttuf+dn2VrxeDveDy0zDw2Z7W4mcIWk7vD+vX9PoNhfmmYV/QLwXERsAP4t6fy0fDQwKyI2ASslXZ5eo0Oa796s5vg3EbNmImKRpB8AT0s6hGIWyK9R3BDn7LRuLcV5BCimeB6X3ujfAK5Py0cD4yXdnl7j81X8b5jtNc8+araXJG2OiM65c5i1NQ8NmZmVnI8IzMxKzkcEZmYl50ZgZlZybgRmZiXnRmBmVnJuBGZmJfdf/19aQDR0mRMAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion matrix, heatmap and evalution metrics"
      ],
      "metadata": {
        "id": "G7qsfS07mJwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = model.evaluate(X_test, y_test)\n",
        "print('Validation-loss:', accuracy[0])\n",
        "print('Accuracy:', accuracy[1])\n",
        "print('F1 Score:', accuracy[2])\n",
        "print('Precision:', accuracy[3])\n",
        "print('Recall:', accuracy[4])\n",
        "pred=model.predict(X_test)\n",
        "y_pred = numpy.argmax(pred, axis=1)\n",
        "y_true = numpy.argmax(y_test, axis=1)\n",
        "print('confusion matrix')\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "f, ax = plt.subplots(figsize=(8,5))\n",
        "sns.heatmap(confusion_matrix(y_true, y_pred), annot=True, fmt=\".0f\", ax=ax)\n",
        "plt.xlabel(\"y_pred\")\n",
        "plt.ylabel(\"y_true\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CHrQWgMpZttB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "outputId": "855ca514-9036-4949-9c31-d0f4f0bf0258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 1s 149ms/step - loss: 0.4302 - accuracy: 0.8850 - f1_m: 0.9071 - precision_m: 0.9175 - recall_m: 0.8973\n",
            "Validation-loss: 0.43016278743743896\n",
            "Accuracy: 0.8849999904632568\n",
            "F1 Score: 0.9070689082145691\n",
            "Precision: 0.9175373315811157\n",
            "Recall: 0.8973214030265808\n",
            "confusion matrix\n",
            "[[21  0  0  0  0  0  1  0  0  0]\n",
            " [ 0 19  0  0  1  0  0  0  1  0]\n",
            " [ 1  0 18  0  0  0  2  0  0  1]\n",
            " [ 0  0  0 17  0  0  2  0  0  1]\n",
            " [ 0  2  0  0 15  0  0  0  0  0]\n",
            " [ 0  0  2  0  0 17  0  0  0  0]\n",
            " [ 0  0  0  2  0  1 14  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 19  1  0]\n",
            " [ 0  0  0  0  0  0  0  0 20  0]\n",
            " [ 1  0  0  2  2  0  0  0  0 17]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}