{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **ANN Model for Single Audio Event Detection**\n"
      ],
      "metadata": {
        "id": "4gL3WOPkWd9f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5pk-azK4uFJ"
      },
      "outputs": [],
      "source": [
        "import numpy \n",
        "import os\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCUeEWjt43cb",
        "outputId": "03f97ce7-5e6e-4f6b-a41a-f8ae495c7fd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize all path variables\n",
        "dir_path = '/content/drive/MyDrive/Audio_Classification-MLSP'\n",
        "train_data_path=os.path.join(dir_path, \"train\")"
      ],
      "metadata": {
        "id": "EBE7YuBl48Jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data from 'annotations.csv' \n",
        "data=pd.read_csv(os.path.join(dir_path, \"annotations.csv\"))"
      ],
      "metadata": {
        "id": "vMznpHFkX1yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Preprocessing data**"
      ],
      "metadata": {
        "id": "fUOb2KyyYrGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#List containing all spectrograms\n",
        "mel_spectrograms=[] \n",
        "\n",
        "for file in data['fname']:\n",
        "  arr=numpy.load(os.path.join(train_data_path, file))\n",
        "  m,n,o=arr.shape\n",
        "  print(m, n, o)\n",
        "  arr.resize(n,o)\n",
        "  print(arr.shape)\n",
        "  # Convert a power spectrogram (amplitude squared) to decibel (dB) units\n",
        "  mel_spectrogram = librosa.power_to_db(arr, ref=numpy.max)\n",
        "  # mfcc = librosa.features.mfcc(mel_spect)\n",
        "  mel_spectrograms.append(mel_spectrogram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTnyufS95GD-",
        "outputId": "040f1748-0f72-4c3c-8731-1633aa91b24e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 128 314\n",
            "(128, 314)\n",
            "1 128 2504\n",
            "(128, 2504)\n",
            "1 128 236\n",
            "(128, 236)\n",
            "1 128 1070\n",
            "(128, 1070)\n",
            "1 128 272\n",
            "(128, 272)\n",
            "1 128 70\n",
            "(128, 70)\n",
            "1 128 664\n",
            "(128, 664)\n",
            "1 128 1421\n",
            "(128, 1421)\n",
            "1 128 432\n",
            "(128, 432)\n",
            "1 128 200\n",
            "(128, 200)\n",
            "1 128 1211\n",
            "(128, 1211)\n",
            "1 128 2512\n",
            "(128, 2512)\n",
            "1 128 52\n",
            "(128, 52)\n",
            "1 128 868\n",
            "(128, 868)\n",
            "1 128 106\n",
            "(128, 106)\n",
            "1 128 34\n",
            "(128, 34)\n",
            "1 128 2512\n",
            "(128, 2512)\n",
            "1 128 2584\n",
            "(128, 2584)\n",
            "1 128 72\n",
            "(128, 72)\n",
            "1 128 32\n",
            "(128, 32)\n",
            "1 128 44\n",
            "(128, 44)\n",
            "1 128 194\n",
            "(128, 194)\n",
            "1 128 100\n",
            "(128, 100)\n",
            "1 128 224\n",
            "(128, 224)\n",
            "1 128 1506\n",
            "(128, 1506)\n",
            "1 128 269\n",
            "(128, 269)\n",
            "1 128 518\n",
            "(128, 518)\n",
            "1 128 586\n",
            "(128, 586)\n",
            "1 128 100\n",
            "(128, 100)\n",
            "1 128 194\n",
            "(128, 194)\n",
            "1 128 41\n",
            "(128, 41)\n",
            "1 128 359\n",
            "(128, 359)\n",
            "1 128 282\n",
            "(128, 282)\n",
            "1 128 94\n",
            "(128, 94)\n",
            "1 128 314\n",
            "(128, 314)\n",
            "1 128 1701\n",
            "(128, 1701)\n",
            "1 128 240\n",
            "(128, 240)\n",
            "1 128 55\n",
            "(128, 55)\n",
            "1 128 2512\n",
            "(128, 2512)\n",
            "1 128 1114\n",
            "(128, 1114)\n",
            "1 128 230\n",
            "(128, 230)\n",
            "1 128 47\n",
            "(128, 47)\n",
            "1 128 272\n",
            "(128, 272)\n",
            "1 128 309\n",
            "(128, 309)\n",
            "1 128 259\n",
            "(128, 259)\n",
            "1 128 1512\n",
            "(128, 1512)\n",
            "1 128 2357\n",
            "(128, 2357)\n",
            "1 128 645\n",
            "(128, 645)\n",
            "1 128 52\n",
            "(128, 52)\n",
            "1 128 57\n",
            "(128, 57)\n",
            "1 128 340\n",
            "(128, 340)\n",
            "1 128 369\n",
            "(128, 369)\n",
            "1 128 475\n",
            "(128, 475)\n",
            "1 128 209\n",
            "(128, 209)\n",
            "1 128 1534\n",
            "(128, 1534)\n",
            "1 128 244\n",
            "(128, 244)\n",
            "1 128 1701\n",
            "(128, 1701)\n",
            "1 128 340\n",
            "(128, 340)\n",
            "1 128 908\n",
            "(128, 908)\n",
            "1 128 307\n",
            "(128, 307)\n",
            "1 128 42\n",
            "(128, 42)\n",
            "1 128 50\n",
            "(128, 50)\n",
            "1 128 52\n",
            "(128, 52)\n",
            "1 128 268\n",
            "(128, 268)\n",
            "1 128 47\n",
            "(128, 47)\n",
            "1 128 216\n",
            "(128, 216)\n",
            "1 128 197\n",
            "(128, 197)\n",
            "1 128 716\n",
            "(128, 716)\n",
            "1 128 64\n",
            "(128, 64)\n",
            "1 128 494\n",
            "(128, 494)\n",
            "1 128 34\n",
            "(128, 34)\n",
            "1 128 162\n",
            "(128, 162)\n",
            "1 128 29\n",
            "(128, 29)\n",
            "1 128 436\n",
            "(128, 436)\n",
            "1 128 445\n",
            "(128, 445)\n",
            "1 128 170\n",
            "(128, 170)\n",
            "1 128 40\n",
            "(128, 40)\n",
            "1 128 307\n",
            "(128, 307)\n",
            "1 128 434\n",
            "(128, 434)\n",
            "1 128 1628\n",
            "(128, 1628)\n",
            "1 128 280\n",
            "(128, 280)\n",
            "1 128 48\n",
            "(128, 48)\n",
            "1 128 50\n",
            "(128, 50)\n",
            "1 128 56\n",
            "(128, 56)\n",
            "1 128 257\n",
            "(128, 257)\n",
            "1 128 381\n",
            "(128, 381)\n",
            "1 128 254\n",
            "(128, 254)\n",
            "1 128 1628\n",
            "(128, 1628)\n",
            "1 128 100\n",
            "(128, 100)\n",
            "1 128 451\n",
            "(128, 451)\n",
            "1 128 760\n",
            "(128, 760)\n",
            "1 128 1471\n",
            "(128, 1471)\n",
            "1 128 100\n",
            "(128, 100)\n",
            "1 128 1904\n",
            "(128, 1904)\n",
            "1 128 325\n",
            "(128, 325)\n",
            "1 128 475\n",
            "(128, 475)\n",
            "1 128 381\n",
            "(128, 381)\n",
            "1 128 51\n",
            "(128, 51)\n",
            "1 128 204\n",
            "(128, 204)\n",
            "1 128 50\n",
            "(128, 50)\n",
            "1 128 75\n",
            "(128, 75)\n",
            "1 128 130\n",
            "(128, 130)\n",
            "1 128 1004\n",
            "(128, 1004)\n",
            "1 128 50\n",
            "(128, 50)\n",
            "1 128 88\n",
            "(128, 88)\n",
            "1 128 124\n",
            "(128, 124)\n",
            "1 128 776\n",
            "(128, 776)\n",
            "1 128 76\n",
            "(128, 76)\n",
            "1 128 130\n",
            "(128, 130)\n",
            "1 128 119\n",
            "(128, 119)\n",
            "1 128 62\n",
            "(128, 62)\n",
            "1 128 85\n",
            "(128, 85)\n",
            "1 128 690\n",
            "(128, 690)\n",
            "1 128 1014\n",
            "(128, 1014)\n",
            "1 128 431\n",
            "(128, 431)\n",
            "1 128 125\n",
            "(128, 125)\n",
            "1 128 74\n",
            "(128, 74)\n",
            "1 128 1900\n",
            "(128, 1900)\n",
            "1 128 974\n",
            "(128, 974)\n",
            "1 128 549\n",
            "(128, 549)\n",
            "1 128 2397\n",
            "(128, 2397)\n",
            "1 128 68\n",
            "(128, 68)\n",
            "1 128 1416\n",
            "(128, 1416)\n",
            "1 128 1938\n",
            "(128, 1938)\n",
            "1 128 496\n",
            "(128, 496)\n",
            "1 128 239\n",
            "(128, 239)\n",
            "1 128 74\n",
            "(128, 74)\n",
            "1 128 899\n",
            "(128, 899)\n",
            "1 128 551\n",
            "(128, 551)\n",
            "1 128 68\n",
            "(128, 68)\n",
            "1 128 63\n",
            "(128, 63)\n",
            "1 128 832\n",
            "(128, 832)\n",
            "1 128 555\n",
            "(128, 555)\n",
            "1 128 100\n",
            "(128, 100)\n",
            "1 128 189\n",
            "(128, 189)\n",
            "1 128 431\n",
            "(128, 431)\n",
            "1 128 360\n",
            "(128, 360)\n",
            "1 128 134\n",
            "(128, 134)\n",
            "1 128 897\n",
            "(128, 897)\n",
            "1 128 130\n",
            "(128, 130)\n",
            "1 128 897\n",
            "(128, 897)\n",
            "1 128 137\n",
            "(128, 137)\n",
            "1 128 136\n",
            "(128, 136)\n",
            "1 128 1642\n",
            "(128, 1642)\n",
            "1 128 555\n",
            "(128, 555)\n",
            "1 128 288\n",
            "(128, 288)\n",
            "1 128 1004\n",
            "(128, 1004)\n",
            "1 128 1678\n",
            "(128, 1678)\n",
            "1 128 137\n",
            "(128, 137)\n",
            "1 128 1995\n",
            "(128, 1995)\n",
            "1 128 51\n",
            "(128, 51)\n",
            "1 128 281\n",
            "(128, 281)\n",
            "1 128 137\n",
            "(128, 137)\n",
            "1 128 66\n",
            "(128, 66)\n",
            "1 128 583\n",
            "(128, 583)\n",
            "1 128 119\n",
            "(128, 119)\n",
            "1 128 832\n",
            "(128, 832)\n",
            "1 128 155\n",
            "(128, 155)\n",
            "1 128 75\n",
            "(128, 75)\n",
            "1 128 130\n",
            "(128, 130)\n",
            "1 128 952\n",
            "(128, 952)\n",
            "1 128 281\n",
            "(128, 281)\n",
            "1 128 136\n",
            "(128, 136)\n",
            "1 128 130\n",
            "(128, 130)\n",
            "1 128 124\n",
            "(128, 124)\n",
            "1 128 137\n",
            "(128, 137)\n",
            "1 128 101\n",
            "(128, 101)\n",
            "1 128 744\n",
            "(128, 744)\n",
            "1 128 776\n",
            "(128, 776)\n",
            "1 128 51\n",
            "(128, 51)\n",
            "1 128 76\n",
            "(128, 76)\n",
            "1 128 1004\n",
            "(128, 1004)\n",
            "1 128 50\n",
            "(128, 50)\n",
            "1 128 137\n",
            "(128, 137)\n",
            "1 128 701\n",
            "(128, 701)\n",
            "1 128 431\n",
            "(128, 431)\n",
            "1 128 897\n",
            "(128, 897)\n",
            "1 128 168\n",
            "(128, 168)\n",
            "1 128 70\n",
            "(128, 70)\n",
            "1 128 50\n",
            "(128, 50)\n",
            "1 128 262\n",
            "(128, 262)\n",
            "1 128 68\n",
            "(128, 68)\n",
            "1 128 952\n",
            "(128, 952)\n",
            "1 128 29\n",
            "(128, 29)\n",
            "1 128 125\n",
            "(128, 125)\n",
            "1 128 579\n",
            "(128, 579)\n",
            "1 128 1628\n",
            "(128, 1628)\n",
            "1 128 754\n",
            "(128, 754)\n",
            "1 128 1826\n",
            "(128, 1826)\n",
            "1 128 591\n",
            "(128, 591)\n",
            "1 128 1014\n",
            "(128, 1014)\n",
            "1 128 63\n",
            "(128, 63)\n",
            "1 128 68\n",
            "(128, 68)\n",
            "1 128 84\n",
            "(128, 84)\n",
            "1 128 947\n",
            "(128, 947)\n",
            "1 128 873\n",
            "(128, 873)\n",
            "1 128 360\n",
            "(128, 360)\n",
            "1 128 281\n",
            "(128, 281)\n",
            "1 128 130\n",
            "(128, 130)\n",
            "1 128 431\n",
            "(128, 431)\n",
            "1 128 1841\n",
            "(128, 1841)\n",
            "1 128 389\n",
            "(128, 389)\n",
            "1 128 352\n",
            "(128, 352)\n",
            "1 128 1073\n",
            "(128, 1073)\n",
            "1 128 1103\n",
            "(128, 1103)\n",
            "1 128 1446\n",
            "(128, 1446)\n",
            "1 128 1723\n",
            "(128, 1723)\n",
            "1 128 150\n",
            "(128, 150)\n",
            "1 128 1927\n",
            "(128, 1927)\n",
            "1 128 1927\n",
            "(128, 1927)\n",
            "1 128 1073\n",
            "(128, 1073)\n",
            "1 128 385\n",
            "(128, 385)\n",
            "1 128 1062\n",
            "(128, 1062)\n",
            "1 128 1270\n",
            "(128, 1270)\n",
            "1 128 1103\n",
            "(128, 1103)\n",
            "1 128 352\n",
            "(128, 352)\n",
            "1 128 1383\n",
            "(128, 1383)\n",
            "1 128 87\n",
            "(128, 87)\n",
            "1 128 389\n",
            "(128, 389)\n",
            "1 128 1062\n",
            "(128, 1062)\n",
            "1 128 1723\n",
            "(128, 1723)\n",
            "1 128 300\n",
            "(128, 300)\n",
            "1 128 1523\n",
            "(128, 1523)\n",
            "1 128 1841\n",
            "(128, 1841)\n",
            "1 128 1062\n",
            "(128, 1062)\n",
            "1 128 2424\n",
            "(128, 2424)\n",
            "1 128 1062\n",
            "(128, 1062)\n",
            "1 128 1270\n",
            "(128, 1270)\n",
            "1 128 2424\n",
            "(128, 2424)\n",
            "1 128 300\n",
            "(128, 300)\n",
            "1 128 87\n",
            "(128, 87)\n",
            "1 128 1062\n",
            "(128, 1062)\n",
            "1 128 1383\n",
            "(128, 1383)\n",
            "1 128 1723\n",
            "(128, 1723)\n",
            "1 128 87\n",
            "(128, 87)\n",
            "1 128 1446\n",
            "(128, 1446)\n",
            "1 128 345\n",
            "(128, 345)\n",
            "1 128 478\n",
            "(128, 478)\n",
            "1 128 780\n",
            "(128, 780)\n",
            "1 128 300\n",
            "(128, 300)\n",
            "1 128 895\n",
            "(128, 895)\n",
            "1 128 478\n",
            "(128, 478)\n",
            "1 128 150\n",
            "(128, 150)\n",
            "1 128 1446\n",
            "(128, 1446)\n",
            "1 128 345\n",
            "(128, 345)\n",
            "1 128 1446\n",
            "(128, 1446)\n",
            "1 128 817\n",
            "(128, 817)\n",
            "1 128 1723\n",
            "(128, 1723)\n",
            "1 128 895\n",
            "(128, 895)\n",
            "1 128 1383\n",
            "(128, 1383)\n",
            "1 128 150\n",
            "(128, 150)\n",
            "1 128 87\n",
            "(128, 87)\n",
            "1 128 385\n",
            "(128, 385)\n",
            "1 128 895\n",
            "(128, 895)\n",
            "1 128 87\n",
            "(128, 87)\n",
            "1 128 1062\n",
            "(128, 1062)\n",
            "1 128 1723\n",
            "(128, 1723)\n",
            "1 128 385\n",
            "(128, 385)\n",
            "1 128 1062\n",
            "(128, 1062)\n",
            "1 128 352\n",
            "(128, 352)\n",
            "1 128 2424\n",
            "(128, 2424)\n",
            "1 128 383\n",
            "(128, 383)\n",
            "1 128 1446\n",
            "(128, 1446)\n",
            "1 128 352\n",
            "(128, 352)\n",
            "1 128 1446\n",
            "(128, 1446)\n",
            "1 128 2424\n",
            "(128, 2424)\n",
            "1 128 895\n",
            "(128, 895)\n",
            "1 128 150\n",
            "(128, 150)\n",
            "1 128 1103\n",
            "(128, 1103)\n",
            "1 128 87\n",
            "(128, 87)\n",
            "1 128 1723\n",
            "(128, 1723)\n",
            "1 128 1270\n",
            "(128, 1270)\n",
            "1 128 352\n",
            "(128, 352)\n",
            "1 128 895\n",
            "(128, 895)\n",
            "1 128 1073\n",
            "(128, 1073)\n",
            "1 128 87\n",
            "(128, 87)\n",
            "1 128 345\n",
            "(128, 345)\n",
            "1 128 1270\n",
            "(128, 1270)\n",
            "1 128 1103\n",
            "(128, 1103)\n",
            "1 128 1270\n",
            "(128, 1270)\n",
            "1 128 389\n",
            "(128, 389)\n",
            "1 128 1270\n",
            "(128, 1270)\n",
            "1 128 694\n",
            "(128, 694)\n",
            "1 128 389\n",
            "(128, 389)\n",
            "1 128 1073\n",
            "(128, 1073)\n",
            "1 128 150\n",
            "(128, 150)\n",
            "1 128 2424\n",
            "(128, 2424)\n",
            "1 128 87\n",
            "(128, 87)\n",
            "1 128 1062\n",
            "(128, 1062)\n",
            "1 128 895\n",
            "(128, 895)\n",
            "1 128 478\n",
            "(128, 478)\n",
            "1 128 1927\n",
            "(128, 1927)\n",
            "1 128 385\n",
            "(128, 385)\n",
            "1 128 1446\n",
            "(128, 1446)\n",
            "1 128 1062\n",
            "(128, 1062)\n",
            "1 128 2117\n",
            "(128, 2117)\n",
            "1 128 1446\n",
            "(128, 1446)\n",
            "1 128 694\n",
            "(128, 694)\n",
            "1 128 2424\n",
            "(128, 2424)\n",
            "1 128 345\n",
            "(128, 345)\n",
            "1 128 294\n",
            "(128, 294)\n",
            "1 128 517\n",
            "(128, 517)\n",
            "1 128 30\n",
            "(128, 30)\n",
            "1 128 138\n",
            "(128, 138)\n",
            "1 128 201\n",
            "(128, 201)\n",
            "1 128 275\n",
            "(128, 275)\n",
            "1 128 45\n",
            "(128, 45)\n",
            "1 128 313\n",
            "(128, 313)\n",
            "1 128 58\n",
            "(128, 58)\n",
            "1 128 1653\n",
            "(128, 1653)\n",
            "1 128 66\n",
            "(128, 66)\n",
            "1 128 83\n",
            "(128, 83)\n",
            "1 128 36\n",
            "(128, 36)\n",
            "1 128 133\n",
            "(128, 133)\n",
            "1 128 122\n",
            "(128, 122)\n",
            "1 128 72\n",
            "(128, 72)\n",
            "1 128 110\n",
            "(128, 110)\n",
            "1 128 517\n",
            "(128, 517)\n",
            "1 128 96\n",
            "(128, 96)\n",
            "1 128 716\n",
            "(128, 716)\n",
            "1 128 121\n",
            "(128, 121)\n",
            "1 128 226\n",
            "(128, 226)\n",
            "1 128 517\n",
            "(128, 517)\n",
            "1 128 31\n",
            "(128, 31)\n",
            "1 128 181\n",
            "(128, 181)\n",
            "1 128 99\n",
            "(128, 99)\n",
            "1 128 369\n",
            "(128, 369)\n",
            "1 128 128\n",
            "(128, 128)\n",
            "1 128 71\n",
            "(128, 71)\n",
            "1 128 275\n",
            "(128, 275)\n",
            "1 128 853\n",
            "(128, 853)\n",
            "1 128 66\n",
            "(128, 66)\n",
            "1 128 921\n",
            "(128, 921)\n",
            "1 128 71\n",
            "(128, 71)\n",
            "1 128 1834\n",
            "(128, 1834)\n",
            "1 128 237\n",
            "(128, 237)\n",
            "1 128 83\n",
            "(128, 83)\n",
            "1 128 1491\n",
            "(128, 1491)\n",
            "1 128 186\n",
            "(128, 186)\n",
            "1 128 478\n",
            "(128, 478)\n",
            "1 128 127\n",
            "(128, 127)\n",
            "1 128 259\n",
            "(128, 259)\n",
            "1 128 96\n",
            "(128, 96)\n",
            "1 128 177\n",
            "(128, 177)\n",
            "1 128 226\n",
            "(128, 226)\n",
            "1 128 166\n",
            "(128, 166)\n",
            "1 128 517\n",
            "(128, 517)\n",
            "1 128 99\n",
            "(128, 99)\n",
            "1 128 1627\n",
            "(128, 1627)\n",
            "1 128 235\n",
            "(128, 235)\n",
            "1 128 181\n",
            "(128, 181)\n",
            "1 128 135\n",
            "(128, 135)\n",
            "1 128 166\n",
            "(128, 166)\n",
            "1 128 241\n",
            "(128, 241)\n",
            "1 128 491\n",
            "(128, 491)\n",
            "1 128 608\n",
            "(128, 608)\n",
            "1 128 93\n",
            "(128, 93)\n",
            "1 128 241\n",
            "(128, 241)\n",
            "1 128 472\n",
            "(128, 472)\n",
            "1 128 428\n",
            "(128, 428)\n",
            "1 128 301\n",
            "(128, 301)\n",
            "1 128 491\n",
            "(128, 491)\n",
            "1 128 79\n",
            "(128, 79)\n",
            "1 128 1254\n",
            "(128, 1254)\n",
            "1 128 316\n",
            "(128, 316)\n",
            "1 128 471\n",
            "(128, 471)\n",
            "1 128 101\n",
            "(128, 101)\n",
            "1 128 66\n",
            "(128, 66)\n",
            "1 128 235\n",
            "(128, 235)\n",
            "1 128 96\n",
            "(128, 96)\n",
            "1 128 130\n",
            "(128, 130)\n",
            "1 128 242\n",
            "(128, 242)\n",
            "1 128 355\n",
            "(128, 355)\n",
            "1 128 73\n",
            "(128, 73)\n",
            "1 128 442\n",
            "(128, 442)\n",
            "1 128 125\n",
            "(128, 125)\n",
            "1 128 294\n",
            "(128, 294)\n",
            "1 128 96\n",
            "(128, 96)\n",
            "1 128 69\n",
            "(128, 69)\n",
            "1 128 517\n",
            "(128, 517)\n",
            "1 128 70\n",
            "(128, 70)\n",
            "1 128 1653\n",
            "(128, 1653)\n",
            "1 128 39\n",
            "(128, 39)\n",
            "1 128 87\n",
            "(128, 87)\n",
            "1 128 441\n",
            "(128, 441)\n",
            "1 128 259\n",
            "(128, 259)\n",
            "1 128 398\n",
            "(128, 398)\n",
            "1 128 122\n",
            "(128, 122)\n",
            "1 128 128\n",
            "(128, 128)\n",
            "1 128 41\n",
            "(128, 41)\n",
            "1 128 139\n",
            "(128, 139)\n",
            "1 128 368\n",
            "(128, 368)\n",
            "1 128 87\n",
            "(128, 87)\n",
            "1 128 37\n",
            "(128, 37)\n",
            "1 128 259\n",
            "(128, 259)\n",
            "1 128 368\n",
            "(128, 368)\n",
            "1 128 259\n",
            "(128, 259)\n",
            "1 128 630\n",
            "(128, 630)\n",
            "1 128 118\n",
            "(128, 118)\n",
            "1 128 396\n",
            "(128, 396)\n",
            "1 128 1320\n",
            "(128, 1320)\n",
            "1 128 319\n",
            "(128, 319)\n",
            "1 128 148\n",
            "(128, 148)\n",
            "1 128 158\n",
            "(128, 158)\n",
            "1 128 100\n",
            "(128, 100)\n",
            "1 128 91\n",
            "(128, 91)\n",
            "1 128 121\n",
            "(128, 121)\n",
            "1 128 216\n",
            "(128, 216)\n",
            "1 128 140\n",
            "(128, 140)\n",
            "1 128 201\n",
            "(128, 201)\n",
            "1 128 565\n",
            "(128, 565)\n",
            "1 128 198\n",
            "(128, 198)\n",
            "1 128 205\n",
            "(128, 205)\n",
            "1 128 203\n",
            "(128, 203)\n",
            "1 128 340\n",
            "(128, 340)\n",
            "1 128 145\n",
            "(128, 145)\n",
            "1 128 152\n",
            "(128, 152)\n",
            "1 128 236\n",
            "(128, 236)\n",
            "1 128 95\n",
            "(128, 95)\n",
            "1 128 280\n",
            "(128, 280)\n",
            "1 128 301\n",
            "(128, 301)\n",
            "1 128 417\n",
            "(128, 417)\n",
            "1 128 197\n",
            "(128, 197)\n",
            "1 128 345\n",
            "(128, 345)\n",
            "1 128 1081\n",
            "(128, 1081)\n",
            "1 128 262\n",
            "(128, 262)\n",
            "1 128 60\n",
            "(128, 60)\n",
            "1 128 114\n",
            "(128, 114)\n",
            "1 128 368\n",
            "(128, 368)\n",
            "1 128 1320\n",
            "(128, 1320)\n",
            "1 128 210\n",
            "(128, 210)\n",
            "1 128 224\n",
            "(128, 224)\n",
            "1 128 268\n",
            "(128, 268)\n",
            "1 128 165\n",
            "(128, 165)\n",
            "1 128 1796\n",
            "(128, 1796)\n",
            "1 128 253\n",
            "(128, 253)\n",
            "1 128 1796\n",
            "(128, 1796)\n",
            "1 128 114\n",
            "(128, 114)\n",
            "1 128 280\n",
            "(128, 280)\n",
            "1 128 65\n",
            "(128, 65)\n",
            "1 128 265\n",
            "(128, 265)\n",
            "1 128 141\n",
            "(128, 141)\n",
            "1 128 219\n",
            "(128, 219)\n",
            "1 128 325\n",
            "(128, 325)\n",
            "1 128 67\n",
            "(128, 67)\n",
            "1 128 216\n",
            "(128, 216)\n",
            "1 128 262\n",
            "(128, 262)\n",
            "1 128 77\n",
            "(128, 77)\n",
            "1 128 130\n",
            "(128, 130)\n",
            "1 128 38\n",
            "(128, 38)\n",
            "1 128 797\n",
            "(128, 797)\n",
            "1 128 280\n",
            "(128, 280)\n",
            "1 128 95\n",
            "(128, 95)\n",
            "1 128 270\n",
            "(128, 270)\n",
            "1 128 776\n",
            "(128, 776)\n",
            "1 128 205\n",
            "(128, 205)\n",
            "1 128 114\n",
            "(128, 114)\n",
            "1 128 2403\n",
            "(128, 2403)\n",
            "1 128 145\n",
            "(128, 145)\n",
            "1 128 436\n",
            "(128, 436)\n",
            "1 128 95\n",
            "(128, 95)\n",
            "1 128 177\n",
            "(128, 177)\n",
            "1 128 270\n",
            "(128, 270)\n",
            "1 128 112\n",
            "(128, 112)\n",
            "1 128 62\n",
            "(128, 62)\n",
            "1 128 261\n",
            "(128, 261)\n",
            "1 128 125\n",
            "(128, 125)\n",
            "1 128 389\n",
            "(128, 389)\n",
            "1 128 252\n",
            "(128, 252)\n",
            "1 128 112\n",
            "(128, 112)\n",
            "1 128 95\n",
            "(128, 95)\n",
            "1 128 216\n",
            "(128, 216)\n",
            "1 128 148\n",
            "(128, 148)\n",
            "1 128 164\n",
            "(128, 164)\n",
            "1 128 484\n",
            "(128, 484)\n",
            "1 128 95\n",
            "(128, 95)\n",
            "1 128 270\n",
            "(128, 270)\n",
            "1 128 263\n",
            "(128, 263)\n",
            "1 128 216\n",
            "(128, 216)\n",
            "1 128 129\n",
            "(128, 129)\n",
            "1 128 417\n",
            "(128, 417)\n",
            "1 128 110\n",
            "(128, 110)\n",
            "1 128 1305\n",
            "(128, 1305)\n",
            "1 128 389\n",
            "(128, 389)\n",
            "1 128 271\n",
            "(128, 271)\n",
            "1 128 201\n",
            "(128, 201)\n",
            "1 128 270\n",
            "(128, 270)\n",
            "1 128 177\n",
            "(128, 177)\n",
            "1 128 110\n",
            "(128, 110)\n",
            "1 128 423\n",
            "(128, 423)\n",
            "1 128 389\n",
            "(128, 389)\n",
            "1 128 1305\n",
            "(128, 1305)\n",
            "1 128 175\n",
            "(128, 175)\n",
            "1 128 112\n",
            "(128, 112)\n",
            "1 128 228\n",
            "(128, 228)\n",
            "1 128 224\n",
            "(128, 224)\n",
            "1 128 1279\n",
            "(128, 1279)\n",
            "1 128 152\n",
            "(128, 152)\n",
            "1 128 203\n",
            "(128, 203)\n",
            "1 128 1111\n",
            "(128, 1111)\n",
            "1 128 666\n",
            "(128, 666)\n",
            "1 128 1203\n",
            "(128, 1203)\n",
            "1 128 646\n",
            "(128, 646)\n",
            "1 128 266\n",
            "(128, 266)\n",
            "1 128 778\n",
            "(128, 778)\n",
            "1 128 1103\n",
            "(128, 1103)\n",
            "1 128 1940\n",
            "(128, 1940)\n",
            "1 128 652\n",
            "(128, 652)\n",
            "1 128 769\n",
            "(128, 769)\n",
            "1 128 591\n",
            "(128, 591)\n",
            "1 128 766\n",
            "(128, 766)\n",
            "1 128 769\n",
            "(128, 769)\n",
            "1 128 102\n",
            "(128, 102)\n",
            "1 128 269\n",
            "(128, 269)\n",
            "1 128 1622\n",
            "(128, 1622)\n",
            "1 128 2057\n",
            "(128, 2057)\n",
            "1 128 237\n",
            "(128, 237)\n",
            "1 128 1387\n",
            "(128, 1387)\n",
            "1 128 710\n",
            "(128, 710)\n",
            "1 128 1940\n",
            "(128, 1940)\n",
            "1 128 1103\n",
            "(128, 1103)\n",
            "1 128 591\n",
            "(128, 591)\n",
            "1 128 1320\n",
            "(128, 1320)\n",
            "1 128 1387\n",
            "(128, 1387)\n",
            "1 128 1940\n",
            "(128, 1940)\n",
            "1 128 591\n",
            "(128, 591)\n",
            "1 128 1622\n",
            "(128, 1622)\n",
            "1 128 1333\n",
            "(128, 1333)\n",
            "1 128 666\n",
            "(128, 666)\n",
            "1 128 1555\n",
            "(128, 1555)\n",
            "1 128 179\n",
            "(128, 179)\n",
            "1 128 1103\n",
            "(128, 1103)\n",
            "1 128 237\n",
            "(128, 237)\n",
            "1 128 1387\n",
            "(128, 1387)\n",
            "1 128 259\n",
            "(128, 259)\n",
            "1 128 1940\n",
            "(128, 1940)\n",
            "1 128 591\n",
            "(128, 591)\n",
            "1 128 311\n",
            "(128, 311)\n",
            "1 128 1311\n",
            "(128, 1311)\n",
            "1 128 332\n",
            "(128, 332)\n",
            "1 128 769\n",
            "(128, 769)\n",
            "1 128 1103\n",
            "(128, 1103)\n",
            "1 128 1387\n",
            "(128, 1387)\n",
            "1 128 769\n",
            "(128, 769)\n",
            "1 128 669\n",
            "(128, 669)\n",
            "1 128 248\n",
            "(128, 248)\n",
            "1 128 1311\n",
            "(128, 1311)\n",
            "1 128 1940\n",
            "(128, 1940)\n",
            "1 128 259\n",
            "(128, 259)\n",
            "1 128 198\n",
            "(128, 198)\n",
            "1 128 769\n",
            "(128, 769)\n",
            "1 128 362\n",
            "(128, 362)\n",
            "1 128 783\n",
            "(128, 783)\n",
            "1 128 669\n",
            "(128, 669)\n",
            "1 128 102\n",
            "(128, 102)\n",
            "1 128 248\n",
            "(128, 248)\n",
            "1 128 591\n",
            "(128, 591)\n",
            "1 128 177\n",
            "(128, 177)\n",
            "1 128 2430\n",
            "(128, 2430)\n",
            "1 128 332\n",
            "(128, 332)\n",
            "1 128 1387\n",
            "(128, 1387)\n",
            "1 128 652\n",
            "(128, 652)\n",
            "1 128 669\n",
            "(128, 669)\n",
            "1 128 1555\n",
            "(128, 1555)\n",
            "1 128 179\n",
            "(128, 179)\n",
            "1 128 198\n",
            "(128, 198)\n",
            "1 128 372\n",
            "(128, 372)\n",
            "1 128 177\n",
            "(128, 177)\n",
            "1 128 179\n",
            "(128, 179)\n",
            "1 128 332\n",
            "(128, 332)\n",
            "1 128 1387\n",
            "(128, 1387)\n",
            "1 128 1103\n",
            "(128, 1103)\n",
            "1 128 332\n",
            "(128, 332)\n",
            "1 128 269\n",
            "(128, 269)\n",
            "1 128 198\n",
            "(128, 198)\n",
            "1 128 1387\n",
            "(128, 1387)\n",
            "1 128 1387\n",
            "(128, 1387)\n",
            "1 128 332\n",
            "(128, 332)\n",
            "1 128 1387\n",
            "(128, 1387)\n",
            "1 128 177\n",
            "(128, 177)\n",
            "1 128 1387\n",
            "(128, 1387)\n",
            "1 128 591\n",
            "(128, 591)\n",
            "1 128 1667\n",
            "(128, 1667)\n",
            "1 128 1791\n",
            "(128, 1791)\n",
            "1 128 1311\n",
            "(128, 1311)\n",
            "1 128 715\n",
            "(128, 715)\n",
            "1 128 259\n",
            "(128, 259)\n",
            "1 128 332\n",
            "(128, 332)\n",
            "1 128 171\n",
            "(128, 171)\n",
            "1 128 1791\n",
            "(128, 1791)\n",
            "1 128 198\n",
            "(128, 198)\n",
            "1 128 1103\n",
            "(128, 1103)\n",
            "1 128 372\n",
            "(128, 372)\n",
            "1 128 769\n",
            "(128, 769)\n",
            "1 128 1311\n",
            "(128, 1311)\n",
            "1 128 647\n",
            "(128, 647)\n",
            "1 128 766\n",
            "(128, 766)\n",
            "1 128 778\n",
            "(128, 778)\n",
            "1 128 591\n",
            "(128, 591)\n",
            "1 128 1311\n",
            "(128, 1311)\n",
            "1 128 1404\n",
            "(128, 1404)\n",
            "1 128 70\n",
            "(128, 70)\n",
            "1 128 59\n",
            "(128, 59)\n",
            "1 128 53\n",
            "(128, 53)\n",
            "1 128 96\n",
            "(128, 96)\n",
            "1 128 59\n",
            "(128, 59)\n",
            "1 128 1376\n",
            "(128, 1376)\n",
            "1 128 739\n",
            "(128, 739)\n",
            "1 128 57\n",
            "(128, 57)\n",
            "1 128 418\n",
            "(128, 418)\n",
            "1 128 2432\n",
            "(128, 2432)\n",
            "1 128 69\n",
            "(128, 69)\n",
            "1 128 115\n",
            "(128, 115)\n",
            "1 128 70\n",
            "(128, 70)\n",
            "1 128 288\n",
            "(128, 288)\n",
            "1 128 478\n",
            "(128, 478)\n",
            "1 128 60\n",
            "(128, 60)\n",
            "1 128 1422\n",
            "(128, 1422)\n",
            "1 128 1822\n",
            "(128, 1822)\n",
            "1 128 133\n",
            "(128, 133)\n",
            "1 128 121\n",
            "(128, 121)\n",
            "1 128 2428\n",
            "(128, 2428)\n",
            "1 128 126\n",
            "(128, 126)\n",
            "1 128 164\n",
            "(128, 164)\n",
            "1 128 1588\n",
            "(128, 1588)\n",
            "1 128 70\n",
            "(128, 70)\n",
            "1 128 1376\n",
            "(128, 1376)\n",
            "1 128 64\n",
            "(128, 64)\n",
            "1 128 982\n",
            "(128, 982)\n",
            "1 128 733\n",
            "(128, 733)\n",
            "1 128 59\n",
            "(128, 59)\n",
            "1 128 56\n",
            "(128, 56)\n",
            "1 128 59\n",
            "(128, 59)\n",
            "1 128 186\n",
            "(128, 186)\n",
            "1 128 899\n",
            "(128, 899)\n",
            "1 128 29\n",
            "(128, 29)\n",
            "1 128 120\n",
            "(128, 120)\n",
            "1 128 1374\n",
            "(128, 1374)\n",
            "1 128 1292\n",
            "(128, 1292)\n",
            "1 128 1560\n",
            "(128, 1560)\n",
            "1 128 739\n",
            "(128, 739)\n",
            "1 128 87\n",
            "(128, 87)\n",
            "1 128 57\n",
            "(128, 57)\n",
            "1 128 74\n",
            "(128, 74)\n",
            "1 128 70\n",
            "(128, 70)\n",
            "1 128 48\n",
            "(128, 48)\n",
            "1 128 208\n",
            "(128, 208)\n",
            "1 128 1560\n",
            "(128, 1560)\n",
            "1 128 78\n",
            "(128, 78)\n",
            "1 128 1310\n",
            "(128, 1310)\n",
            "1 128 767\n",
            "(128, 767)\n",
            "1 128 2240\n",
            "(128, 2240)\n",
            "1 128 196\n",
            "(128, 196)\n",
            "1 128 1558\n",
            "(128, 1558)\n",
            "1 128 126\n",
            "(128, 126)\n",
            "1 128 70\n",
            "(128, 70)\n",
            "1 128 1634\n",
            "(128, 1634)\n",
            "1 128 64\n",
            "(128, 64)\n",
            "1 128 59\n",
            "(128, 59)\n",
            "1 128 367\n",
            "(128, 367)\n",
            "1 128 130\n",
            "(128, 130)\n",
            "1 128 1558\n",
            "(128, 1558)\n",
            "1 128 780\n",
            "(128, 780)\n",
            "1 128 335\n",
            "(128, 335)\n",
            "1 128 130\n",
            "(128, 130)\n",
            "1 128 70\n",
            "(128, 70)\n",
            "1 128 164\n",
            "(128, 164)\n",
            "1 128 296\n",
            "(128, 296)\n",
            "1 128 70\n",
            "(128, 70)\n",
            "1 128 296\n",
            "(128, 296)\n",
            "1 128 164\n",
            "(128, 164)\n",
            "1 128 1588\n",
            "(128, 1588)\n",
            "1 128 335\n",
            "(128, 335)\n",
            "1 128 2428\n",
            "(128, 2428)\n",
            "1 128 335\n",
            "(128, 335)\n",
            "1 128 253\n",
            "(128, 253)\n",
            "1 128 57\n",
            "(128, 57)\n",
            "1 128 1733\n",
            "(128, 1733)\n",
            "1 128 367\n",
            "(128, 367)\n",
            "1 128 335\n",
            "(128, 335)\n",
            "1 128 1376\n",
            "(128, 1376)\n",
            "1 128 221\n",
            "(128, 221)\n",
            "1 128 1054\n",
            "(128, 1054)\n",
            "1 128 1353\n",
            "(128, 1353)\n",
            "1 128 1560\n",
            "(128, 1560)\n",
            "1 128 1132\n",
            "(128, 1132)\n",
            "1 128 1157\n",
            "(128, 1157)\n",
            "1 128 48\n",
            "(128, 48)\n",
            "1 128 49\n",
            "(128, 49)\n",
            "1 128 1376\n",
            "(128, 1376)\n",
            "1 128 69\n",
            "(128, 69)\n",
            "1 128 221\n",
            "(128, 221)\n",
            "1 128 574\n",
            "(128, 574)\n",
            "1 128 1404\n",
            "(128, 1404)\n",
            "1 128 2240\n",
            "(128, 2240)\n",
            "1 128 780\n",
            "(128, 780)\n",
            "1 128 70\n",
            "(128, 70)\n",
            "1 128 2428\n",
            "(128, 2428)\n",
            "1 128 93\n",
            "(128, 93)\n",
            "1 128 208\n",
            "(128, 208)\n",
            "1 128 213\n",
            "(128, 213)\n",
            "1 128 1459\n",
            "(128, 1459)\n",
            "1 128 279\n",
            "(128, 279)\n",
            "1 128 1345\n",
            "(128, 1345)\n",
            "1 128 183\n",
            "(128, 183)\n",
            "1 128 381\n",
            "(128, 381)\n",
            "1 128 293\n",
            "(128, 293)\n",
            "1 128 315\n",
            "(128, 315)\n",
            "1 128 213\n",
            "(128, 213)\n",
            "1 128 310\n",
            "(128, 310)\n",
            "1 128 214\n",
            "(128, 214)\n",
            "1 128 1734\n",
            "(128, 1734)\n",
            "1 128 270\n",
            "(128, 270)\n",
            "1 128 213\n",
            "(128, 213)\n",
            "1 128 214\n",
            "(128, 214)\n",
            "1 128 373\n",
            "(128, 373)\n",
            "1 128 119\n",
            "(128, 119)\n",
            "1 128 459\n",
            "(128, 459)\n",
            "1 128 214\n",
            "(128, 214)\n",
            "1 128 2454\n",
            "(128, 2454)\n",
            "1 128 487\n",
            "(128, 487)\n",
            "1 128 459\n",
            "(128, 459)\n",
            "1 128 1120\n",
            "(128, 1120)\n",
            "1 128 373\n",
            "(128, 373)\n",
            "1 128 1345\n",
            "(128, 1345)\n",
            "1 128 345\n",
            "(128, 345)\n",
            "1 128 959\n",
            "(128, 959)\n",
            "1 128 71\n",
            "(128, 71)\n",
            "1 128 409\n",
            "(128, 409)\n",
            "1 128 1550\n",
            "(128, 1550)\n",
            "1 128 1704\n",
            "(128, 1704)\n",
            "1 128 208\n",
            "(128, 208)\n",
            "1 128 459\n",
            "(128, 459)\n",
            "1 128 164\n",
            "(128, 164)\n",
            "1 128 701\n",
            "(128, 701)\n",
            "1 128 340\n",
            "(128, 340)\n",
            "1 128 131\n",
            "(128, 131)\n",
            "1 128 278\n",
            "(128, 278)\n",
            "1 128 166\n",
            "(128, 166)\n",
            "1 128 321\n",
            "(128, 321)\n",
            "1 128 315\n",
            "(128, 315)\n",
            "1 128 80\n",
            "(128, 80)\n",
            "1 128 164\n",
            "(128, 164)\n",
            "1 128 1120\n",
            "(128, 1120)\n",
            "1 128 247\n",
            "(128, 247)\n",
            "1 128 240\n",
            "(128, 240)\n",
            "1 128 87\n",
            "(128, 87)\n",
            "1 128 71\n",
            "(128, 71)\n",
            "1 128 256\n",
            "(128, 256)\n",
            "1 128 666\n",
            "(128, 666)\n",
            "1 128 108\n",
            "(128, 108)\n",
            "1 128 108\n",
            "(128, 108)\n",
            "1 128 62\n",
            "(128, 62)\n",
            "1 128 178\n",
            "(128, 178)\n",
            "1 128 108\n",
            "(128, 108)\n",
            "1 128 1704\n",
            "(128, 1704)\n",
            "1 128 87\n",
            "(128, 87)\n",
            "1 128 959\n",
            "(128, 959)\n",
            "1 128 107\n",
            "(128, 107)\n",
            "1 128 1261\n",
            "(128, 1261)\n",
            "1 128 71\n",
            "(128, 71)\n",
            "1 128 1234\n",
            "(128, 1234)\n",
            "1 128 1120\n",
            "(128, 1120)\n",
            "1 128 214\n",
            "(128, 214)\n",
            "1 128 222\n",
            "(128, 222)\n",
            "1 128 71\n",
            "(128, 71)\n",
            "1 128 538\n",
            "(128, 538)\n",
            "1 128 71\n",
            "(128, 71)\n",
            "1 128 538\n",
            "(128, 538)\n",
            "1 128 2454\n",
            "(128, 2454)\n",
            "1 128 1550\n",
            "(128, 1550)\n",
            "1 128 87\n",
            "(128, 87)\n",
            "1 128 321\n",
            "(128, 321)\n",
            "1 128 1459\n",
            "(128, 1459)\n",
            "1 128 65\n",
            "(128, 65)\n",
            "1 128 381\n",
            "(128, 381)\n",
            "1 128 824\n",
            "(128, 824)\n",
            "1 128 487\n",
            "(128, 487)\n",
            "1 128 36\n",
            "(128, 36)\n",
            "1 128 1704\n",
            "(128, 1704)\n",
            "1 128 107\n",
            "(128, 107)\n",
            "1 128 1511\n",
            "(128, 1511)\n",
            "1 128 71\n",
            "(128, 71)\n",
            "1 128 1550\n",
            "(128, 1550)\n",
            "1 128 113\n",
            "(128, 113)\n",
            "1 128 258\n",
            "(128, 258)\n",
            "1 128 526\n",
            "(128, 526)\n",
            "1 128 213\n",
            "(128, 213)\n",
            "1 128 247\n",
            "(128, 247)\n",
            "1 128 1550\n",
            "(128, 1550)\n",
            "1 128 214\n",
            "(128, 214)\n",
            "1 128 315\n",
            "(128, 315)\n",
            "1 128 36\n",
            "(128, 36)\n",
            "1 128 240\n",
            "(128, 240)\n",
            "1 128 152\n",
            "(128, 152)\n",
            "1 128 71\n",
            "(128, 71)\n",
            "1 128 213\n",
            "(128, 213)\n",
            "1 128 178\n",
            "(128, 178)\n",
            "1 128 213\n",
            "(128, 213)\n",
            "1 128 459\n",
            "(128, 459)\n",
            "1 128 544\n",
            "(128, 544)\n",
            "1 128 387\n",
            "(128, 387)\n",
            "1 128 242\n",
            "(128, 242)\n",
            "1 128 544\n",
            "(128, 544)\n",
            "1 128 161\n",
            "(128, 161)\n",
            "1 128 1771\n",
            "(128, 1771)\n",
            "1 128 417\n",
            "(128, 417)\n",
            "1 128 205\n",
            "(128, 205)\n",
            "1 128 194\n",
            "(128, 194)\n",
            "1 128 201\n",
            "(128, 201)\n",
            "1 128 293\n",
            "(128, 293)\n",
            "1 128 387\n",
            "(128, 387)\n",
            "1 128 320\n",
            "(128, 320)\n",
            "1 128 260\n",
            "(128, 260)\n",
            "1 128 613\n",
            "(128, 613)\n",
            "1 128 672\n",
            "(128, 672)\n",
            "1 128 247\n",
            "(128, 247)\n",
            "1 128 161\n",
            "(128, 161)\n",
            "1 128 1849\n",
            "(128, 1849)\n",
            "1 128 194\n",
            "(128, 194)\n",
            "1 128 210\n",
            "(128, 210)\n",
            "1 128 232\n",
            "(128, 232)\n",
            "1 128 672\n",
            "(128, 672)\n",
            "1 128 1809\n",
            "(128, 1809)\n",
            "1 128 194\n",
            "(128, 194)\n",
            "1 128 1240\n",
            "(128, 1240)\n",
            "1 128 205\n",
            "(128, 205)\n",
            "1 128 364\n",
            "(128, 364)\n",
            "1 128 431\n",
            "(128, 431)\n",
            "1 128 646\n",
            "(128, 646)\n",
            "1 128 1240\n",
            "(128, 1240)\n",
            "1 128 268\n",
            "(128, 268)\n",
            "1 128 320\n",
            "(128, 320)\n",
            "1 128 1809\n",
            "(128, 1809)\n",
            "1 128 672\n",
            "(128, 672)\n",
            "1 128 194\n",
            "(128, 194)\n",
            "1 128 194\n",
            "(128, 194)\n",
            "1 128 196\n",
            "(128, 196)\n",
            "1 128 1046\n",
            "(128, 1046)\n",
            "1 128 581\n",
            "(128, 581)\n",
            "1 128 320\n",
            "(128, 320)\n",
            "1 128 201\n",
            "(128, 201)\n",
            "1 128 892\n",
            "(128, 892)\n",
            "1 128 320\n",
            "(128, 320)\n",
            "1 128 2379\n",
            "(128, 2379)\n",
            "1 128 320\n",
            "(128, 320)\n",
            "1 128 1809\n",
            "(128, 1809)\n",
            "1 128 581\n",
            "(128, 581)\n",
            "1 128 1857\n",
            "(128, 1857)\n",
            "1 128 646\n",
            "(128, 646)\n",
            "1 128 672\n",
            "(128, 672)\n",
            "1 128 201\n",
            "(128, 201)\n",
            "1 128 88\n",
            "(128, 88)\n",
            "1 128 1809\n",
            "(128, 1809)\n",
            "1 128 1857\n",
            "(128, 1857)\n",
            "1 128 880\n",
            "(128, 880)\n",
            "1 128 205\n",
            "(128, 205)\n",
            "1 128 1046\n",
            "(128, 1046)\n",
            "1 128 1809\n",
            "(128, 1809)\n",
            "1 128 210\n",
            "(128, 210)\n",
            "1 128 364\n",
            "(128, 364)\n",
            "1 128 581\n",
            "(128, 581)\n",
            "1 128 206\n",
            "(128, 206)\n",
            "1 128 880\n",
            "(128, 880)\n",
            "1 128 201\n",
            "(128, 201)\n",
            "1 128 1809\n",
            "(128, 1809)\n",
            "1 128 1809\n",
            "(128, 1809)\n",
            "1 128 121\n",
            "(128, 121)\n",
            "1 128 1809\n",
            "(128, 1809)\n",
            "1 128 653\n",
            "(128, 653)\n",
            "1 128 892\n",
            "(128, 892)\n",
            "1 128 195\n",
            "(128, 195)\n",
            "1 128 498\n",
            "(128, 498)\n",
            "1 128 210\n",
            "(128, 210)\n",
            "1 128 293\n",
            "(128, 293)\n",
            "1 128 80\n",
            "(128, 80)\n",
            "1 128 315\n",
            "(128, 315)\n",
            "1 128 591\n",
            "(128, 591)\n",
            "1 128 718\n",
            "(128, 718)\n",
            "1 128 194\n",
            "(128, 194)\n",
            "1 128 194\n",
            "(128, 194)\n",
            "1 128 880\n",
            "(128, 880)\n",
            "1 128 1809\n",
            "(128, 1809)\n",
            "1 128 210\n",
            "(128, 210)\n",
            "1 128 201\n",
            "(128, 201)\n",
            "1 128 1809\n",
            "(128, 1809)\n",
            "1 128 205\n",
            "(128, 205)\n",
            "1 128 892\n",
            "(128, 892)\n",
            "1 128 880\n",
            "(128, 880)\n",
            "1 128 1004\n",
            "(128, 1004)\n",
            "1 128 1240\n",
            "(128, 1240)\n",
            "1 128 672\n",
            "(128, 672)\n",
            "1 128 1538\n",
            "(128, 1538)\n",
            "1 128 121\n",
            "(128, 121)\n",
            "1 128 880\n",
            "(128, 880)\n",
            "1 128 655\n",
            "(128, 655)\n",
            "1 128 195\n",
            "(128, 195)\n",
            "1 128 2379\n",
            "(128, 2379)\n",
            "1 128 1240\n",
            "(128, 1240)\n",
            "1 128 320\n",
            "(128, 320)\n",
            "1 128 688\n",
            "(128, 688)\n",
            "1 128 2561\n",
            "(128, 2561)\n",
            "1 128 46\n",
            "(128, 46)\n",
            "1 128 809\n",
            "(128, 809)\n",
            "1 128 545\n",
            "(128, 545)\n",
            "1 128 583\n",
            "(128, 583)\n",
            "1 128 162\n",
            "(128, 162)\n",
            "1 128 2240\n",
            "(128, 2240)\n",
            "1 128 784\n",
            "(128, 784)\n",
            "1 128 842\n",
            "(128, 842)\n",
            "1 128 1503\n",
            "(128, 1503)\n",
            "1 128 669\n",
            "(128, 669)\n",
            "1 128 543\n",
            "(128, 543)\n",
            "1 128 1193\n",
            "(128, 1193)\n",
            "1 128 38\n",
            "(128, 38)\n",
            "1 128 303\n",
            "(128, 303)\n",
            "1 128 209\n",
            "(128, 209)\n",
            "1 128 598\n",
            "(128, 598)\n",
            "1 128 842\n",
            "(128, 842)\n",
            "1 128 855\n",
            "(128, 855)\n",
            "1 128 557\n",
            "(128, 557)\n",
            "1 128 594\n",
            "(128, 594)\n",
            "1 128 573\n",
            "(128, 573)\n",
            "1 128 59\n",
            "(128, 59)\n",
            "1 128 502\n",
            "(128, 502)\n",
            "1 128 68\n",
            "(128, 68)\n",
            "1 128 704\n",
            "(128, 704)\n",
            "1 128 669\n",
            "(128, 669)\n",
            "1 128 2561\n",
            "(128, 2561)\n",
            "1 128 623\n",
            "(128, 623)\n",
            "1 128 80\n",
            "(128, 80)\n",
            "1 128 179\n",
            "(128, 179)\n",
            "1 128 464\n",
            "(128, 464)\n",
            "1 128 295\n",
            "(128, 295)\n",
            "1 128 751\n",
            "(128, 751)\n",
            "1 128 713\n",
            "(128, 713)\n",
            "1 128 797\n",
            "(128, 797)\n",
            "1 128 43\n",
            "(128, 43)\n",
            "1 128 60\n",
            "(128, 60)\n",
            "1 128 409\n",
            "(128, 409)\n",
            "1 128 264\n",
            "(128, 264)\n",
            "1 128 53\n",
            "(128, 53)\n",
            "1 128 414\n",
            "(128, 414)\n",
            "1 128 603\n",
            "(128, 603)\n",
            "1 128 699\n",
            "(128, 699)\n",
            "1 128 385\n",
            "(128, 385)\n",
            "1 128 65\n",
            "(128, 65)\n",
            "1 128 138\n",
            "(128, 138)\n",
            "1 128 217\n",
            "(128, 217)\n",
            "1 128 598\n",
            "(128, 598)\n",
            "1 128 94\n",
            "(128, 94)\n",
            "1 128 64\n",
            "(128, 64)\n",
            "1 128 572\n",
            "(128, 572)\n",
            "1 128 37\n",
            "(128, 37)\n",
            "1 128 142\n",
            "(128, 142)\n",
            "1 128 348\n",
            "(128, 348)\n",
            "1 128 1579\n",
            "(128, 1579)\n",
            "1 128 130\n",
            "(128, 130)\n",
            "1 128 566\n",
            "(128, 566)\n",
            "1 128 856\n",
            "(128, 856)\n",
            "1 128 696\n",
            "(128, 696)\n",
            "1 128 328\n",
            "(128, 328)\n",
            "1 128 53\n",
            "(128, 53)\n",
            "1 128 685\n",
            "(128, 685)\n",
            "1 128 806\n",
            "(128, 806)\n",
            "1 128 842\n",
            "(128, 842)\n",
            "1 128 589\n",
            "(128, 589)\n",
            "1 128 342\n",
            "(128, 342)\n",
            "1 128 803\n",
            "(128, 803)\n",
            "1 128 651\n",
            "(128, 651)\n",
            "1 128 52\n",
            "(128, 52)\n",
            "1 128 392\n",
            "(128, 392)\n",
            "1 128 562\n",
            "(128, 562)\n",
            "1 128 80\n",
            "(128, 80)\n",
            "1 128 237\n",
            "(128, 237)\n",
            "1 128 663\n",
            "(128, 663)\n",
            "1 128 397\n",
            "(128, 397)\n",
            "1 128 706\n",
            "(128, 706)\n",
            "1 128 143\n",
            "(128, 143)\n",
            "1 128 341\n",
            "(128, 341)\n",
            "1 128 64\n",
            "(128, 64)\n",
            "1 128 314\n",
            "(128, 314)\n",
            "1 128 244\n",
            "(128, 244)\n",
            "1 128 464\n",
            "(128, 464)\n",
            "1 128 484\n",
            "(128, 484)\n",
            "1 128 598\n",
            "(128, 598)\n",
            "1 128 610\n",
            "(128, 610)\n",
            "1 128 582\n",
            "(128, 582)\n",
            "1 128 34\n",
            "(128, 34)\n",
            "1 128 244\n",
            "(128, 244)\n",
            "1 128 573\n",
            "(128, 573)\n",
            "1 128 807\n",
            "(128, 807)\n",
            "1 128 160\n",
            "(128, 160)\n",
            "1 128 473\n",
            "(128, 473)\n",
            "1 128 256\n",
            "(128, 256)\n",
            "1 128 374\n",
            "(128, 374)\n",
            "1 128 812\n",
            "(128, 812)\n",
            "1 128 201\n",
            "(128, 201)\n",
            "1 128 734\n",
            "(128, 734)\n",
            "1 128 228\n",
            "(128, 228)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The data provided has constant frequency scale in spectrogram.\n",
        "# But, the duration(time) is different for all the provided samples.\n",
        "# Hence, it is necessary to pad the data\n",
        "\n",
        "# get the max_length of spectrograms in the time axis\n",
        "max_duration=0\n",
        "for spec in mel_spectrograms:\n",
        "  m,n=spec.shape\n",
        "  if max_duration<n:\n",
        "      max_duration=n\n",
        "\n",
        "# add padding in the given .npy files\n",
        "features=[]\n",
        "for spec in mel_spectrograms:\n",
        "  mat=numpy.pad(spec, [(0, 0), (0, max_duration-spec[0].size)], mode='constant', constant_values=0)\n",
        "  mat=mat.reshape((mat.shape[0], mat.shape[1], 1))\n",
        "  features.append(mat)"
      ],
      "metadata": {
        "id": "C3a9oLij55tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert features list into numpy.ndarray type\n",
        "features=numpy.array(features)"
      ],
      "metadata": {
        "id": "grQIczgJbaO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['label'].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Myz2C6Fu6VKK",
        "outputId": "e4fdd05b-601c-4940-a011-9808fd91ffb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count     1000\n",
              "unique      10\n",
              "top       Bark\n",
              "freq       100\n",
              "Name: label, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# need to convert training data into tensor datatype\n",
        "i=0\n",
        "for _ in features:\n",
        "    features[i]= tf.convert_to_tensor(features[i])\n",
        "    i=i+1"
      ],
      "metadata": {
        "id": "xGcaW9gT6lZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Splitting Dataset into training and validation**"
      ],
      "metadata": {
        "id": "HUXaGUdhdGc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=features\n",
        "y=data['label']\n",
        "\n",
        "# used 'random_state' of 40 while splitting to get the balanced split of data \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40, shuffle=\"true\")"
      ],
      "metadata": {
        "id": "ZLjVti4_6t3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the count of classes present in y_test\n",
        "print(type(y_test))\n",
        "val_label=pd.Series(list(y_test))\n",
        "val_label.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vb7FX8HUdcjT",
        "outputId": "dac013c3-aa30-4c29-d585-be952ca3f02b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Bark                                     22\n",
              "Walk_and_footsteps                       22\n",
              "Doorbell                                 22\n",
              "Crying_and_sobbing                       21\n",
              "Siren                                    20\n",
              "Knock                                    20\n",
              "Vehicle_horn_and_car_horn_and_honking    20\n",
              "Microwave_oven                           19\n",
              "Shatter                                  17\n",
              "Meow                                     17\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Convert label data (y_train & y_test) into 'one-hot vector' format**"
      ],
      "metadata": {
        "id": "_1O1vPt9eisG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "train_encoder = LabelEncoder()\n",
        "train_ = train_encoder.fit_transform(y_train)\n",
        "to_onehot=to_categorical(train_)\n",
        "y_train=to_onehot\n",
        "\n",
        "test_encoder = LabelEncoder()\n",
        "test_ = test_encoder.fit_transform(y_test)\n",
        "to_onehot=to_categorical(test_)\n",
        "y_test=to_onehot"
      ],
      "metadata": {
        "id": "Bw4vn3IV8uuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definitions for recall, precision and f1 metrics"
      ],
      "metadata": {
        "id": "MKh5Njkiflou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reference: https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n",
        "from keras import backend \n",
        "from sklearn.metrics import precision_score , recall_score\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = backend.sum(backend.round(backend.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + backend.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = backend.sum(backend.round(backend.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + backend.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+backend.epsilon())) "
      ],
      "metadata": {
        "id": "QFBZGfkwi1Ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ANN Model**"
      ],
      "metadata": {
        "id": "JKtI2M-tiMPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pool_size = (2, 2)\n",
        "kernel_size = (3, 3)\n",
        "input_shape = X_train.shape\n",
        "num_classes = 10\n",
        "print(X_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00VA1GInKTUA",
        "outputId": "a765709e-d9c4-4422-b4f8-38722b2eec6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(800, 128, 2584, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    #Fully connected 1st layer\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "]) "
      ],
      "metadata": {
        "id": "WypDxjA4iPnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.build(input_shape)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "k9E_fHvhiuLU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c02016b-3c91-4e1c-ac91-ee05716b3651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (800, 330752)             0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (800, 330752)             0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (800, 128)                42336384  \n",
            "                                                                 \n",
            " dense_4 (Dense)             (800, 128)                16512     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (800, 10)                 1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,354,186\n",
            "Trainable params: 42,354,186\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model using Adam optimizer\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "          loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "          metrics=[\"accuracy\", f1_m, precision_m, recall_m])"
      ],
      "metadata": {
        "id": "c9LejeMgZa_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training**"
      ],
      "metadata": {
        "id": "hP6Hcbq9jhTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To keep track of the best metrices obtained while training the model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "filepath = '/content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_ann.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
      ],
      "metadata": {
        "id": "Ofn1Gx2QZjUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=64, epochs=150, verbose = 1, callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLeQhciRRCwB",
        "outputId": "9fbb6219-cf7c-4547-e54f-3016cf6d9680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 56.5464 - accuracy: 0.1363 - f1_m: 0.1232 - precision_m: 0.1281 - recall_m: 0.1190\n",
            "Epoch 1: val_loss improved from inf to 45.92176, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_ann.hdf5\n",
            "13/13 [==============================] - 4s 264ms/step - loss: 56.5464 - accuracy: 0.1363 - f1_m: 0.1232 - precision_m: 0.1281 - recall_m: 0.1190 - val_loss: 45.9218 - val_accuracy: 0.1400 - val_f1_m: 0.1916 - val_precision_m: 0.1918 - val_recall_m: 0.1914\n",
            "Epoch 2/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 23.2767 - accuracy: 0.1863 - f1_m: 0.1788 - precision_m: 0.1897 - recall_m: 0.1695\n",
            "Epoch 2: val_loss improved from 45.92176 to 22.31333, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_ann.hdf5\n",
            "13/13 [==============================] - 3s 233ms/step - loss: 23.2767 - accuracy: 0.1863 - f1_m: 0.1788 - precision_m: 0.1897 - recall_m: 0.1695 - val_loss: 22.3133 - val_accuracy: 0.1800 - val_f1_m: 0.2407 - val_precision_m: 0.2799 - val_recall_m: 0.2148\n",
            "Epoch 3/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 14.3937 - accuracy: 0.2409 - f1_m: 0.2399 - precision_m: 0.2520 - recall_m: 0.2292\n",
            "Epoch 3: val_loss improved from 22.31333 to 20.48157, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_ann.hdf5\n",
            "13/13 [==============================] - 3s 228ms/step - loss: 14.3587 - accuracy: 0.2425 - f1_m: 0.2442 - precision_m: 0.2565 - recall_m: 0.2332 - val_loss: 20.4816 - val_accuracy: 0.2200 - val_f1_m: 0.2892 - val_precision_m: 0.3025 - val_recall_m: 0.2773\n",
            "Epoch 4/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 10.6240 - accuracy: 0.3325 - f1_m: 0.3301 - precision_m: 0.3526 - recall_m: 0.3113\n",
            "Epoch 4: val_loss improved from 20.48157 to 18.14897, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_ann.hdf5\n",
            "13/13 [==============================] - 3s 251ms/step - loss: 10.6240 - accuracy: 0.3325 - f1_m: 0.3301 - precision_m: 0.3526 - recall_m: 0.3113 - val_loss: 18.1490 - val_accuracy: 0.3650 - val_f1_m: 0.3742 - val_precision_m: 0.4279 - val_recall_m: 0.3359\n",
            "Epoch 5/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 8.3144 - accuracy: 0.3887 - f1_m: 0.3949 - precision_m: 0.4255 - recall_m: 0.3690\n",
            "Epoch 5: val_loss improved from 18.14897 to 15.00650, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_ann.hdf5\n",
            "13/13 [==============================] - 3s 233ms/step - loss: 8.3144 - accuracy: 0.3887 - f1_m: 0.3949 - precision_m: 0.4255 - recall_m: 0.3690 - val_loss: 15.0065 - val_accuracy: 0.3200 - val_f1_m: 0.3371 - val_precision_m: 0.3558 - val_recall_m: 0.3203\n",
            "Epoch 6/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.6509 - accuracy: 0.4450 - f1_m: 0.4311 - precision_m: 0.4667 - recall_m: 0.4014\n",
            "Epoch 6: val_loss improved from 15.00650 to 10.88605, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_ann.hdf5\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 6.6509 - accuracy: 0.4450 - f1_m: 0.4311 - precision_m: 0.4667 - recall_m: 0.4014 - val_loss: 10.8860 - val_accuracy: 0.3650 - val_f1_m: 0.3378 - val_precision_m: 0.3981 - val_recall_m: 0.3008\n",
            "Epoch 7/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.9067 - accuracy: 0.4837 - f1_m: 0.4748 - precision_m: 0.5098 - recall_m: 0.4447\n",
            "Epoch 7: val_loss did not improve from 10.88605\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 4.9067 - accuracy: 0.4837 - f1_m: 0.4748 - precision_m: 0.5098 - recall_m: 0.4447 - val_loss: 11.1101 - val_accuracy: 0.4400 - val_f1_m: 0.4437 - val_precision_m: 0.5008 - val_recall_m: 0.4023\n",
            "Epoch 8/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.2662 - accuracy: 0.4963 - f1_m: 0.4914 - precision_m: 0.5168 - recall_m: 0.4688\n",
            "Epoch 8: val_loss did not improve from 10.88605\n",
            "13/13 [==============================] - 1s 65ms/step - loss: 4.2662 - accuracy: 0.4963 - f1_m: 0.4914 - precision_m: 0.5168 - recall_m: 0.4688 - val_loss: 14.5627 - val_accuracy: 0.5450 - val_f1_m: 0.5536 - val_precision_m: 0.5883 - val_recall_m: 0.5234\n",
            "Epoch 9/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 3.8366 - accuracy: 0.5495 - f1_m: 0.5400 - precision_m: 0.5860 - recall_m: 0.5013\n",
            "Epoch 9: val_loss did not improve from 10.88605\n",
            "13/13 [==============================] - 1s 66ms/step - loss: 3.8258 - accuracy: 0.5475 - f1_m: 0.5388 - precision_m: 0.5834 - recall_m: 0.5012 - val_loss: 13.5829 - val_accuracy: 0.4200 - val_f1_m: 0.3621 - val_precision_m: 0.4004 - val_recall_m: 0.3359\n",
            "Epoch 10/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.0150 - accuracy: 0.5938 - f1_m: 0.6041 - precision_m: 0.6562 - recall_m: 0.5601\n",
            "Epoch 10: val_loss did not improve from 10.88605\n",
            "13/13 [==============================] - 1s 66ms/step - loss: 3.0150 - accuracy: 0.5938 - f1_m: 0.6041 - precision_m: 0.6562 - recall_m: 0.5601 - val_loss: 11.0668 - val_accuracy: 0.4650 - val_f1_m: 0.5133 - val_precision_m: 0.5692 - val_recall_m: 0.4688\n",
            "Epoch 11/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4293 - accuracy: 0.6150 - f1_m: 0.5985 - precision_m: 0.6513 - recall_m: 0.5541\n",
            "Epoch 11: val_loss improved from 10.88605 to 10.19109, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_ann.hdf5\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 2.4293 - accuracy: 0.6150 - f1_m: 0.5985 - precision_m: 0.6513 - recall_m: 0.5541 - val_loss: 10.1911 - val_accuracy: 0.5200 - val_f1_m: 0.5230 - val_precision_m: 0.5533 - val_recall_m: 0.4961\n",
            "Epoch 12/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 3.6365 - accuracy: 0.6302 - f1_m: 0.6226 - precision_m: 0.6547 - recall_m: 0.5938\n",
            "Epoch 12: val_loss did not improve from 10.19109\n",
            "13/13 [==============================] - 1s 65ms/step - loss: 3.5441 - accuracy: 0.6375 - f1_m: 0.6353 - precision_m: 0.6680 - recall_m: 0.6058 - val_loss: 12.0742 - val_accuracy: 0.5050 - val_f1_m: 0.4341 - val_precision_m: 0.4842 - val_recall_m: 0.3984\n",
            "Epoch 13/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.8755 - accuracy: 0.5950 - f1_m: 0.5897 - precision_m: 0.6234 - recall_m: 0.5601\n",
            "Epoch 13: val_loss did not improve from 10.19109\n",
            "13/13 [==============================] - 1s 66ms/step - loss: 2.8755 - accuracy: 0.5950 - f1_m: 0.5897 - precision_m: 0.6234 - recall_m: 0.5601 - val_loss: 10.7804 - val_accuracy: 0.5150 - val_f1_m: 0.5065 - val_precision_m: 0.5635 - val_recall_m: 0.4648\n",
            "Epoch 14/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5617 - accuracy: 0.6875 - f1_m: 0.6885 - precision_m: 0.7340 - recall_m: 0.6490\n",
            "Epoch 14: val_loss improved from 10.19109 to 8.96088, saving model to /content/drive/MyDrive/Audio_Classification-MLSP/my_best_model_ann.hdf5\n",
            "13/13 [==============================] - 3s 232ms/step - loss: 1.5617 - accuracy: 0.6875 - f1_m: 0.6885 - precision_m: 0.7340 - recall_m: 0.6490 - val_loss: 8.9609 - val_accuracy: 0.5850 - val_f1_m: 0.5884 - val_precision_m: 0.6392 - val_recall_m: 0.5469\n",
            "Epoch 15/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3605 - accuracy: 0.7412 - f1_m: 0.7425 - precision_m: 0.7923 - recall_m: 0.6995\n",
            "Epoch 15: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 64ms/step - loss: 1.3605 - accuracy: 0.7412 - f1_m: 0.7425 - precision_m: 0.7923 - recall_m: 0.6995 - val_loss: 9.8059 - val_accuracy: 0.5750 - val_f1_m: 0.5821 - val_precision_m: 0.6533 - val_recall_m: 0.5312\n",
            "Epoch 16/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3417 - accuracy: 0.7425 - f1_m: 0.7416 - precision_m: 0.7864 - recall_m: 0.7019\n",
            "Epoch 16: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 65ms/step - loss: 1.3417 - accuracy: 0.7425 - f1_m: 0.7416 - precision_m: 0.7864 - recall_m: 0.7019 - val_loss: 12.4707 - val_accuracy: 0.5350 - val_f1_m: 0.6216 - val_precision_m: 0.6756 - val_recall_m: 0.5781\n",
            "Epoch 17/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.3358 - accuracy: 0.6712 - f1_m: 0.6825 - precision_m: 0.7139 - recall_m: 0.6538\n",
            "Epoch 17: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 66ms/step - loss: 2.3358 - accuracy: 0.6712 - f1_m: 0.6825 - precision_m: 0.7139 - recall_m: 0.6538 - val_loss: 11.8163 - val_accuracy: 0.5200 - val_f1_m: 0.5466 - val_precision_m: 0.5897 - val_recall_m: 0.5117\n",
            "Epoch 18/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 3.2957 - accuracy: 0.6328 - f1_m: 0.6399 - precision_m: 0.6802 - recall_m: 0.6055\n",
            "Epoch 18: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 66ms/step - loss: 3.2182 - accuracy: 0.6350 - f1_m: 0.6420 - precision_m: 0.6828 - recall_m: 0.6070 - val_loss: 10.4658 - val_accuracy: 0.4950 - val_f1_m: 0.4762 - val_precision_m: 0.4974 - val_recall_m: 0.4570\n",
            "Epoch 19/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 2.3172 - accuracy: 0.6576 - f1_m: 0.6562 - precision_m: 0.6913 - recall_m: 0.6250\n",
            "Epoch 19: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 65ms/step - loss: 2.3643 - accuracy: 0.6500 - f1_m: 0.6405 - precision_m: 0.6740 - recall_m: 0.6106 - val_loss: 10.1823 - val_accuracy: 0.5600 - val_f1_m: 0.5520 - val_precision_m: 0.5662 - val_recall_m: 0.5391\n",
            "Epoch 20/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.0634 - accuracy: 0.6050 - f1_m: 0.5979 - precision_m: 0.6206 - recall_m: 0.5769\n",
            "Epoch 20: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 66ms/step - loss: 4.0634 - accuracy: 0.6050 - f1_m: 0.5979 - precision_m: 0.6206 - recall_m: 0.5769 - val_loss: 11.9281 - val_accuracy: 0.5450 - val_f1_m: 0.5755 - val_precision_m: 0.6031 - val_recall_m: 0.5508\n",
            "Epoch 21/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.8198 - accuracy: 0.6388 - f1_m: 0.6426 - precision_m: 0.6738 - recall_m: 0.6142\n",
            "Epoch 21: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 65ms/step - loss: 2.8198 - accuracy: 0.6388 - f1_m: 0.6426 - precision_m: 0.6738 - recall_m: 0.6142 - val_loss: 9.5252 - val_accuracy: 0.5650 - val_f1_m: 0.5432 - val_precision_m: 0.5746 - val_recall_m: 0.5156\n",
            "Epoch 22/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.4747 - accuracy: 0.6862 - f1_m: 0.6848 - precision_m: 0.7151 - recall_m: 0.6575\n",
            "Epoch 22: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 66ms/step - loss: 2.4747 - accuracy: 0.6862 - f1_m: 0.6848 - precision_m: 0.7151 - recall_m: 0.6575 - val_loss: 9.2893 - val_accuracy: 0.5650 - val_f1_m: 0.5967 - val_precision_m: 0.6263 - val_recall_m: 0.5703\n",
            "Epoch 23/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5347 - accuracy: 0.7550 - f1_m: 0.7585 - precision_m: 0.7874 - recall_m: 0.7320\n",
            "Epoch 23: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 65ms/step - loss: 1.5347 - accuracy: 0.7550 - f1_m: 0.7585 - precision_m: 0.7874 - recall_m: 0.7320 - val_loss: 12.2136 - val_accuracy: 0.6100 - val_f1_m: 0.6107 - val_precision_m: 0.6247 - val_recall_m: 0.5977\n",
            "Epoch 24/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.3726 - accuracy: 0.7500 - f1_m: 0.7517 - precision_m: 0.7798 - recall_m: 0.7260\n",
            "Epoch 24: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 1.3726 - accuracy: 0.7500 - f1_m: 0.7517 - precision_m: 0.7798 - recall_m: 0.7260 - val_loss: 11.0874 - val_accuracy: 0.5800 - val_f1_m: 0.5872 - val_precision_m: 0.6313 - val_recall_m: 0.5508\n",
            "Epoch 25/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.8646 - accuracy: 0.7943 - f1_m: 0.7984 - precision_m: 0.8328 - recall_m: 0.7669\n",
            "Epoch 25: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.8475 - accuracy: 0.7975 - f1_m: 0.8051 - precision_m: 0.8404 - recall_m: 0.7728 - val_loss: 11.2347 - val_accuracy: 0.6250 - val_f1_m: 0.6238 - val_precision_m: 0.6929 - val_recall_m: 0.5742\n",
            "Epoch 26/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.6435 - accuracy: 0.8398 - f1_m: 0.8376 - precision_m: 0.8697 - recall_m: 0.8086\n",
            "Epoch 26: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.6387 - accuracy: 0.8388 - f1_m: 0.8366 - precision_m: 0.8673 - recall_m: 0.8089 - val_loss: 10.3673 - val_accuracy: 0.6400 - val_f1_m: 0.6359 - val_precision_m: 0.6519 - val_recall_m: 0.6211\n",
            "Epoch 27/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.6854 - accuracy: 0.8451 - f1_m: 0.8495 - precision_m: 0.8780 - recall_m: 0.8229\n",
            "Epoch 27: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 0.6876 - accuracy: 0.8438 - f1_m: 0.8472 - precision_m: 0.8768 - recall_m: 0.8197 - val_loss: 10.9014 - val_accuracy: 0.6650 - val_f1_m: 0.6661 - val_precision_m: 0.7295 - val_recall_m: 0.6211\n",
            "Epoch 28/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8649 - accuracy: 0.8525 - f1_m: 0.8437 - precision_m: 0.8763 - recall_m: 0.8137\n",
            "Epoch 28: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.8649 - accuracy: 0.8525 - f1_m: 0.8437 - precision_m: 0.8763 - recall_m: 0.8137 - val_loss: 10.7965 - val_accuracy: 0.5800 - val_f1_m: 0.6007 - val_precision_m: 0.6259 - val_recall_m: 0.5781\n",
            "Epoch 29/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9568 - accuracy: 0.7937 - f1_m: 0.7836 - precision_m: 0.8086 - recall_m: 0.7608\n",
            "Epoch 29: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 66ms/step - loss: 0.9568 - accuracy: 0.7937 - f1_m: 0.7836 - precision_m: 0.8086 - recall_m: 0.7608 - val_loss: 11.2084 - val_accuracy: 0.5800 - val_f1_m: 0.5617 - val_precision_m: 0.5736 - val_recall_m: 0.5508\n",
            "Epoch 30/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8808 - accuracy: 0.8163 - f1_m: 0.8181 - precision_m: 0.8453 - recall_m: 0.7933\n",
            "Epoch 30: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 0.8808 - accuracy: 0.8163 - f1_m: 0.8181 - precision_m: 0.8453 - recall_m: 0.7933 - val_loss: 10.2745 - val_accuracy: 0.6050 - val_f1_m: 0.6262 - val_precision_m: 0.6532 - val_recall_m: 0.6016\n",
            "Epoch 31/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.6620 - accuracy: 0.8313 - f1_m: 0.8359 - precision_m: 0.8625 - recall_m: 0.8113\n",
            "Epoch 31: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 0.6620 - accuracy: 0.8313 - f1_m: 0.8359 - precision_m: 0.8625 - recall_m: 0.8113 - val_loss: 10.4793 - val_accuracy: 0.6250 - val_f1_m: 0.6394 - val_precision_m: 0.6683 - val_recall_m: 0.6133\n",
            "Epoch 32/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.3603 - accuracy: 0.8863 - f1_m: 0.8887 - precision_m: 0.9193 - recall_m: 0.8606\n",
            "Epoch 32: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 65ms/step - loss: 0.3603 - accuracy: 0.8863 - f1_m: 0.8887 - precision_m: 0.9193 - recall_m: 0.8606 - val_loss: 11.5287 - val_accuracy: 0.6650 - val_f1_m: 0.6831 - val_precision_m: 0.7351 - val_recall_m: 0.6406\n",
            "Epoch 33/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.3793 - accuracy: 0.8888 - f1_m: 0.8908 - precision_m: 0.9267 - recall_m: 0.8582\n",
            "Epoch 33: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 66ms/step - loss: 0.3793 - accuracy: 0.8888 - f1_m: 0.8908 - precision_m: 0.9267 - recall_m: 0.8582 - val_loss: 9.2094 - val_accuracy: 0.7150 - val_f1_m: 0.6777 - val_precision_m: 0.7272 - val_recall_m: 0.6367\n",
            "Epoch 34/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.5105 - accuracy: 0.8950 - f1_m: 0.8888 - precision_m: 0.9165 - recall_m: 0.8630\n",
            "Epoch 34: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 65ms/step - loss: 0.5105 - accuracy: 0.8950 - f1_m: 0.8888 - precision_m: 0.9165 - recall_m: 0.8630 - val_loss: 10.3268 - val_accuracy: 0.6600 - val_f1_m: 0.6837 - val_precision_m: 0.7363 - val_recall_m: 0.6406\n",
            "Epoch 35/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.4456 - accuracy: 0.8863 - f1_m: 0.8882 - precision_m: 0.9182 - recall_m: 0.8606\n",
            "Epoch 35: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 65ms/step - loss: 0.4456 - accuracy: 0.8863 - f1_m: 0.8882 - precision_m: 0.9182 - recall_m: 0.8606 - val_loss: 10.5902 - val_accuracy: 0.6600 - val_f1_m: 0.6425 - val_precision_m: 0.6873 - val_recall_m: 0.6055\n",
            "Epoch 36/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.4104 - accuracy: 0.8963 - f1_m: 0.8926 - precision_m: 0.9168 - recall_m: 0.8702\n",
            "Epoch 36: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 0.4104 - accuracy: 0.8963 - f1_m: 0.8926 - precision_m: 0.9168 - recall_m: 0.8702 - val_loss: 11.4266 - val_accuracy: 0.5900 - val_f1_m: 0.5991 - val_precision_m: 0.6088 - val_recall_m: 0.5898\n",
            "Epoch 37/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.6634 - accuracy: 0.8512 - f1_m: 0.8506 - precision_m: 0.8815 - recall_m: 0.8221\n",
            "Epoch 37: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 65ms/step - loss: 0.6634 - accuracy: 0.8512 - f1_m: 0.8506 - precision_m: 0.8815 - recall_m: 0.8221 - val_loss: 11.5153 - val_accuracy: 0.6000 - val_f1_m: 0.6198 - val_precision_m: 0.6442 - val_recall_m: 0.5977\n",
            "Epoch 38/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.4977 - accuracy: 0.8711 - f1_m: 0.8671 - precision_m: 0.8938 - recall_m: 0.8424\n",
            "Epoch 38: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 64ms/step - loss: 0.5095 - accuracy: 0.8725 - f1_m: 0.8712 - precision_m: 0.8970 - recall_m: 0.8474 - val_loss: 9.9975 - val_accuracy: 0.6850 - val_f1_m: 0.6720 - val_precision_m: 0.6938 - val_recall_m: 0.6523\n",
            "Epoch 39/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.6684 - accuracy: 0.8372 - f1_m: 0.8341 - precision_m: 0.8602 - recall_m: 0.8099\n",
            "Epoch 39: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 66ms/step - loss: 0.6487 - accuracy: 0.8400 - f1_m: 0.8419 - precision_m: 0.8684 - recall_m: 0.8173 - val_loss: 11.7841 - val_accuracy: 0.5850 - val_f1_m: 0.5834 - val_precision_m: 0.6145 - val_recall_m: 0.5586\n",
            "Epoch 40/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8146 - accuracy: 0.8238 - f1_m: 0.8289 - precision_m: 0.8545 - recall_m: 0.8053\n",
            "Epoch 40: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 66ms/step - loss: 0.8146 - accuracy: 0.8238 - f1_m: 0.8289 - precision_m: 0.8545 - recall_m: 0.8053 - val_loss: 11.0274 - val_accuracy: 0.6450 - val_f1_m: 0.6742 - val_precision_m: 0.7202 - val_recall_m: 0.6367\n",
            "Epoch 41/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.3746 - accuracy: 0.8975 - f1_m: 0.8942 - precision_m: 0.9160 - recall_m: 0.8738\n",
            "Epoch 41: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 65ms/step - loss: 0.3746 - accuracy: 0.8975 - f1_m: 0.8942 - precision_m: 0.9160 - recall_m: 0.8738 - val_loss: 10.9174 - val_accuracy: 0.6800 - val_f1_m: 0.6841 - val_precision_m: 0.7103 - val_recall_m: 0.6602\n",
            "Epoch 42/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.4481 - accuracy: 0.8763 - f1_m: 0.8786 - precision_m: 0.8990 - recall_m: 0.8594\n",
            "Epoch 42: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 66ms/step - loss: 0.4481 - accuracy: 0.8763 - f1_m: 0.8786 - precision_m: 0.8990 - recall_m: 0.8594 - val_loss: 10.1718 - val_accuracy: 0.6550 - val_f1_m: 0.6583 - val_precision_m: 0.6915 - val_recall_m: 0.6289\n",
            "Epoch 43/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.4315 - accuracy: 0.9038 - f1_m: 0.8949 - precision_m: 0.9136 - recall_m: 0.8774\n",
            "Epoch 43: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 65ms/step - loss: 0.4315 - accuracy: 0.9038 - f1_m: 0.8949 - precision_m: 0.9136 - recall_m: 0.8774 - val_loss: 10.3202 - val_accuracy: 0.6650 - val_f1_m: 0.6757 - val_precision_m: 0.7235 - val_recall_m: 0.6367\n",
            "Epoch 44/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.4193 - accuracy: 0.8838 - f1_m: 0.8894 - precision_m: 0.9072 - recall_m: 0.8726\n",
            "Epoch 44: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 65ms/step - loss: 0.4193 - accuracy: 0.8838 - f1_m: 0.8894 - precision_m: 0.9072 - recall_m: 0.8726 - val_loss: 11.4679 - val_accuracy: 0.6400 - val_f1_m: 0.6125 - val_precision_m: 0.6454 - val_recall_m: 0.5859\n",
            "Epoch 45/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.4622 - accuracy: 0.8789 - f1_m: 0.8826 - precision_m: 0.9031 - recall_m: 0.8633\n",
            "Epoch 45: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 66ms/step - loss: 0.4521 - accuracy: 0.8825 - f1_m: 0.8892 - precision_m: 0.9081 - recall_m: 0.8714 - val_loss: 10.2805 - val_accuracy: 0.6550 - val_f1_m: 0.6648 - val_precision_m: 0.6918 - val_recall_m: 0.6406\n",
            "Epoch 46/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.5481 - accuracy: 0.8737 - f1_m: 0.8768 - precision_m: 0.9018 - recall_m: 0.8534\n",
            "Epoch 46: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 0.5481 - accuracy: 0.8737 - f1_m: 0.8768 - precision_m: 0.9018 - recall_m: 0.8534 - val_loss: 11.4315 - val_accuracy: 0.6150 - val_f1_m: 0.6275 - val_precision_m: 0.6562 - val_recall_m: 0.6016\n",
            "Epoch 47/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.6382 - accuracy: 0.8763 - f1_m: 0.8838 - precision_m: 0.9048 - recall_m: 0.8642\n",
            "Epoch 47: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 65ms/step - loss: 0.6382 - accuracy: 0.8763 - f1_m: 0.8838 - precision_m: 0.9048 - recall_m: 0.8642 - val_loss: 12.0459 - val_accuracy: 0.6450 - val_f1_m: 0.6362 - val_precision_m: 0.6738 - val_recall_m: 0.6055\n",
            "Epoch 48/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.4430 - accuracy: 0.9050 - f1_m: 0.9071 - precision_m: 0.9222 - recall_m: 0.8930\n",
            "Epoch 48: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 65ms/step - loss: 0.4430 - accuracy: 0.9050 - f1_m: 0.9071 - precision_m: 0.9222 - recall_m: 0.8930 - val_loss: 12.8007 - val_accuracy: 0.7000 - val_f1_m: 0.7211 - val_precision_m: 0.7496 - val_recall_m: 0.6953\n",
            "Epoch 49/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.2763 - accuracy: 0.9162 - f1_m: 0.9182 - precision_m: 0.9333 - recall_m: 0.9038\n",
            "Epoch 49: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.2763 - accuracy: 0.9162 - f1_m: 0.9182 - precision_m: 0.9333 - recall_m: 0.9038 - val_loss: 11.3652 - val_accuracy: 0.6700 - val_f1_m: 0.6836 - val_precision_m: 0.7094 - val_recall_m: 0.6602\n",
            "Epoch 50/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.4727 - accuracy: 0.8963 - f1_m: 0.8967 - precision_m: 0.9104 - recall_m: 0.8834\n",
            "Epoch 50: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 66ms/step - loss: 0.4727 - accuracy: 0.8963 - f1_m: 0.8967 - precision_m: 0.9104 - recall_m: 0.8834 - val_loss: 11.5652 - val_accuracy: 0.6400 - val_f1_m: 0.6518 - val_precision_m: 0.6814 - val_recall_m: 0.6250\n",
            "Epoch 51/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8871 - accuracy: 0.8400 - f1_m: 0.8438 - precision_m: 0.8670 - recall_m: 0.8221\n",
            "Epoch 51: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 0.8871 - accuracy: 0.8400 - f1_m: 0.8438 - precision_m: 0.8670 - recall_m: 0.8221 - val_loss: 10.6978 - val_accuracy: 0.6150 - val_f1_m: 0.6186 - val_precision_m: 0.6417 - val_recall_m: 0.5977\n",
            "Epoch 52/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 1.5417 - accuracy: 0.8125 - f1_m: 0.8135 - precision_m: 0.8281 - recall_m: 0.7995\n",
            "Epoch 52: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 1.5513 - accuracy: 0.8050 - f1_m: 0.7973 - precision_m: 0.8116 - recall_m: 0.7837 - val_loss: 12.6306 - val_accuracy: 0.5700 - val_f1_m: 0.5538 - val_precision_m: 0.5654 - val_recall_m: 0.5430\n",
            "Epoch 53/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.9942 - accuracy: 0.7550 - f1_m: 0.7512 - precision_m: 0.7652 - recall_m: 0.7380\n",
            "Epoch 53: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 66ms/step - loss: 2.9942 - accuracy: 0.7550 - f1_m: 0.7512 - precision_m: 0.7652 - recall_m: 0.7380 - val_loss: 11.5735 - val_accuracy: 0.5550 - val_f1_m: 0.5235 - val_precision_m: 0.5363 - val_recall_m: 0.5117\n",
            "Epoch 54/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 1.9710 - accuracy: 0.8021 - f1_m: 0.7967 - precision_m: 0.8116 - recall_m: 0.7826\n",
            "Epoch 54: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 1.9468 - accuracy: 0.8062 - f1_m: 0.8049 - precision_m: 0.8210 - recall_m: 0.7897 - val_loss: 13.0409 - val_accuracy: 0.5900 - val_f1_m: 0.5653 - val_precision_m: 0.5810 - val_recall_m: 0.5508\n",
            "Epoch 55/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.1364 - accuracy: 0.8075 - f1_m: 0.7978 - precision_m: 0.8157 - recall_m: 0.7812\n",
            "Epoch 55: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 64ms/step - loss: 1.1364 - accuracy: 0.8075 - f1_m: 0.7978 - precision_m: 0.8157 - recall_m: 0.7812 - val_loss: 11.5162 - val_accuracy: 0.5900 - val_f1_m: 0.5737 - val_precision_m: 0.5990 - val_recall_m: 0.5508\n",
            "Epoch 56/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.2609 - accuracy: 0.7563 - f1_m: 0.7623 - precision_m: 0.7778 - recall_m: 0.7476\n",
            "Epoch 56: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 65ms/step - loss: 2.2609 - accuracy: 0.7563 - f1_m: 0.7623 - precision_m: 0.7778 - recall_m: 0.7476 - val_loss: 15.2823 - val_accuracy: 0.5300 - val_f1_m: 0.5666 - val_precision_m: 0.5883 - val_recall_m: 0.5469\n",
            "Epoch 57/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 1.9224 - accuracy: 0.8112 - f1_m: 0.8097 - precision_m: 0.8203 - recall_m: 0.7995\n",
            "Epoch 57: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 66ms/step - loss: 1.8854 - accuracy: 0.8112 - f1_m: 0.8070 - precision_m: 0.8187 - recall_m: 0.7957 - val_loss: 17.3667 - val_accuracy: 0.5600 - val_f1_m: 0.5663 - val_precision_m: 0.5879 - val_recall_m: 0.5469\n",
            "Epoch 58/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9767 - accuracy: 0.8188 - f1_m: 0.8203 - precision_m: 0.8363 - recall_m: 0.8053\n",
            "Epoch 58: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 65ms/step - loss: 1.9767 - accuracy: 0.8188 - f1_m: 0.8203 - precision_m: 0.8363 - recall_m: 0.8053 - val_loss: 15.8327 - val_accuracy: 0.6350 - val_f1_m: 0.5813 - val_precision_m: 0.5975 - val_recall_m: 0.5664\n",
            "Epoch 59/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.7643 - accuracy: 0.7375 - f1_m: 0.7363 - precision_m: 0.7471 - recall_m: 0.7260\n",
            "Epoch 59: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 66ms/step - loss: 3.7643 - accuracy: 0.7375 - f1_m: 0.7363 - precision_m: 0.7471 - recall_m: 0.7260 - val_loss: 20.7315 - val_accuracy: 0.5650 - val_f1_m: 0.5722 - val_precision_m: 0.5824 - val_recall_m: 0.5625\n",
            "Epoch 60/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 3.7965 - accuracy: 0.7357 - f1_m: 0.7363 - precision_m: 0.7465 - recall_m: 0.7266\n",
            "Epoch 60: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 3.6661 - accuracy: 0.7387 - f1_m: 0.7417 - precision_m: 0.7531 - recall_m: 0.7308 - val_loss: 20.2848 - val_accuracy: 0.4550 - val_f1_m: 0.4046 - val_precision_m: 0.4111 - val_recall_m: 0.3984\n",
            "Epoch 61/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.6449 - accuracy: 0.7000 - f1_m: 0.7006 - precision_m: 0.7143 - recall_m: 0.6875\n",
            "Epoch 61: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 4.6449 - accuracy: 0.7000 - f1_m: 0.7006 - precision_m: 0.7143 - recall_m: 0.6875 - val_loss: 23.9880 - val_accuracy: 0.4300 - val_f1_m: 0.4393 - val_precision_m: 0.4453 - val_recall_m: 0.4336\n",
            "Epoch 62/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 4.5133 - accuracy: 0.7096 - f1_m: 0.7072 - precision_m: 0.7225 - recall_m: 0.6927\n",
            "Epoch 62: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 4.5038 - accuracy: 0.7100 - f1_m: 0.7065 - precision_m: 0.7215 - recall_m: 0.6923 - val_loss: 25.5855 - val_accuracy: 0.4900 - val_f1_m: 0.5468 - val_precision_m: 0.5508 - val_recall_m: 0.5430\n",
            "Epoch 63/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.3429 - accuracy: 0.7300 - f1_m: 0.7299 - precision_m: 0.7389 - recall_m: 0.7212\n",
            "Epoch 63: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 66ms/step - loss: 3.3429 - accuracy: 0.7300 - f1_m: 0.7299 - precision_m: 0.7389 - recall_m: 0.7212 - val_loss: 20.6050 - val_accuracy: 0.5250 - val_f1_m: 0.4973 - val_precision_m: 0.5027 - val_recall_m: 0.4922\n",
            "Epoch 64/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.0632 - accuracy: 0.7300 - f1_m: 0.7297 - precision_m: 0.7397 - recall_m: 0.7200\n",
            "Epoch 64: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 66ms/step - loss: 3.0632 - accuracy: 0.7300 - f1_m: 0.7297 - precision_m: 0.7397 - recall_m: 0.7200 - val_loss: 20.0459 - val_accuracy: 0.5700 - val_f1_m: 0.6010 - val_precision_m: 0.6352 - val_recall_m: 0.5742\n",
            "Epoch 65/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9043 - accuracy: 0.7950 - f1_m: 0.7962 - precision_m: 0.8094 - recall_m: 0.7837\n",
            "Epoch 65: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 66ms/step - loss: 1.9043 - accuracy: 0.7950 - f1_m: 0.7962 - precision_m: 0.8094 - recall_m: 0.7837 - val_loss: 17.7548 - val_accuracy: 0.5950 - val_f1_m: 0.5893 - val_precision_m: 0.6101 - val_recall_m: 0.5703\n",
            "Epoch 66/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.7821 - accuracy: 0.8503 - f1_m: 0.8463 - precision_m: 0.8598 - recall_m: 0.8333\n",
            "Epoch 66: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 66ms/step - loss: 0.7653 - accuracy: 0.8550 - f1_m: 0.8557 - precision_m: 0.8682 - recall_m: 0.8438 - val_loss: 18.0211 - val_accuracy: 0.5550 - val_f1_m: 0.5827 - val_precision_m: 0.5967 - val_recall_m: 0.5703\n",
            "Epoch 67/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8653 - accuracy: 0.8662 - f1_m: 0.8673 - precision_m: 0.8731 - recall_m: 0.8618\n",
            "Epoch 67: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 0.8653 - accuracy: 0.8662 - f1_m: 0.8673 - precision_m: 0.8731 - recall_m: 0.8618 - val_loss: 15.6772 - val_accuracy: 0.5950 - val_f1_m: 0.6085 - val_precision_m: 0.6249 - val_recall_m: 0.5938\n",
            "Epoch 68/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9537 - accuracy: 0.8450 - f1_m: 0.8394 - precision_m: 0.8435 - recall_m: 0.8353\n",
            "Epoch 68: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 66ms/step - loss: 0.9537 - accuracy: 0.8450 - f1_m: 0.8394 - precision_m: 0.8435 - recall_m: 0.8353 - val_loss: 13.5854 - val_accuracy: 0.6400 - val_f1_m: 0.6638 - val_precision_m: 0.7026 - val_recall_m: 0.6328\n",
            "Epoch 69/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0703 - accuracy: 0.8662 - f1_m: 0.8632 - precision_m: 0.8733 - recall_m: 0.8534\n",
            "Epoch 69: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 65ms/step - loss: 1.0703 - accuracy: 0.8662 - f1_m: 0.8632 - precision_m: 0.8733 - recall_m: 0.8534 - val_loss: 17.2827 - val_accuracy: 0.5750 - val_f1_m: 0.5588 - val_precision_m: 0.5633 - val_recall_m: 0.5547\n",
            "Epoch 70/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9244 - accuracy: 0.8413 - f1_m: 0.8459 - precision_m: 0.8569 - recall_m: 0.8353\n",
            "Epoch 70: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 65ms/step - loss: 0.9244 - accuracy: 0.8413 - f1_m: 0.8459 - precision_m: 0.8569 - recall_m: 0.8353 - val_loss: 16.4180 - val_accuracy: 0.6350 - val_f1_m: 0.6386 - val_precision_m: 0.6621 - val_recall_m: 0.6172\n",
            "Epoch 71/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.7467 - accuracy: 0.9000 - f1_m: 0.8994 - precision_m: 0.9071 - recall_m: 0.8918\n",
            "Epoch 71: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 66ms/step - loss: 0.7467 - accuracy: 0.9000 - f1_m: 0.8994 - precision_m: 0.9071 - recall_m: 0.8918 - val_loss: 18.5148 - val_accuracy: 0.6350 - val_f1_m: 0.6664 - val_precision_m: 0.6728 - val_recall_m: 0.6602\n",
            "Epoch 72/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.5736 - accuracy: 0.8850 - f1_m: 0.8852 - precision_m: 0.8957 - recall_m: 0.8750\n",
            "Epoch 72: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.5736 - accuracy: 0.8850 - f1_m: 0.8852 - precision_m: 0.8957 - recall_m: 0.8750 - val_loss: 16.3471 - val_accuracy: 0.6400 - val_f1_m: 0.6364 - val_precision_m: 0.6442 - val_recall_m: 0.6289\n",
            "Epoch 73/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.2849 - accuracy: 0.9337 - f1_m: 0.9324 - precision_m: 0.9459 - recall_m: 0.9195\n",
            "Epoch 73: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.2849 - accuracy: 0.9337 - f1_m: 0.9324 - precision_m: 0.9459 - recall_m: 0.9195 - val_loss: 16.6455 - val_accuracy: 0.6250 - val_f1_m: 0.6393 - val_precision_m: 0.6552 - val_recall_m: 0.6250\n",
            "Epoch 74/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.2685 - accuracy: 0.9479 - f1_m: 0.9465 - precision_m: 0.9531 - recall_m: 0.9401\n",
            "Epoch 74: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 0.2670 - accuracy: 0.9475 - f1_m: 0.9458 - precision_m: 0.9519 - recall_m: 0.9399 - val_loss: 16.3706 - val_accuracy: 0.6850 - val_f1_m: 0.6842 - val_precision_m: 0.7063 - val_recall_m: 0.6641\n",
            "Epoch 75/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.2316 - accuracy: 0.9453 - f1_m: 0.9449 - precision_m: 0.9526 - recall_m: 0.9375\n",
            "Epoch 75: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.2341 - accuracy: 0.9450 - f1_m: 0.9444 - precision_m: 0.9515 - recall_m: 0.9375 - val_loss: 16.9778 - val_accuracy: 0.6700 - val_f1_m: 0.6762 - val_precision_m: 0.7024 - val_recall_m: 0.6523\n",
            "Epoch 76/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.2883 - accuracy: 0.9557 - f1_m: 0.9580 - precision_m: 0.9629 - recall_m: 0.9531\n",
            "Epoch 76: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 0.2875 - accuracy: 0.9563 - f1_m: 0.9588 - precision_m: 0.9634 - recall_m: 0.9543 - val_loss: 17.3519 - val_accuracy: 0.6750 - val_f1_m: 0.6643 - val_precision_m: 0.6771 - val_recall_m: 0.6523\n",
            "Epoch 77/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.2991 - accuracy: 0.9438 - f1_m: 0.9431 - precision_m: 0.9500 - recall_m: 0.9363\n",
            "Epoch 77: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 0.2991 - accuracy: 0.9438 - f1_m: 0.9431 - precision_m: 0.9500 - recall_m: 0.9363 - val_loss: 18.5671 - val_accuracy: 0.6550 - val_f1_m: 0.6628 - val_precision_m: 0.6871 - val_recall_m: 0.6406\n",
            "Epoch 78/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.3143 - accuracy: 0.9336 - f1_m: 0.9303 - precision_m: 0.9389 - recall_m: 0.9219\n",
            "Epoch 78: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3035 - accuracy: 0.9362 - f1_m: 0.9356 - precision_m: 0.9436 - recall_m: 0.9279 - val_loss: 18.7415 - val_accuracy: 0.6850 - val_f1_m: 0.6735 - val_precision_m: 0.6834 - val_recall_m: 0.6641\n",
            "Epoch 79/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.1899 - accuracy: 0.9453 - f1_m: 0.9474 - precision_m: 0.9562 - recall_m: 0.9388\n",
            "Epoch 79: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 0.1866 - accuracy: 0.9463 - f1_m: 0.9478 - precision_m: 0.9571 - recall_m: 0.9387 - val_loss: 16.7460 - val_accuracy: 0.6800 - val_f1_m: 0.6658 - val_precision_m: 0.6800 - val_recall_m: 0.6523\n",
            "Epoch 80/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.2516 - accuracy: 0.9518 - f1_m: 0.9475 - precision_m: 0.9550 - recall_m: 0.9401\n",
            "Epoch 80: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 65ms/step - loss: 0.2485 - accuracy: 0.9500 - f1_m: 0.9443 - precision_m: 0.9513 - recall_m: 0.9375 - val_loss: 17.4130 - val_accuracy: 0.6850 - val_f1_m: 0.7156 - val_precision_m: 0.7338 - val_recall_m: 0.6992\n",
            "Epoch 81/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.1133 - accuracy: 0.9740 - f1_m: 0.9719 - precision_m: 0.9777 - recall_m: 0.9661\n",
            "Epoch 81: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 0.1108 - accuracy: 0.9750 - f1_m: 0.9728 - precision_m: 0.9794 - recall_m: 0.9663 - val_loss: 16.8066 - val_accuracy: 0.6800 - val_f1_m: 0.6746 - val_precision_m: 0.6990 - val_recall_m: 0.6523\n",
            "Epoch 82/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.1094 - accuracy: 0.9762 - f1_m: 0.9752 - precision_m: 0.9807 - recall_m: 0.9700\n",
            "Epoch 82: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.1094 - accuracy: 0.9762 - f1_m: 0.9752 - precision_m: 0.9807 - recall_m: 0.9700 - val_loss: 16.3470 - val_accuracy: 0.6900 - val_f1_m: 0.7281 - val_precision_m: 0.7556 - val_recall_m: 0.7031\n",
            "Epoch 83/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.1351 - accuracy: 0.9648 - f1_m: 0.9659 - precision_m: 0.9736 - recall_m: 0.9583\n",
            "Epoch 83: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.1333 - accuracy: 0.9638 - f1_m: 0.9637 - precision_m: 0.9708 - recall_m: 0.9567 - val_loss: 16.4020 - val_accuracy: 0.6800 - val_f1_m: 0.6904 - val_precision_m: 0.7285 - val_recall_m: 0.6602\n",
            "Epoch 84/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.1418 - accuracy: 0.9648 - f1_m: 0.9633 - precision_m: 0.9672 - recall_m: 0.9596\n",
            "Epoch 84: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 65ms/step - loss: 0.1396 - accuracy: 0.9650 - f1_m: 0.9638 - precision_m: 0.9673 - recall_m: 0.9603 - val_loss: 16.5419 - val_accuracy: 0.7250 - val_f1_m: 0.7038 - val_precision_m: 0.7126 - val_recall_m: 0.6953\n",
            "Epoch 85/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.0982 - accuracy: 0.9753 - f1_m: 0.9752 - precision_m: 0.9778 - recall_m: 0.9727\n",
            "Epoch 85: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.1427 - accuracy: 0.9712 - f1_m: 0.9675 - precision_m: 0.9699 - recall_m: 0.9651 - val_loss: 17.4395 - val_accuracy: 0.6400 - val_f1_m: 0.6729 - val_precision_m: 0.6821 - val_recall_m: 0.6641\n",
            "Epoch 86/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.5742 - accuracy: 0.9154 - f1_m: 0.9171 - precision_m: 0.9215 - recall_m: 0.9128\n",
            "Epoch 86: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.5672 - accuracy: 0.9137 - f1_m: 0.9149 - precision_m: 0.9201 - recall_m: 0.9099 - val_loss: 16.9194 - val_accuracy: 0.5950 - val_f1_m: 0.5806 - val_precision_m: 0.5962 - val_recall_m: 0.5664\n",
            "Epoch 87/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.3753 - accuracy: 0.9180 - f1_m: 0.9184 - precision_m: 0.9269 - recall_m: 0.9102\n",
            "Epoch 87: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.3621 - accuracy: 0.9212 - f1_m: 0.9247 - precision_m: 0.9325 - recall_m: 0.9171 - val_loss: 17.3013 - val_accuracy: 0.6600 - val_f1_m: 0.6576 - val_precision_m: 0.7118 - val_recall_m: 0.6211\n",
            "Epoch 88/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.2215 - accuracy: 0.9475 - f1_m: 0.9462 - precision_m: 0.9502 - recall_m: 0.9423\n",
            "Epoch 88: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 0.2215 - accuracy: 0.9475 - f1_m: 0.9462 - precision_m: 0.9502 - recall_m: 0.9423 - val_loss: 17.4863 - val_accuracy: 0.6650 - val_f1_m: 0.6786 - val_precision_m: 0.7165 - val_recall_m: 0.6484\n",
            "Epoch 89/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.2656 - accuracy: 0.9427 - f1_m: 0.9441 - precision_m: 0.9522 - recall_m: 0.9362\n",
            "Epoch 89: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.2941 - accuracy: 0.9388 - f1_m: 0.9364 - precision_m: 0.9439 - recall_m: 0.9291 - val_loss: 17.9867 - val_accuracy: 0.6650 - val_f1_m: 0.6589 - val_precision_m: 0.6657 - val_recall_m: 0.6523\n",
            "Epoch 90/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.7883 - accuracy: 0.9036 - f1_m: 0.9039 - precision_m: 0.9121 - recall_m: 0.8958\n",
            "Epoch 90: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 64ms/step - loss: 0.7767 - accuracy: 0.9038 - f1_m: 0.9041 - precision_m: 0.9117 - recall_m: 0.8966 - val_loss: 17.1347 - val_accuracy: 0.6650 - val_f1_m: 0.6679 - val_precision_m: 0.6892 - val_recall_m: 0.6484\n",
            "Epoch 91/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.4038 - accuracy: 0.9193 - f1_m: 0.9191 - precision_m: 0.9256 - recall_m: 0.9128\n",
            "Epoch 91: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 0.3918 - accuracy: 0.9200 - f1_m: 0.9203 - precision_m: 0.9287 - recall_m: 0.9123 - val_loss: 17.9538 - val_accuracy: 0.6750 - val_f1_m: 0.6972 - val_precision_m: 0.7167 - val_recall_m: 0.6797\n",
            "Epoch 92/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.3633 - accuracy: 0.9310 - f1_m: 0.9318 - precision_m: 0.9379 - recall_m: 0.9258\n",
            "Epoch 92: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.3492 - accuracy: 0.9337 - f1_m: 0.9370 - precision_m: 0.9427 - recall_m: 0.9315 - val_loss: 18.2769 - val_accuracy: 0.7050 - val_f1_m: 0.7061 - val_precision_m: 0.7401 - val_recall_m: 0.6797\n",
            "Epoch 93/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.1777 - accuracy: 0.9648 - f1_m: 0.9619 - precision_m: 0.9682 - recall_m: 0.9557\n",
            "Epoch 93: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.1844 - accuracy: 0.9650 - f1_m: 0.9624 - precision_m: 0.9683 - recall_m: 0.9567 - val_loss: 16.8625 - val_accuracy: 0.6800 - val_f1_m: 0.6772 - val_precision_m: 0.6959 - val_recall_m: 0.6602\n",
            "Epoch 94/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.2674 - accuracy: 0.9596 - f1_m: 0.9601 - precision_m: 0.9646 - recall_m: 0.9557\n",
            "Epoch 94: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.2641 - accuracy: 0.9600 - f1_m: 0.9595 - precision_m: 0.9648 - recall_m: 0.9543 - val_loss: 17.2316 - val_accuracy: 0.6850 - val_f1_m: 0.6695 - val_precision_m: 0.6791 - val_recall_m: 0.6602\n",
            "Epoch 95/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.3273 - accuracy: 0.9187 - f1_m: 0.9133 - precision_m: 0.9205 - recall_m: 0.9062\n",
            "Epoch 95: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.3273 - accuracy: 0.9187 - f1_m: 0.9133 - precision_m: 0.9205 - recall_m: 0.9062 - val_loss: 16.6030 - val_accuracy: 0.6450 - val_f1_m: 0.6277 - val_precision_m: 0.6437 - val_recall_m: 0.6133\n",
            "Epoch 96/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.4072 - accuracy: 0.9245 - f1_m: 0.9224 - precision_m: 0.9310 - recall_m: 0.9141\n",
            "Epoch 96: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.3937 - accuracy: 0.9262 - f1_m: 0.9247 - precision_m: 0.9338 - recall_m: 0.9159 - val_loss: 16.5943 - val_accuracy: 0.6600 - val_f1_m: 0.6519 - val_precision_m: 0.6642 - val_recall_m: 0.6406\n",
            "Epoch 97/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.3771 - accuracy: 0.9297 - f1_m: 0.9312 - precision_m: 0.9381 - recall_m: 0.9245\n",
            "Epoch 97: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.4160 - accuracy: 0.9262 - f1_m: 0.9245 - precision_m: 0.9308 - recall_m: 0.9183 - val_loss: 16.7377 - val_accuracy: 0.6400 - val_f1_m: 0.6162 - val_precision_m: 0.6276 - val_recall_m: 0.6055\n",
            "Epoch 98/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.4305 - accuracy: 0.9245 - f1_m: 0.9246 - precision_m: 0.9328 - recall_m: 0.9167\n",
            "Epoch 98: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.4293 - accuracy: 0.9200 - f1_m: 0.9170 - precision_m: 0.9256 - recall_m: 0.9087 - val_loss: 19.3657 - val_accuracy: 0.6050 - val_f1_m: 0.6221 - val_precision_m: 0.6363 - val_recall_m: 0.6094\n",
            "Epoch 99/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.3924 - accuracy: 0.9115 - f1_m: 0.9134 - precision_m: 0.9208 - recall_m: 0.9062\n",
            "Epoch 99: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.3968 - accuracy: 0.9112 - f1_m: 0.9115 - precision_m: 0.9194 - recall_m: 0.9038 - val_loss: 18.9931 - val_accuracy: 0.6700 - val_f1_m: 0.6643 - val_precision_m: 0.6685 - val_recall_m: 0.6602\n",
            "Epoch 100/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.1901 - accuracy: 0.9538 - f1_m: 0.9517 - precision_m: 0.9552 - recall_m: 0.9483\n",
            "Epoch 100: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.1901 - accuracy: 0.9538 - f1_m: 0.9517 - precision_m: 0.9552 - recall_m: 0.9483 - val_loss: 18.6839 - val_accuracy: 0.6700 - val_f1_m: 0.6732 - val_precision_m: 0.6920 - val_recall_m: 0.6562\n",
            "Epoch 101/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.4062 - accuracy: 0.9440 - f1_m: 0.9464 - precision_m: 0.9501 - recall_m: 0.9427\n",
            "Epoch 101: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 66ms/step - loss: 0.3908 - accuracy: 0.9463 - f1_m: 0.9505 - precision_m: 0.9540 - recall_m: 0.9471 - val_loss: 15.8836 - val_accuracy: 0.6700 - val_f1_m: 0.6759 - val_precision_m: 0.6974 - val_recall_m: 0.6562\n",
            "Epoch 102/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.2028 - accuracy: 0.9625 - f1_m: 0.9589 - precision_m: 0.9623 - recall_m: 0.9555\n",
            "Epoch 102: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.2028 - accuracy: 0.9625 - f1_m: 0.9589 - precision_m: 0.9623 - recall_m: 0.9555 - val_loss: 17.6766 - val_accuracy: 0.6900 - val_f1_m: 0.6827 - val_precision_m: 0.7032 - val_recall_m: 0.6641\n",
            "Epoch 103/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.1924 - accuracy: 0.9531 - f1_m: 0.9529 - precision_m: 0.9567 - recall_m: 0.9492\n",
            "Epoch 103: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.1950 - accuracy: 0.9525 - f1_m: 0.9517 - precision_m: 0.9552 - recall_m: 0.9483 - val_loss: 18.1029 - val_accuracy: 0.6400 - val_f1_m: 0.6366 - val_precision_m: 0.6405 - val_recall_m: 0.6328\n",
            "Epoch 104/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.1161 - accuracy: 0.9663 - f1_m: 0.9651 - precision_m: 0.9674 - recall_m: 0.9627\n",
            "Epoch 104: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.1161 - accuracy: 0.9663 - f1_m: 0.9651 - precision_m: 0.9674 - recall_m: 0.9627 - val_loss: 17.8971 - val_accuracy: 0.6650 - val_f1_m: 0.6355 - val_precision_m: 0.6422 - val_recall_m: 0.6289\n",
            "Epoch 105/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.1103 - accuracy: 0.9779 - f1_m: 0.9759 - precision_m: 0.9778 - recall_m: 0.9740\n",
            "Epoch 105: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.1125 - accuracy: 0.9775 - f1_m: 0.9753 - precision_m: 0.9771 - recall_m: 0.9736 - val_loss: 16.9628 - val_accuracy: 0.6800 - val_f1_m: 0.6655 - val_precision_m: 0.6710 - val_recall_m: 0.6602\n",
            "Epoch 106/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.1215 - accuracy: 0.9805 - f1_m: 0.9798 - precision_m: 0.9804 - recall_m: 0.9792\n",
            "Epoch 106: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.1195 - accuracy: 0.9800 - f1_m: 0.9789 - precision_m: 0.9795 - recall_m: 0.9784 - val_loss: 17.4219 - val_accuracy: 0.6750 - val_f1_m: 0.6616 - val_precision_m: 0.6711 - val_recall_m: 0.6523\n",
            "Epoch 107/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.2533 - accuracy: 0.9475 - f1_m: 0.9462 - precision_m: 0.9502 - recall_m: 0.9423\n",
            "Epoch 107: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.2533 - accuracy: 0.9475 - f1_m: 0.9462 - precision_m: 0.9502 - recall_m: 0.9423 - val_loss: 17.9427 - val_accuracy: 0.6450 - val_f1_m: 0.6130 - val_precision_m: 0.6169 - val_recall_m: 0.6094\n",
            "Epoch 108/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.5103 - accuracy: 0.9062 - f1_m: 0.9071 - precision_m: 0.9167 - recall_m: 0.8978\n",
            "Epoch 108: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.5103 - accuracy: 0.9062 - f1_m: 0.9071 - precision_m: 0.9167 - recall_m: 0.8978 - val_loss: 18.0215 - val_accuracy: 0.6050 - val_f1_m: 0.5559 - val_precision_m: 0.5572 - val_recall_m: 0.5547\n",
            "Epoch 109/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.3075 - accuracy: 0.9297 - f1_m: 0.9285 - precision_m: 0.9340 - recall_m: 0.9232\n",
            "Epoch 109: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 0.3168 - accuracy: 0.9250 - f1_m: 0.9196 - precision_m: 0.9247 - recall_m: 0.9147 - val_loss: 17.4964 - val_accuracy: 0.6950 - val_f1_m: 0.6732 - val_precision_m: 0.7042 - val_recall_m: 0.6484\n",
            "Epoch 110/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.2154 - accuracy: 0.9544 - f1_m: 0.9553 - precision_m: 0.9616 - recall_m: 0.9492\n",
            "Epoch 110: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.2083 - accuracy: 0.9563 - f1_m: 0.9588 - precision_m: 0.9646 - recall_m: 0.9531 - val_loss: 18.0286 - val_accuracy: 0.6650 - val_f1_m: 0.6862 - val_precision_m: 0.6889 - val_recall_m: 0.6836\n",
            "Epoch 111/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.1528 - accuracy: 0.9557 - f1_m: 0.9568 - precision_m: 0.9619 - recall_m: 0.9518\n",
            "Epoch 111: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.1469 - accuracy: 0.9575 - f1_m: 0.9601 - precision_m: 0.9648 - recall_m: 0.9555 - val_loss: 17.7344 - val_accuracy: 0.6950 - val_f1_m: 0.6984 - val_precision_m: 0.7189 - val_recall_m: 0.6797\n",
            "Epoch 112/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.1174 - accuracy: 0.9740 - f1_m: 0.9705 - precision_m: 0.9763 - recall_m: 0.9648\n",
            "Epoch 112: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.1167 - accuracy: 0.9725 - f1_m: 0.9679 - precision_m: 0.9733 - recall_m: 0.9627 - val_loss: 17.5642 - val_accuracy: 0.6800 - val_f1_m: 0.6708 - val_precision_m: 0.6736 - val_recall_m: 0.6680\n",
            "Epoch 113/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.3196 - accuracy: 0.9350 - f1_m: 0.9327 - precision_m: 0.9390 - recall_m: 0.9267\n",
            "Epoch 113: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.3196 - accuracy: 0.9350 - f1_m: 0.9327 - precision_m: 0.9390 - recall_m: 0.9267 - val_loss: 18.0958 - val_accuracy: 0.6950 - val_f1_m: 0.6811 - val_precision_m: 0.6867 - val_recall_m: 0.6758\n",
            "Epoch 114/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.4904 - accuracy: 0.9245 - f1_m: 0.9233 - precision_m: 0.9288 - recall_m: 0.9180\n",
            "Epoch 114: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.4830 - accuracy: 0.9237 - f1_m: 0.9231 - precision_m: 0.9293 - recall_m: 0.9171 - val_loss: 19.1225 - val_accuracy: 0.6300 - val_f1_m: 0.6036 - val_precision_m: 0.6097 - val_recall_m: 0.5977\n",
            "Epoch 115/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.3578 - accuracy: 0.9401 - f1_m: 0.9408 - precision_m: 0.9470 - recall_m: 0.9349\n",
            "Epoch 115: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 66ms/step - loss: 0.3487 - accuracy: 0.9413 - f1_m: 0.9417 - precision_m: 0.9486 - recall_m: 0.9351 - val_loss: 17.7077 - val_accuracy: 0.6300 - val_f1_m: 0.6376 - val_precision_m: 0.6557 - val_recall_m: 0.6211\n",
            "Epoch 116/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.6949 - accuracy: 0.9000 - f1_m: 0.8979 - precision_m: 0.9054 - recall_m: 0.8906\n",
            "Epoch 116: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.6949 - accuracy: 0.9000 - f1_m: 0.8979 - precision_m: 0.9054 - recall_m: 0.8906 - val_loss: 20.6129 - val_accuracy: 0.6250 - val_f1_m: 0.5808 - val_precision_m: 0.6077 - val_recall_m: 0.5586\n",
            "Epoch 117/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.7847 - accuracy: 0.9036 - f1_m: 0.9054 - precision_m: 0.9125 - recall_m: 0.8984\n",
            "Epoch 117: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 0.7774 - accuracy: 0.9038 - f1_m: 0.9054 - precision_m: 0.9120 - recall_m: 0.8990 - val_loss: 21.1481 - val_accuracy: 0.6900 - val_f1_m: 0.6787 - val_precision_m: 0.6857 - val_recall_m: 0.6719\n",
            "Epoch 118/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.5605 - accuracy: 0.9349 - f1_m: 0.9333 - precision_m: 0.9357 - recall_m: 0.9310\n",
            "Epoch 118: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 0.5531 - accuracy: 0.9325 - f1_m: 0.9285 - precision_m: 0.9330 - recall_m: 0.9243 - val_loss: 20.0216 - val_accuracy: 0.6650 - val_f1_m: 0.6302 - val_precision_m: 0.6314 - val_recall_m: 0.6289\n",
            "Epoch 119/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.3732 - accuracy: 0.9349 - f1_m: 0.9335 - precision_m: 0.9360 - recall_m: 0.9310\n",
            "Epoch 119: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 65ms/step - loss: 0.4058 - accuracy: 0.9350 - f1_m: 0.9338 - precision_m: 0.9361 - recall_m: 0.9315 - val_loss: 17.7034 - val_accuracy: 0.6550 - val_f1_m: 0.6614 - val_precision_m: 0.6799 - val_recall_m: 0.6445\n",
            "Epoch 120/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.4747 - accuracy: 0.9337 - f1_m: 0.9293 - precision_m: 0.9345 - recall_m: 0.9243\n",
            "Epoch 120: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 66ms/step - loss: 0.4747 - accuracy: 0.9337 - f1_m: 0.9293 - precision_m: 0.9345 - recall_m: 0.9243 - val_loss: 16.5045 - val_accuracy: 0.6800 - val_f1_m: 0.6637 - val_precision_m: 0.6762 - val_recall_m: 0.6523\n",
            "Epoch 121/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9118 - accuracy: 0.9089 - f1_m: 0.9095 - precision_m: 0.9143 - recall_m: 0.9049\n",
            "Epoch 121: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 1.0902 - accuracy: 0.9087 - f1_m: 0.9093 - precision_m: 0.9137 - recall_m: 0.9050 - val_loss: 18.0004 - val_accuracy: 0.6350 - val_f1_m: 0.6758 - val_precision_m: 0.6976 - val_recall_m: 0.6562\n",
            "Epoch 122/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 1.4903 - accuracy: 0.8984 - f1_m: 0.8995 - precision_m: 0.9060 - recall_m: 0.8932\n",
            "Epoch 122: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 1.4425 - accuracy: 0.9000 - f1_m: 0.9025 - precision_m: 0.9084 - recall_m: 0.8966 - val_loss: 16.9703 - val_accuracy: 0.6450 - val_f1_m: 0.6777 - val_precision_m: 0.6973 - val_recall_m: 0.6602\n",
            "Epoch 123/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9289 - accuracy: 0.8906 - f1_m: 0.8913 - precision_m: 0.8960 - recall_m: 0.8867\n",
            "Epoch 123: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.9024 - accuracy: 0.8900 - f1_m: 0.8900 - precision_m: 0.8944 - recall_m: 0.8858 - val_loss: 16.5478 - val_accuracy: 0.6000 - val_f1_m: 0.5900 - val_precision_m: 0.6074 - val_recall_m: 0.5742\n",
            "Epoch 124/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 1.5655 - accuracy: 0.8711 - f1_m: 0.8701 - precision_m: 0.8758 - recall_m: 0.8646\n",
            "Epoch 124: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 1.5688 - accuracy: 0.8750 - f1_m: 0.8777 - precision_m: 0.8829 - recall_m: 0.8726 - val_loss: 18.0963 - val_accuracy: 0.6450 - val_f1_m: 0.6418 - val_precision_m: 0.6471 - val_recall_m: 0.6367\n",
            "Epoch 125/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9806 - accuracy: 0.8562 - f1_m: 0.8576 - precision_m: 0.8633 - recall_m: 0.8522\n",
            "Epoch 125: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 0.9806 - accuracy: 0.8562 - f1_m: 0.8576 - precision_m: 0.8633 - recall_m: 0.8522 - val_loss: 21.3722 - val_accuracy: 0.6300 - val_f1_m: 0.6441 - val_precision_m: 0.6610 - val_recall_m: 0.6289\n",
            "Epoch 126/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9015 - accuracy: 0.8802 - f1_m: 0.8793 - precision_m: 0.8850 - recall_m: 0.8737\n",
            "Epoch 126: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 0.9192 - accuracy: 0.8788 - f1_m: 0.8765 - precision_m: 0.8818 - recall_m: 0.8714 - val_loss: 23.9607 - val_accuracy: 0.5500 - val_f1_m: 0.5437 - val_precision_m: 0.5576 - val_recall_m: 0.5312\n",
            "Epoch 127/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 1.6363 - accuracy: 0.8477 - f1_m: 0.8484 - precision_m: 0.8559 - recall_m: 0.8411\n",
            "Epoch 127: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 1.6528 - accuracy: 0.8425 - f1_m: 0.8384 - precision_m: 0.8454 - recall_m: 0.8317 - val_loss: 21.4271 - val_accuracy: 0.6250 - val_f1_m: 0.6261 - val_precision_m: 0.6312 - val_recall_m: 0.6211\n",
            "Epoch 128/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 1.9556 - accuracy: 0.8672 - f1_m: 0.8674 - precision_m: 0.8743 - recall_m: 0.8607\n",
            "Epoch 128: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 2.0042 - accuracy: 0.8675 - f1_m: 0.8680 - precision_m: 0.8743 - recall_m: 0.8618 - val_loss: 18.8444 - val_accuracy: 0.6400 - val_f1_m: 0.6161 - val_precision_m: 0.6321 - val_recall_m: 0.6016\n",
            "Epoch 129/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 1.7865 - accuracy: 0.8776 - f1_m: 0.8766 - precision_m: 0.8795 - recall_m: 0.8737\n",
            "Epoch 129: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 1.7347 - accuracy: 0.8788 - f1_m: 0.8789 - precision_m: 0.8816 - recall_m: 0.8762 - val_loss: 20.4561 - val_accuracy: 0.6300 - val_f1_m: 0.6391 - val_precision_m: 0.6548 - val_recall_m: 0.6250\n",
            "Epoch 130/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.9050 - accuracy: 0.8537 - f1_m: 0.8540 - precision_m: 0.8609 - recall_m: 0.8474\n",
            "Epoch 130: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 65ms/step - loss: 1.9050 - accuracy: 0.8537 - f1_m: 0.8540 - precision_m: 0.8609 - recall_m: 0.8474 - val_loss: 17.2190 - val_accuracy: 0.6900 - val_f1_m: 0.6786 - val_precision_m: 0.6816 - val_recall_m: 0.6758\n",
            "Epoch 131/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.1376 - accuracy: 0.8788 - f1_m: 0.8765 - precision_m: 0.8818 - recall_m: 0.8714\n",
            "Epoch 131: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 1.1376 - accuracy: 0.8788 - f1_m: 0.8765 - precision_m: 0.8818 - recall_m: 0.8714 - val_loss: 24.6079 - val_accuracy: 0.5400 - val_f1_m: 0.5636 - val_precision_m: 0.5821 - val_recall_m: 0.5469\n",
            "Epoch 132/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 1.1797 - accuracy: 0.8828 - f1_m: 0.8834 - precision_m: 0.8880 - recall_m: 0.8789\n",
            "Epoch 132: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 1.1552 - accuracy: 0.8800 - f1_m: 0.8765 - precision_m: 0.8818 - recall_m: 0.8714 - val_loss: 20.6746 - val_accuracy: 0.6250 - val_f1_m: 0.6114 - val_precision_m: 0.6389 - val_recall_m: 0.5898\n",
            "Epoch 133/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.1972 - accuracy: 0.8875 - f1_m: 0.8886 - precision_m: 0.8951 - recall_m: 0.8822\n",
            "Epoch 133: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 1.1972 - accuracy: 0.8875 - f1_m: 0.8886 - precision_m: 0.8951 - recall_m: 0.8822 - val_loss: 19.8571 - val_accuracy: 0.5700 - val_f1_m: 0.5890 - val_precision_m: 0.6054 - val_recall_m: 0.5742\n",
            "Epoch 134/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.7023 - accuracy: 0.9013 - f1_m: 0.8994 - precision_m: 0.9022 - recall_m: 0.8966\n",
            "Epoch 134: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.7023 - accuracy: 0.9013 - f1_m: 0.8994 - precision_m: 0.9022 - recall_m: 0.8966 - val_loss: 19.5294 - val_accuracy: 0.6700 - val_f1_m: 0.6575 - val_precision_m: 0.6588 - val_recall_m: 0.6562\n",
            "Epoch 135/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.3049 - accuracy: 0.9414 - f1_m: 0.9423 - precision_m: 0.9486 - recall_m: 0.9362\n",
            "Epoch 135: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.2938 - accuracy: 0.9438 - f1_m: 0.9467 - precision_m: 0.9525 - recall_m: 0.9411 - val_loss: 22.8547 - val_accuracy: 0.6500 - val_f1_m: 0.6755 - val_precision_m: 0.6792 - val_recall_m: 0.6719\n",
            "Epoch 136/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.3454 - accuracy: 0.9350 - f1_m: 0.9371 - precision_m: 0.9417 - recall_m: 0.9327\n",
            "Epoch 136: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 66ms/step - loss: 0.3454 - accuracy: 0.9350 - f1_m: 0.9371 - precision_m: 0.9417 - recall_m: 0.9327 - val_loss: 17.2432 - val_accuracy: 0.6650 - val_f1_m: 0.6536 - val_precision_m: 0.6588 - val_recall_m: 0.6484\n",
            "Epoch 137/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.2116 - accuracy: 0.9505 - f1_m: 0.9516 - precision_m: 0.9540 - recall_m: 0.9492\n",
            "Epoch 137: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.2043 - accuracy: 0.9525 - f1_m: 0.9553 - precision_m: 0.9575 - recall_m: 0.9531 - val_loss: 18.4873 - val_accuracy: 0.6850 - val_f1_m: 0.6708 - val_precision_m: 0.6778 - val_recall_m: 0.6641\n",
            "Epoch 138/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.1421 - accuracy: 0.9661 - f1_m: 0.9660 - precision_m: 0.9686 - recall_m: 0.9635\n",
            "Epoch 138: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.1555 - accuracy: 0.9663 - f1_m: 0.9650 - precision_m: 0.9685 - recall_m: 0.9615 - val_loss: 16.9397 - val_accuracy: 0.6800 - val_f1_m: 0.6692 - val_precision_m: 0.6705 - val_recall_m: 0.6680\n",
            "Epoch 139/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0895 - accuracy: 0.9775 - f1_m: 0.9778 - precision_m: 0.9783 - recall_m: 0.9772\n",
            "Epoch 139: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 0.0895 - accuracy: 0.9775 - f1_m: 0.9778 - precision_m: 0.9783 - recall_m: 0.9772 - val_loss: 18.0736 - val_accuracy: 0.6350 - val_f1_m: 0.6365 - val_precision_m: 0.6403 - val_recall_m: 0.6328\n",
            "Epoch 140/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.1476 - accuracy: 0.9588 - f1_m: 0.9579 - precision_m: 0.9602 - recall_m: 0.9555\n",
            "Epoch 140: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 66ms/step - loss: 0.1476 - accuracy: 0.9588 - f1_m: 0.9579 - precision_m: 0.9602 - recall_m: 0.9555 - val_loss: 16.4201 - val_accuracy: 0.6850 - val_f1_m: 0.6622 - val_precision_m: 0.6940 - val_recall_m: 0.6367\n",
            "Epoch 141/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.0726 - accuracy: 0.9766 - f1_m: 0.9751 - precision_m: 0.9804 - recall_m: 0.9701\n",
            "Epoch 141: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.0713 - accuracy: 0.9775 - f1_m: 0.9758 - precision_m: 0.9819 - recall_m: 0.9700 - val_loss: 16.2830 - val_accuracy: 0.6800 - val_f1_m: 0.6836 - val_precision_m: 0.7009 - val_recall_m: 0.6680\n",
            "Epoch 142/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0476 - accuracy: 0.9862 - f1_m: 0.9862 - precision_m: 0.9880 - recall_m: 0.9844\n",
            "Epoch 142: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.0476 - accuracy: 0.9862 - f1_m: 0.9862 - precision_m: 0.9880 - recall_m: 0.9844 - val_loss: 17.0653 - val_accuracy: 0.6850 - val_f1_m: 0.6838 - val_precision_m: 0.7012 - val_recall_m: 0.6680\n",
            "Epoch 143/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.0696 - accuracy: 0.9870 - f1_m: 0.9863 - precision_m: 0.9870 - recall_m: 0.9857\n",
            "Epoch 143: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 0.0696 - accuracy: 0.9862 - f1_m: 0.9850 - precision_m: 0.9856 - recall_m: 0.9844 - val_loss: 18.1450 - val_accuracy: 0.6850 - val_f1_m: 0.6772 - val_precision_m: 0.6827 - val_recall_m: 0.6719\n",
            "Epoch 144/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.0167 - accuracy: 0.9974 - f1_m: 0.9974 - precision_m: 0.9987 - recall_m: 0.9961\n",
            "Epoch 144: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 66ms/step - loss: 0.0164 - accuracy: 0.9975 - f1_m: 0.9976 - precision_m: 0.9988 - recall_m: 0.9964 - val_loss: 17.4999 - val_accuracy: 0.6950 - val_f1_m: 0.6836 - val_precision_m: 0.6876 - val_recall_m: 0.6797\n",
            "Epoch 145/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.0630 - accuracy: 0.9935 - f1_m: 0.9935 - precision_m: 0.9948 - recall_m: 0.9922\n",
            "Epoch 145: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 64ms/step - loss: 0.0606 - accuracy: 0.9937 - f1_m: 0.9940 - precision_m: 0.9952 - recall_m: 0.9928 - val_loss: 18.5760 - val_accuracy: 0.6850 - val_f1_m: 0.6864 - val_precision_m: 0.7024 - val_recall_m: 0.6719\n",
            "Epoch 146/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.0790 - accuracy: 0.9870 - f1_m: 0.9863 - precision_m: 0.9870 - recall_m: 0.9857\n",
            "Epoch 146: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.0774 - accuracy: 0.9862 - f1_m: 0.9850 - precision_m: 0.9856 - recall_m: 0.9844 - val_loss: 19.0218 - val_accuracy: 0.6750 - val_f1_m: 0.6587 - val_precision_m: 0.6613 - val_recall_m: 0.6562\n",
            "Epoch 147/150\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0620 - accuracy: 0.9887 - f1_m: 0.9891 - precision_m: 0.9928 - recall_m: 0.9856\n",
            "Epoch 147: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.0620 - accuracy: 0.9887 - f1_m: 0.9891 - precision_m: 0.9928 - recall_m: 0.9856 - val_loss: 20.0391 - val_accuracy: 0.7250 - val_f1_m: 0.7375 - val_precision_m: 0.7447 - val_recall_m: 0.7305\n",
            "Epoch 148/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.0150 - accuracy: 0.9974 - f1_m: 0.9961 - precision_m: 0.9974 - recall_m: 0.9948\n",
            "Epoch 148: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 0.0178 - accuracy: 0.9962 - f1_m: 0.9940 - precision_m: 0.9952 - recall_m: 0.9928 - val_loss: 20.1376 - val_accuracy: 0.7050 - val_f1_m: 0.7035 - val_precision_m: 0.7347 - val_recall_m: 0.6797\n",
            "Epoch 149/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.0159 - accuracy: 0.9974 - f1_m: 0.9974 - precision_m: 0.9987 - recall_m: 0.9961\n",
            "Epoch 149: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.0156 - accuracy: 0.9975 - f1_m: 0.9976 - precision_m: 0.9988 - recall_m: 0.9964 - val_loss: 19.1930 - val_accuracy: 0.7450 - val_f1_m: 0.7474 - val_precision_m: 0.7488 - val_recall_m: 0.7461\n",
            "Epoch 150/150\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.0117 - accuracy: 0.9987 - f1_m: 0.9987 - precision_m: 0.9987 - recall_m: 0.9987\n",
            "Epoch 150: val_loss did not improve from 8.96088\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 0.0118 - accuracy: 0.9987 - f1_m: 0.9988 - precision_m: 0.9988 - recall_m: 0.9988 - val_loss: 18.8571 - val_accuracy: 0.7200 - val_f1_m: 0.7047 - val_precision_m: 0.7195 - val_recall_m: 0.6914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Plots and Evaluation Metrices**"
      ],
      "metadata": {
        "id": "HnlfDZx5k6ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "model.metrics_names\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "HrkY2VZoSnDC",
        "outputId": "d20ed0b6-a077-4b84-e40e-0eadaed35473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion matrix, heatmap and evalution metrics"
      ],
      "metadata": {
        "id": "G7qsfS07mJwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(filepath, custom_objects={'f1_m':f1_m, 'precision_m':precision_m, 'recall_m':recall_m})"
      ],
      "metadata": {
        "id": "x0etGrbys0B7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = model.evaluate(X_test, y_test)\n",
        "print('Validation-loss:', accuracy[0])\n",
        "print('Accuracy:', accuracy[1])\n",
        "print('F1 Score:', accuracy[2])\n",
        "print('Precision:', accuracy[3])\n",
        "print('Recall:', accuracy[4])\n",
        "pred=model.predict(X_test)\n",
        "y_pred = numpy.argmax(pred, axis=1)\n",
        "y_true = numpy.argmax(y_test, axis=1)\n",
        "print('confusion matrix')\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "f, ax = plt.subplots(figsize=(8,5))\n",
        "sns.heatmap(confusion_matrix(y_true, y_pred), annot=True, fmt=\".0f\", ax=ax)\n",
        "plt.xlabel(\"y_pred\")\n",
        "plt.ylabel(\"y_true\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CHrQWgMpZttB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "outputId": "ed80ce74-baaf-46c6-f20d-12e35ca05ff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 17ms/step - loss: 18.8571 - accuracy: 0.7200 - f1_m: 0.7102 - precision_m: 0.7206 - recall_m: 0.7009\n",
            "n Test_Accuracy:- 0.7200000286102295\n",
            "confusion matrix\n",
            "[[16  0  2  0  2  1  0  0  0  1]\n",
            " [ 0 17  1  0  0  2  0  0  1  0]\n",
            " [ 1  0 17  0  0  3  1  0  0  0]\n",
            " [ 0  0  2 12  0  4  1  0  0  1]\n",
            " [ 0  2  0  0 14  0  0  0  0  1]\n",
            " [ 0  0  1  3  2 12  0  0  1  0]\n",
            " [ 1  1  0  1  1  1 11  0  0  1]\n",
            " [ 0  0  0  0  0  0  0 18  0  2]\n",
            " [ 0  1  2  1  0  0  0  0 16  0]\n",
            " [ 0  1  0  1  0  1  5  1  2 11]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}